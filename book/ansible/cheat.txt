Dan’s Cheat Sheets Documentation
Release 1

Dan Poirier

Mar 13, 2019

Contents

1

Android information

3

2

Ansible

7

3

AWS

49

4

Bootstrap

51

5

Debian

53

6

Diet

55

7

Django

61

8

Docker

123

9

Elasticsearch

125

10 Elixir

131

11 Git

137

12 Google APIs

143

13 Gulp Tasks

145

14 HAProxy

147

15 Haskell

149

16 i3

153

17 IPv6

155

18 Javascript

157

19 Kobo ereader

165

20 Linux Notes, Misc.

169

i

21 LIRC: linux infrared remote control

171

22 LVM

173

23 LXDE

175

24 Logitech Harmony

177

25 MPD

199

26 MySQL with Django

201

27 Nginx

205

28 NPM

209

29 OpenSSL

211

30 Org mode (Emacs)

217

31 Postfix

219

32 Postgres

221

33 Python

227

34 Raspberry Pi

249

35 Release - how to

253

36 reStructuredText

255

37 Salt Stack

261

38 Socat

263

39 Tmux

265

40 Travis CI

267

41 Video

269

42 X11 Window System

271

43 Virtualbox

273

44 Vue

275

45 Possibly surprising things in Vue

279

46 YAML

283

47 Indices and tables

285

ii

Dan’s Cheat Sheets Documentation, Release 1

Contents:

Contents

1

Dan’s Cheat Sheets Documentation, Release 1

2

Contents

CHAPTER

1

Android information

Contents:

1.1 Nexus 6P
This information is specific to the Google/Huawei Nexus 6P. See also more universal android info.
Code name: angler
There’s lots of information about the Nexus 6P that is nicely gathered in this thread on xda-developers.
SEE ALSO: Android universal instructions

1.1.1 Booting into different modes
Enter safe mode
(this will boot with 3rd-party apps disabled):
1. Have Your Nexus 6P Powered on and at the Home Screen
2. Press and Hold the Power Button until You See the ‘Power Off’ Dialog Screen Pop Up,
3. Let Go of the Power Button
4. Then Tap and Hold Your Finger on the “Power Off’ Option. After Holding for a Few Seconds You’ll be Asked
if You Want to Reboot Into Safe Mode.
5. Simply Tap the ‘OK’ Option to Reboot Your Nexus 6P Into Safe Mode. Then Wait for the Nexus 6P to Reboot
Enter fastboot aka bootloader mode
(https://www.androidexplained.com/nexus-6p-fastboot-mode/):

3

Dan’s Cheat Sheets Documentation, Release 1

This lets you execute certain ADB and Fastboot commands from your computer, get to recovery mode from here.
1. Power Down the Nexus 6P
2. Once the Device is Off, Press and Hold the Power Button and Volume Down Button at the Same Time
3. Continue Holding These Two Buttons Until you See the Special Fastboot Mode Screen
4. When You are in Fastboot Mode, You Can Let Go of These Two Buttons
Enter recovery mode
This lets you do a factory reset, wipe the cache partition or sideload an OTA update, etc. Also, “reboot bootloader”
goes back to fastboot/bootloader mode.
1. Boot the Nexus 6P into Fastboot Mode
2. Once in Fastboot Mode, Press the volume Down Button Twice. This Should Highlight the ‘Recovery’ Option
3. Press the Power Button to Select This Option. This Will Take You to a Black Screen with a Green Android
Laying Down
4. Press and Hold the the Power Button, Then Press the Volume Up Button, You’ll Immediately be Taken to the
Recovery Mode Menu
Here’s a kernel? https://forum.xda-developers.com/nexus-6p/development/kernel-purez-kernel-v2-0-purezandroid-t3636909
https://github.com/purezandroid/purez-kernel-angler

1.1.2 Installing/replacing stuff
Custom recovery
This is a pre-req to install custom ROM.
The following information is not specific to any Android device. See the links just above for device-specific info.
Android universal instructions (custom roms etc)
See device-specific pages for how to get into recovery mode, fastboot mode, etc etc

1.2 Installing adb and fastboot on a computer
(not the android, a linux or windows or something)
https://developer.android.com/studio/releases/platform-tools.html
Just download the zip, unpack, and put the binaries on your PATH or something.

1.3 Custom recovery
(Pre-req to install custom ROM)
https://www.xda-developers.com/how-to-install-twrp/
Download from https://twrp.me/Devices/
Before:

4

Chapter 1. Android information

Dan’s Cheat Sheets Documentation, Release 1

• Install adb and fastboot on a computer
• Enable USB debugging on the android device
To install TWRP:
1. Boot into bootloader mode (e.g. fastboot mode)
2. “fastboot flash recovery twrp-2.8.x.x-xxx.img”
3. “fastboot reboot”
ALTERNATIVELY if device is already rooted, you can install and use TWRP manager

1.4 Custom ROM
http://www.android.gs/install-custom-roms-android-devices-guide/
THIS WIPES ALL YOUR DATA
1. Copy zipfiles to phone file system
2. Boot into recovery mode
3. select “wipe data factory reset”, “wipe cache partition” and “wipe dalvick cache”.
4. Choose “install zip from SD card” and “choose zip from SD card”. Pick the update file and flash the same.
5. Optional: repeat this operation for applying the Google Apps package.
6. Reboot

1.5 Kernel
(as opposed to the whole ROM)

1.5.1 With fastboot
1. Plug in the phone and boot to fastboot mode (back+power or camera+power). Wait until the screen with skating
‘droids appears,
2. press the back button (the center bar should say “Fastboot” or “Fastboot USB”)
3. On the computer:
fastboot flash boot boot.img
fastboot reboot

1.4. Custom ROM

5

Dan’s Cheat Sheets Documentation, Release 1

6

Chapter 1. Android information

CHAPTER

2

Ansible

This is growing into a minimal Ansible reference of sorts, since Ansible’s own docs have nothing like a reference.
• Ansible.
• list of keys that common playbook objects can take.
• Release tarballs
• Ansible documentation for older releases
Quickies:
To check the ubuntu version, ansible_distribution_version|float < 18 (ansible_distribution_version
is e.g. “16.04”):
"ansible_distribution_release": "bionic"
"ansible_distribution_version": "18.04"

2.1 Running Ansible tasks in the background
Example:
- name: start collectstatic in the background
command: "{{ install_root }}/env/bin/python manage.py collectstatic --noinput -v 0"
args:
chdir: "{{ install_root }}/webapp"
async: 1000
poll: 0
register: collectstatic_bg
################################################################################
#
# PUT TASKS HERE THAT DON'T NEED TO BE RUN BEFORE COLLECTSTATIC CAN START,
# AND THAT WON'T AFFECT THE BACKGROUND COLLECTSTATIC.
(continues on next page)

7

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

#
################################################################################
- name: clean up local tarball
delegate_to: 127.0.0.1
# Run on localhost
run_once: yes
# only once
become: no
# Don't need sudo
file:
state: absent
path: "{{ tarball }}"
- name: migrate
command: "{{ install_root }}/env/bin/python manage.py migrate --noinput"
args:
chdir: "{{ install_root }}/webapp"
- name: install tasks
command: "{{ install_root }}/env/bin/python manage.py installtasks --traceback"
args:
chdir: "{{ install_root }}/webapp"
################################################################################
#
# Check every 'delay' seconds, up to 'retries' times, until collectstatic is done
#
################################################################################
- name: wait for collectstatic to finish
async_status: jid={{ collectstatic_bg.ansible_job_id }}
register: job_result
until: job_result.finished
retries: 80
delay: 15
################################################################################
#
# PUT TASKS AFTER THIS THAT CAN'T RUN UNTIL COLLECTSTATIC IS DONE
#
################################################################################

2.2 Blocks
• Blocks doc
• A blog post about blocks
• Blog post with examples
• Complete list of possible keywords
Blocks can be used anywhere a task can (mostly?). They allow applying task keys to a group of tasks without having
to repeat them over and over. They also provide a form of error handling.
Syntax:
block:
- <task1>
- <task2>
(continues on next page)

8

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

when: <condition>
become: true
become_user: <username>
....
[rescue:
- debug: msg="This task runs if there's an error in the block"
- <task2>
...
always:
- debug: msg="I always run"
... more tasks ..
]

2.3 Conditionals, return values, and registered variables
Ansible conditionals doc

2.3.1 Conditional tasks
See Task.

2.4 Return Values and registered variables
To create a variable with results from a task, use register:
- name: any task
command: whatever
register: varname

Then in later tasks, you can use varname in conditionals like when.
The variable is actually an object with lots of useful items in it. Some of them:
• .changed - boolean, whether the task changed anything
• .failed - boolean, true if the task failed
• .skipped - boolean, true if the task was skipped
• .result - ? (depends on the task?)
• .results - If this key exists, it indicates that a loop was present for the task and that it contains a list of the
normal module ‘result’ per item.
more on common return values.
There are also useful filters:
• is succeeded - boolean, true if task succeeded
• is failed - boolean, true if task failed
• is skipped = boolean, true if the task was skipped
succeeded is probably the most useful here - the others just duplicate attributes.

2.3. Conditionals, return values, and registered variables

9

Dan’s Cheat Sheets Documentation, Release 1

2.5 Configuration
2.5.1 Configuration file
Syntax .ini file
See The Ansible Configuration File doc.
Ansible uses the first config file it finds on this list:
• ANSIBLE_CONFIG (an environment variable)
• ansible.cfg (in the current directory)
• .ansible.cfg (in the home directory)
• /etc/ansible/ansible.cfg
Some useful vars in the [defaults] section:
any_errors_fatal
If true, stop immediately if any task fails. Default value of False only stops for the host that failed. The playbook
invocation will eventually report failure, but the error itself might be thousands of lines back in the output. Recommend
changing this to True.
display_args_to_stdout
If true, more information displayed as tasks execute. Default: False.
error_on_undefined_vars
If true, task fails if any undefined vars are encountered, which seems like it ought to be the default behavior, but it’s
not.
hostfile
This is the default location of the inventory file, script, or directory that Ansible will use to determine what hosts it has
available to talk to:
hostfile = /etc/ansible/hosts
use_persistent_connections
Default False. Whether to use persistent connections. (Yes, this is in the defaults section.)
private_role_vars
Makes role variables inaccessible from other roles. This was introduced as a way to reset role variables to default
values if a role is used more than once in a playbook. Default: False

10

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

retry_files_enabled
Default true. If True, create .retry files on failure. These are generally useless so I change this to False to not clutter
up my file system with them.
roles_path
The roles path indicate additional directories beyond the ‘roles/’ subdirectory of a playbook project to search to find
Ansible roles. For instance, if there was a source control repository of common roles and a different repository of
playbooks, you might choose to establish a convention to checkout roles in /opt/mysite/roles like so:
roles_path = /opt/mysite/roles
Additional paths can be provided separated by colon characters, in the same way as other pathstrings:
roles_path = /opt/mysite/roles:/opt/othersite/roles
Roles will be first searched for in the playbook directory. Should a role not be found, it will indicate all the possible
paths that were searched.
Some useful vars in the [inventory] section:
any_unparsed_is_failed
Default false. If ‘true’, it is a fatal error when any given inventory source cannot be successfully parsed by any available
inventory plugin; otherwise, this situation only attracts a warning.
Some useful vars in the [ssh_connection] section:
pipelining
Pipelining, if supported by the connection plugin, reduces the number of network operations required to execute a
module on the remote server, by executing many Ansible modules without actual file transfer. This can result in a very
significant performance improvement when enabled. However this conflicts with privilege escalation (become). For
example, when using ‘sudo:’ operations you must first disable ‘requiretty’ in /etc/sudoers on all managed hosts, which
is why it is disabled by default.
scp_if_ssh
Preferred method to use when transferring files over ssh. When set to smart, Ansible will try them until one succeeds
or they all fail. If set to True, it will force ‘scp’, if False it will use ‘sftp’.
ssh_args
If set, this will override the Ansible default ssh arguments.In particular, users may wish to raise the ControlPersist
time to encourage performance. A value of 30 minutes may be appropriate.Be aware that if -o ControlPath is set in
ssh_args, the control path setting is not used.

2.5. Configuration

11

Dan’s Cheat Sheets Documentation, Release 1

Warning: If you set this, the default setting is completely overridden, so you should include it (possibly edited):
-C -o ControlMaster=auto -o ControlPersist=60s
Example:
ssh_args = -C -o ControlMaster=auto -o ControlPersist=300s -o ForwardAgent=yes -o
˓→ControlPath=./ansible_ssh_conn_%h

2.6 Host Patterns
See ansible host patterns doc for host patterns.
<hosts>:
“all” = all hosts in inventory file “*” = all hosts in inventory file “~<regex>” = use regex syntax
for this pattern “<pattern1>:<pattern2>” = include all hosts that match pattern1 OR pattern2 “<pattern1>:&<pattern2>” = include all hosts that match pattern1 AND pattern2 “<pattern1>:!<pattern2>”
= include all hosts that match pattern1 but NOT pattern2

2.7 Inventory
2.7.1 Inventory directory
Whatever directory the Inventory file is in.

2.7.2 Inventory file
Default /etc/ansible/hosts
Change set ANSIBLE_HOSTS in environment
ansible-playbook -i <inventoryfile> ...
set hostfile in configuration
Syntax .ini file, except initial lines don’t need to be in a section
The inventory file is basically a list of hostnames or IP addresses, one per line.
hostname:port or address:port.

Can include port with

Ranges: Including [m:n] in a line will repeat the line for every value from m through n. m and n can be numbers or
letters:
[mygroup]
host[1:25]

Host Pre-defined variables: Can specify per-host options after hostname on the same line. E.g.:
jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50

See also Variables files.
Group Pre-defined variables: add [groupname:vars] section and put var definitions in it, one per line. Example:

12

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

[all:vars]
project_name="PeterPan"
environment_name=staging

See also Variables files.
Groups of groups: add [newgroupname:children] and put other group names in it, one per line:
[group3]
host13
host14
[group3:children]
group1
group2
[group3:vars]
group3_var1=27
group3_var2="Hello, World"

2.8 Invoking
2.8.1 Ad-hoc
To run an ad-hoc command, use ansible. (But you almost always will want to run a playbook; see below.)
Examples of ad-hoc commands:
$
#
$
#
$
#
$
$

ansible all -m ping
as bruce
ansible all -m ping -u bruce
as bruce, sudoing to root
ansible all -m ping -u bruce --sudo
as bruce, sudoing to batman
ansible all -m ping -u bruce --sdo --sudo-user batman
ansible all -a "/bin/echo hello"

Help:
Usage: ansible <host-pattern> [options]
Options:
-a MODULE_ARGS, --args=MODULE_ARGS
module arguments
-k, --ask-pass
ask for SSH password
--ask-su-pass
ask for su password
-K, --ask-sudo-pass
ask for sudo password
--ask-vault-pass
ask for vault password
-B SECONDS, --background=SECONDS
run asynchronously, failing after X seconds
(default=N/A)
-C, --check
don't make any changes; instead, try to predict some
of the changes that may occur
-c CONNECTION, --connection=CONNECTION
connection type to use (default=smart)
(continues on next page)

2.8. Invoking

13

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

-f FORKS, --forks=FORKS
specify number of parallel processes to use
(default=5)
-h, --help
show this help message and exit
-i INVENTORY, --inventory-file=INVENTORY
specify inventory host file
(default=/etc/ansible/hosts)
-l SUBSET, --limit=SUBSET
further limit selected hosts to an additional pattern
--list-hosts
outputs a list of matching hosts; does not execute
anything else
-m MODULE_NAME, --module-name=MODULE_NAME
module name to execute (default=command)
-M MODULE_PATH, --module-path=MODULE_PATH
specify path(s) to module library
(default=/usr/share/ansible/)
-o, --one-line
condense output
-P POLL_INTERVAL, --poll=POLL_INTERVAL
set the poll interval if using -B (default=15)
--private-key=PRIVATE_KEY_FILE
use this file to authenticate the connection
-S, --su
run operations with su
-R SU_USER, --su-user=SU_USER
run operations with su as this user (default=root)
-s, --sudo
run operations with sudo (nopasswd)
-U SUDO_USER, --sudo-user=SUDO_USER
desired sudo user (default=root)
-T TIMEOUT, --timeout=TIMEOUT
override the SSH timeout in seconds (default=10)
-t TREE, --tree=TREE log output to this directory
-u REMOTE_USER, --user=REMOTE_USER
connect as this user (default=poirier)
--vault-password-file=VAULT_PASSWORD_FILE
vault password file
-v, --verbose
verbose mode (-vvv for more, -vvvv to enable
connection debugging)
--version
show program's version number and exit

2.8.2 Playbooks
To run a playbook, use ansible-playbook. Here’s the help from 2.0.1.0:
Usage: ansible-playbook playbook.yml
Options:
--ask-become-pass
ask for privilege escalation password
-k, --ask-pass
ask for connection password
--ask-su-pass
ask for su password (deprecated, use become)
-K, --ask-sudo-pass
ask for sudo password (deprecated, use become)
--ask-vault-pass
ask for vault password
-b, --become
run operations with become (nopasswd implied)
--become-method=BECOME_METHOD
privilege escalation method to use (default=sudo),
valid choices: [ sudo | su | pbrun | pfexec | runas |
doas ]
(continues on next page)

14

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

--become-user=BECOME_USER
run operations as this user (default=root)
-C, --check
don't make any changes; instead, try to predict some
of the changes that may occur
-c CONNECTION, --connection=CONNECTION
connection type to use (default=smart)
-D, --diff
when changing (small) files and templates, show the
differences in those files; works great with --check
-e EXTRA_VARS, --extra-vars=EXTRA_VARS
set additional variables as key=value or YAML/JSON
--flush-cache
clear the fact cache
--force-handlers
run handlers even if a task fails
-f FORKS, --forks=FORKS
specify number of parallel processes to use
(default=5)
-h, --help
show this help message and exit
-i INVENTORY, --inventory-file=INVENTORY
specify inventory host path
(default=/etc/ansible/hosts) or comma separated host
list.
-l SUBSET, --limit=SUBSET
further limit selected hosts to an additional pattern
--list-hosts
outputs a list of matching hosts; does not execute
anything else
--list-tags
list all available tags
--list-tasks
list all tasks that would be executed
-M MODULE_PATH, --module-path=MODULE_PATH
specify path(s) to module library (default=None)
--new-vault-password-file=NEW_VAULT_PASSWORD_FILE
new vault password file for rekey
--output=OUTPUT_FILE output file name for encrypt or decrypt; use - for
stdout
--private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE
use this file to authenticate the connection
--scp-extra-args=SCP_EXTRA_ARGS
specify extra arguments to pass to scp only (e.g. -l)
--sftp-extra-args=SFTP_EXTRA_ARGS
specify extra arguments to pass to sftp only (e.g. -f,
-l)
--skip-tags=SKIP_TAGS
only run plays and tasks whose tags do not match these
values
--ssh-common-args=SSH_COMMON_ARGS
specify common arguments to pass to sftp/scp/ssh (e.g.
ProxyCommand)
--ssh-extra-args=SSH_EXTRA_ARGS
specify extra arguments to pass to ssh only (e.g. -R)
--start-at-task=START_AT_TASK
start the playbook at the task matching this name
--step
one-step-at-a-time: confirm each task before running
-S, --su
run operations with su (deprecated, use become)
-R SU_USER, --su-user=SU_USER
run operations with su as this user (default=root)
(deprecated, use become)
-s, --sudo
run operations with sudo (nopasswd) (deprecated, use
become)
-U SUDO_USER, --sudo-user=SUDO_USER
(continues on next page)

2.8. Invoking

15

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

desired sudo user (default=root) (deprecated, use
become)
--syntax-check
perform a syntax check on the playbook, but do not
execute it
-t TAGS, --tags=TAGS only run plays and tasks tagged with these values
-T TIMEOUT, --timeout=TIMEOUT
override the connection timeout in seconds
(default=10)
-u REMOTE_USER, --user=REMOTE_USER
connect as this user (default=None)
--vault-password-file=VAULT_PASSWORD_FILE
vault password file
-v, --verbose
verbose mode (-vvv for more, -vvvv to enable
connection debugging)
--version
show program's version number and exit

2.8.3 Hosts pulling config
Ansible-pull (ansible-pull doc) is a small script that will checkout a repo of configuration instructions from git, and
then run ansible-playbook against that content.
Assuming you load balance your checkout location, ansible-pull scales essentially infinitely.
Help from ansible-pull 2.0.1.0:
Usage: ansible-pull -U <repository> [options]
Options:
--accept-host-key
adds the hostkey for the repo url if not already added
--ask-become-pass
ask for privilege escalation password
-k, --ask-pass
ask for connection password
--ask-su-pass
ask for su password (deprecated, use become)
-K, --ask-sudo-pass
ask for sudo password (deprecated, use become)
--ask-vault-pass
ask for vault password
-C CHECKOUT, --checkout=CHECKOUT
branch/tag/commit to checkout. Defaults to behavior
of repository module.
-c CONNECTION, --connection=CONNECTION
connection type to use (default=smart)
-d DEST, --directory=DEST
directory to checkout repository to
-e EXTRA_VARS, --extra-vars=EXTRA_VARS
set additional variables as key=value or YAML/JSON
-f, --force
run the playbook even if the repository could not be
updated
--full
Do a full clone, instead of a shallow one.
-h, --help
show this help message and exit
-i INVENTORY, --inventory-file=INVENTORY
specify inventory host path
(default=/etc/ansible/hosts) or comma separated host
list.
-l SUBSET, --limit=SUBSET
further limit selected hosts to an additional pattern
--list-hosts
outputs a list of matching hosts; does not execute
anything else
-m MODULE_NAME, --module-name=MODULE_NAME
(continues on next page)

16

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

Repository module name, which ansible will use to
check out the repo. Default is git.
-M MODULE_PATH, --module-path=MODULE_PATH
specify path(s) to module library (default=None)
--new-vault-password-file=NEW_VAULT_PASSWORD_FILE
new vault password file for rekey
-o, --only-if-changed
only run the playbook if the repository has been
updated
--output=OUTPUT_FILE output file name for encrypt or decrypt; use - for
stdout
--private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE
use this file to authenticate the connection
--purge
purge checkout after playbook run
--scp-extra-args=SCP_EXTRA_ARGS
specify extra arguments to pass to scp only (e.g. -l)
--sftp-extra-args=SFTP_EXTRA_ARGS
specify extra arguments to pass to sftp only (e.g. -f,
-l)
--skip-tags=SKIP_TAGS
only run plays and tasks whose tags do not match these
values
-s SLEEP, --sleep=SLEEP
sleep for random interval (between 0 and n number of
seconds) before starting. This is a useful way to
disperse git requests
--ssh-common-args=SSH_COMMON_ARGS
specify common arguments to pass to sftp/scp/ssh (e.g.
ProxyCommand)
--ssh-extra-args=SSH_EXTRA_ARGS
specify extra arguments to pass to ssh only (e.g. -R)
-t TAGS, --tags=TAGS only run plays and tasks tagged with these values
-T TIMEOUT, --timeout=TIMEOUT
override the connection timeout in seconds
(default=10)
-U URL, --url=URL
URL of the playbook repository
-u REMOTE_USER, --user=REMOTE_USER
connect as this user (default=None)
--vault-password-file=VAULT_PASSWORD_FILE
vault password file
-v, --verbose
verbose mode (-vvv for more, -vvvv to enable
connection debugging)
--verify-commit
verify GPG signature of checked out commit, if it
fails abort running the playbook. This needs the
corresponding VCS module to support such an operation
--version
show program's version number and exit

2.9 Loops
See http://docs.ansible.com/playbooks_loops.html

2.9.1 Iterating with nested loops
Write a task:
2.9. Loops

17

Dan’s Cheat Sheets Documentation, Release 1

- module: args
with_subelements:
- thelist
- fieldname

Then Ansible will essentially do this:
for thing in thelist:
item.0 = thing
for fieldvalue in get(thing, fieldname):
item.1 = fieldvalue
EXECUTE (module, args)

In other words, it’ll iterate over the first value as a list, call it item.0, then get the list from that value’s field named
‘fieldname’, and iterate over that as well, calling it item.1.
Presumably you could nest this deeper.
Example from the docs. With variables:
--users:
- name: alice
authorized:
- /tmp/alice/onekey.pub
- /tmp/alice/twokey.pub
- name: bob
authorized:
- /tmp/bob/id_rsa.pub

You can write tasks:
- user: name={{ item.name }} state=present generate_ssh_key=yes
with_items: "{{users}}"
- authorized_key: "user={{ item.0.name }} key='{{ lookup('file', item.1) }}'"
with_subelements:
- users
- authorized

2.10 Playbook
2.10.1 Playbook directory
Default current dir

2.10.2 Playbook
Syntax A YAML file defining a list of Play s and Playbook include s:
-

18

<play>
<play>
include: <path to playbook>
include: <path to playbook>

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

Templating A playbook is rendered as a Jinja2 template (using variables in playbooks doc) before processing it, but
playbooks should not use loops and conditionals.

2.10.3 Playbook include
A playbook can include other playbooks:
- include: <path to playbook>

Note that, unlike Task include s, playbook includes cannot set variables.

2.10.4 Play
Complete list of possible keys
A dictionary:
hosts: hosta:pattern1:pattern2
# required
vars:
var1: value1
var2: value2
roles:
- <rolename1>
- {role: <rolename2>, var1: value1, tags: ['tag1', 'tag2']}
- role: <rolename3>
var1: value1
var2: value2
tags:
- tag1
- tag2
tags:
- <tag1>
- <tag2>
remote_user: username
sudo: yes|no
sudo_user: username
tasks:
- <task>
- include: <taskfile>
- include: <taskfile2>
tags: [tag1, tag2]
- <task>
handlers:
- <task>
- include: <taskfile>
- <task>
notify:
- <handler name>
- <handler name>
vars_files:
- <path to external variables file>
- [<path1>, <path2>, ...]
(ansible loads the first one found)
- <path to external variables file>
strategy: linear|free
serial: <number>|"<number>%"

2.10. Playbook

19

Dan’s Cheat Sheets Documentation, Release 1

Required keys:
hosts A string, containing one or more Host Patterns s separated by colons
Optional keys:
handlers list of Handler s and Task include s.
pre_tasks list of Task s and Task include s. These are executed before roles.
roles list of names of Role s to include in the play. You can add parameters, tags, and conditionals:
roles:
- common
- { role: foo_app_instance, dir: '/opt/a', tags: ["bar", "baz"] }
- { role: foo_app_instance, dir: '/opt/b', when: "ansible_os_family == 'RedHat'
˓→" }

serial Set how many hosts at a time to run at a time. The default is to run tasks on all of a play’s machines at once.
See also strategy.
strategy How plays are run on multiple hosts. The default is “linear”, where each task is run on up to serial hosts in
parallel, and then Ansible waits for them all to complete before starting the next task on all the hosts.
“free” lets each host run independently, starting its next task as soon as it finishes the previous one, regardless
of how far other hosts have gotten.
tags see Tags.
tasks list of Task s and Task include s. These are executed after the roles.
post_tasks list of Task s and Task include s. These are executed after the tasks.
notify list of names of Handler s to trigger when done, but only if something changed
vars A dictionary defining additional Pre-defined variables
remote_user user to login as remotely
sudo yes|no
sudo_user user to sudo to remotely

2.10.5 Running a playbook
ansible-playbook <filepath of playbook> [options]
ansible-playbook playbook.yml –start-at=”install packages” The above will start executing your playbook at a
task named “install packages”.
ansible-playbook playbook.yml –step This will cause ansible to stop on each task, and ask if it should execute that
task.

2.11 Roles
2.11.1 Role
A role is a directory with specified contents. The role directory must be in one of the directories on the roles_path and
its name is used to refer to the role elsewhere.
Complete list of possible keywords
20

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

Inside the role’s top-level directory, you might see a tree like this (most of this is optional).
defaults/main.yml variables within will be defined at the lowest priority (can be overridden by variables declared
anywhere else, even inventory variables)
files/ Any copy tasks can reference files in roles/x/files/ without having to path them relatively or absolutely
Any script tasks can reference scripts in roles/x/files/ without having to path them relatively or absolutely
handlers/main.yml handlers listed therein will be added to the play
library/ modules here (directories) will be available in the role, and any roles called after this role
meta/main.yml Role dependencies file
tasks/main.yml Tasks file
Any include tasks can reference files in roles/x/tasks/ without having to path them relatively or absolutely
templates/ Any template tasks can reference files in roles/x/templates/ without having to path them relatively or
absolutely
vars/main.yml variables listed therein will be added to the play. These override almost any other variables except
those on the command line, so this is really better for the role’s “constants” than variables :-)

2.11.2 Role dependencies file
Syntax YAML file
Templating Jinja2
Contents A dictionary
The role dependencies file defines what other roles this role depends on.
Keys:
dependencies A list of Dependency dictionary s
allow-duplicates yes|no
Defaults to no, preventing the same role from being listed as a dependency more than once. Set to yes if you
want to list the same role with different variables.
Example:
--dependencies:
- role: role1
- role: role2
varname: value

2.11.3 Dependency dictionary
Required keys:
role
name of role, or quoted path to role file, or quoted repo URL:

2.11. Roles

21

Dan’s Cheat Sheets Documentation, Release 1

role: postgres
role: ‘/path/to/common/roles/foo’
role: ‘git+http://git.example.com/repos/role-foo,v1.1,foo’
role: ‘/path/to/tar/file.tgz„friendly-name’
Optional keys: any parameters for the role - these define Pre-defined variables

2.11.4 Embedding modules in roles

2.12 Secrets
Ansible handles secrets using a feature called Vault.
Vault lets you encrypt any of your .yml files, but typically you’d apply it to files containing variable definitions, then
use the variables’ values as needed elsewhere.
Vault provides subcommands that let you encrypt a file in place, decrypt a file in place, edit a file that’s encrypted in
one step, etc.
When ansible is running your playbook or whatever, any time it comes across a .yml file that appears to be encrypted,
it will decrypt it (in memory) and use the decrypted contents, fairly transparently. You can have as many of your files
encrypted as you want.
However, all the encrypted files have to use the same password.

2.12.1 Providing the password to Ansible
1. Have Ansible prompt for it by passing --ask-vault-pass. Most secure, but inconvenient.
2. Put it plaintext in a well-protected file, and pass --vault-password-file <filename>. Most insecure,
but more convenient than the prompt.
3. Write a script or program that outputs the password on stdout, mark it executable, and pass that:
--vault-password-file <path-to-program>. This makes it possible to use a local system keychain or something, which might be more secure than the other options. Or worse. . .

2.12.2 Ways to use it
One approach I’ve used is to have a single encrypted secrets.yml file in my base directory containing all my secret
variables, and another file with very restrictive permissions (and outside of source control) containing my password,
then add these arguments when running ansible:
--extra-vars @secrets.yml --vault-password-file path/to/passfile

The advantage of that is that if I don’t need the secrets, I can leave all that off and Ansible will run fine. (As opposed
to having the encrypted file automatically read by Ansible every time.)
I’m not sure if that will scale, though.

22

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

2.12.3 Limitations
• This is symmetric encryption. In other words, anyone with the password can encrypt and decrypt a file.
• All the encrypted files must be encrypted using the same password.
• That means you have to protect the decrypting password (the only password) very carefully, and makes providing
it to Ansible awkward.
Links:
• Vault
• Not logging secrets
• How to upload encrypted file using ansible vault?
• Managing Secrets with Ansible Vault – The Missing Guide (Part 1 of 2)
• Managing Secrets with Ansible Vault – The Missing Guide (Part 2 of 2)

2.13 synchronize
The Ansible synchronize module gets its own page because it is a bitch.
(Update: apparently some of these bad behaviors were bugs in Ansible 2.0.0.x, but I’m keeping this page around for
history.)
Let me count the ways:
• By default, it tries to become locally the user you’ve specified using the become_user variable that you have
said you want to become remotely. [Apparently that was a bug in 2.0.0.x and works correctly in 1.9.x and
2.0.1+.]
• Then it does not try to remotely become the user you’ve specified; you have to hack it by setting rsync_path:
"sudo rsync". [I have not tried this again with 2.0.1+.]
• Unlike every other Ansible module, the owner and group options are booleans, not the names or numbers of
users and groups. If true, it’ll try to copy the owner of the local files, but if you want to specify the ownership of
the target files yourself, you’ll have to fix it afterward.
Here’s a working example:
- name: sync source from local directory
synchronize:
dest: "{{ source_dir }}"
src: "{{ local_project_dir }}/"
delete: yes
rsync_path: "sudo rsync" # Use sudo on the remote system
recursive: true
rsync_opts:
- "--exclude=.git"
- "--exclude=*.pyc"
become: no # stops synchronize trying to sudo locally

NOTE: Ansible 2.0.1 fixed numerous bugs in synchronize:
• Fixes a major compatibility break in the synchronize module shipped with 2.0.0.x. That version of synchronize
ran sudo on the controller prior to running rsync. In 1.9.x and previous, sudo was run on the host that rsync
connected to. 2.0.1 restores the 1.9.x behaviour.

2.13. synchronize

23

Dan’s Cheat Sheets Documentation, Release 1

• Additionally, several other problems with where synchronize chose to run when combined with delegate_to were
fixed. In particular, if a playbook targetted localhost and then delegated_to a remote host the prior behavior (in
1.9.x and 2.0.0.x) was to copy files between the src and destination directories on the delegated host. This has
now been fixed to copy between localhost and the delegated host.
• Fix a regression where synchronize was unable to deal with unicode paths.
• Fix a regression where synchronize deals with inventory hosts that use localhost but with an alternate port.

2.14 Tags
When you apply tags to things, you can then control whether they’re executed by adding command line options.

2.14.1 How to tag things
Plays and tasks have optional tags attributes where you can specify a list of tags. Here are some tagged Task s:
tasks:
- module: parm1=a parm2=b
tags:
- packages
- module2: parm1=x parm2=y
tags:
- configuration

And here’s a playbook with some tagged Play s:
- hosts: all
tags:
- foo
- bar
roles:
- role1
- role2

You can also apply tags when invoking a role from a playbook:
roles:
- { role: webserver, port: 5000, tags: [ 'web', 'foo' ] }

and when including tasks:
- include: foo.yml
tags: [web,foo]

2.14.2 What tags do
Adding a tag to a play or task says that if ansible is invoked with --tags=x,y,z, that the tagged play or task will
only be executed if at least one of its tags is included in the list of tags from the command line.
Specifying --tags=all is equivalent to the default behavior, where all playbooks and tasks are run regardless of
their tags.

24

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

Specifying --tags=tagged runs only things that have some tag, while --tags=untagged runs only things that
have no tag.
You could alternatively invoke ansible with --skip-tags=a,b,c and it will execute all plays and tasks that are
not tagged with a, b, or c.
Presumably --skip-tags=tagged does the opposite of --tags=tagged, and --skip-tags=untagged
does the opposite of --tags=untagged.
If a play or task is tagged always, then it will be executed unless ansible is invoked with skip-tags=always.

2.15 Task
2.15.1 Tasks file
Syntax YAML FILE
Templating Jinja2
Content A list of task definitions, task includes, and Blocks.

2.15.2 Task include
Anywhere there can be a task definition, you can also use a task include:
- include: <path to tasks file> [options]

The path is relative to the Playbook directory, or the file is also searched for in the tasks directory of a role.
[options] is an optional list of additional variable settings, e.g.:
- include: tasks/footasks.yml vara=1 varb=2 varc=3

You can use an expanded syntax with a vars setting to set more complicated values:
- include: wordpress.yml
vars:
wp_user: timmy
some_list_variable:
- alpha
- beta
- gamma

Or use this more compact but apparently equivalent syntax:
- { include: wordpress.yml, wp_user: timmy, ssh_keys: [ 'keys/one.txt', 'keys/two.txt
˓→' ] }

2.15.3 Task
ansible tasks doc, complete list of possible keywords
A dictionary:

2.15. Task

25

Dan’s Cheat Sheets Documentation, Release 1

name: string
# optional but highly recommended
module: args
# required; the "action"
environment: dictionary
remote_user: username
sudo: yes|no
sudo_user: username
otheroption: othervalue
# depending on module
tags:
- <tag1>
- <tag2>

Required keys:
name text
modulename options
Optional keys that can be used on any task:
environment dictionary (in YAML, or variable containing dictionary)
ignore_errors if true, continue even if task fails
register <varname> store result of task in <varname>. See also when for some ways to use.
remote_user user to login as remotely
sudo yes|no
sudo_user user to sudo to remotely
tags list of tags to associate with the task
when expression controls whether task is executed ansible when doc:
when: <varname>
when: not <varname>

Special filters for checking result of a prior task:
when: <varname>|failed
when: <varname>|skipped
when: <varname>|success

Additional keys might be required and optional depending on the module being used.

2.15.4 Handler
Same syntax as a Task, it just gets triggered under different circumstances.

2.16 Variables
2.16.1 Pre-defined variables
Ansible defines some variables for you
These are not mentioned when you list Facts (see below) - go figure.

26

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

inventory_hostname is the name of the current host as you’ve configured it in your Ansible inventory file,
regardless of the system’s actual hostname.
If you have a long FQDN, inventory_hostname_short also contains the part up to the first period, without the
rest of the domain.

2.16.2 Variables
Some variables alter the behavior of ansible (see http://docs.ansible.com/intro_inventory.html#
list-of-behavioral-inventory-parameters for a list). You can set some of these using environment variables
(ansible variables doc).
CORRECTION: Use ansible_ssh_user, not ansible_user.
Any of them can be used anywhere Jinja2 templating is in effect.
Places to define variables:
• inventory
• playbook
• included files and roles
• local facts
• ansible command line (--extra-vars "foo=1 bar=2" or --extra-vars @filepath.json or
--extra-vars @filepath.yml)
See also “Variable Precedence”, a little farther down. . .

2.16.3 Variables file
A variables file (doc) is a file that defines values of Pre-defined variables.
Syntax YAML defining a single dictionary
Templating The file does not appear to undergo template expansion, but the values of variables do??

2.16.4 Variables files
Ansible will look in Inventory directory and Playbook directory for directories named host_vars or group_vars.
Inside those directories, you can put a single Variables file with the same name as a host or group (respectively) and
Ansible will use those Pre-defined variables definitions.
Or a file named all that will be used for all hosts or groups.
Or you can create a directory with the same name as a host or group and Ansible will use all the files in that directory
as Variables file s.
You can also include vars files from a Play (ansible variable files doc).

2.16.5 Variable precedence
docs
From 2.0 on, from lowest priority to highest - in other words, if a variable is defined in two places, the place that’s
farther down in this list takes precedence.

2.16. Variables

27

Dan’s Cheat Sheets Documentation, Release 1

• role defaults [1]
• inventory file or script group vars [2]
• inventory group_vars/all [3]
• playbook group_vars/all [3]
• inventory group_vars/* [3]
• playbook group_vars/* [3]
• inventory file or script host vars [2]
• inventory host_vars/*
• playbook host_vars/*
• host facts / cached set_facts [4]
• inventory host_vars/* [3]
• playbook host_vars/* [3]
• host facts
• play vars
• play vars_prompt
• play vars_files
• role vars (defined in role/vars/main.yml)
• block vars (only for tasks in block)
• task vars (only for the task)
• include_vars
• set_facts / registered vars
• role (and include_role) params
• include params
• extra vars (defined on command line with -e, always win precedence)
[1] Tasks in each role will see their own role’s defaults. Tasks defined outside of a role will see the last role’s defaults.
[2] (1, 2) Variables defined in inventory file or provided by dynamic inventory. [3] (1, 2, 3, 4, 5, 6) Includes vars added
by ‘vars plugins’ as well as host_vars and group_vars which are added by the default vars plugin shipped with Ansible.
[4] When created with set_facts’s cacheable option, variables will have the high precedence in the play, but will be the
same as a host facts precedence when they come from the cache.

2.16.6 Facts
Ansible automatically defines a whole bunch of variables with information about the system that it’s running on (the
system the plays and tasks are running on, not the system you’re controlling ansible from).
You can add to the facts with config files called local facts (ansible local facts doc) though I don’t know how that’s any
better than putting variables in all the other places you can set them. . .
To see a list of all of the facts that are available about a machine, you can run the “setup” module as an ad-hoc action:
ansible -m setup hostname

28

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

This will print out a dictionary of all of the facts that are available for that particular host.
Facts output is an example from one of my machines.
The Ansible docs used to show an example of this output, but apparently they’ve removed or moved that. And here’s
an example.
The top of the output will look like:
staging-web2 | SUCCESS => {
"ansible_facts": {
"ansible_all_ipv4_addresses": [
"10.132.77.14",
"138.197.111.207",
"10.17.0.12"
],
"ansible_all_ipv6_addresses": [

Ignore the "ansible_facts" part of that. To reference any of these variable, start with the next level. E.g. {{
ansible_all_ipv4_addresses[1] }}.
ALTERNATIVELY, you can access the same variables as items in the ansible_facts dictionary, only without
the individual keys prefixed by ansible_ (or so the docs say https://docs.ansible.com/ansible/latest/reference_
appendices/config.html#inject-facts-as-vars) and this should work even if INJECT_FACTS_AS_VARS has been set
False).

2.17 Ansible Galaxy
2.17.1 Links
• Galaxy doc
• popular galaxy roles and recent activity
• search galaxy

2.17.2 Role specification
Format when installing roles from galaxy:
• username.rolename[,version]
• scm+repo_url[,version]
• tarball_url
Versions represent tags in the role’s source repository.
E.g.:
user2.role2
user1.role1,v1.0.0
user1.role2,master
git+http://bitbucket.org/willthames/git-ansible-galaxy
https://some.webserver.example.com/files/master.tar.gz

2.17. Ansible Galaxy

29

Dan’s Cheat Sheets Documentation, Release 1

2.17.3 Ways of installing
Command-line
List roles on the command line:
ansible-galaxy install user2.role2 user1.role1,v1.0.9

Simple file
List roles in a file, one per line. Example file:
# file: roles.txt
user2.role2
user1.role1,v1.0.0

And install with -r:
ansible-galaxy install -r roles.txt

YAML file
Use a YAML file to provide more control. The YAML file should contain a list of dictionaries. Each dictionary
specifies a role to install. Keys can include:
src (required) a role specification as above. (Since there’s a separate dictionary key for version, I don’t know
whether you can include version here, or if you’re required to list it separately as version.)
path Where to install (directory, can be relative)
version version to install. e.g. master or v1.4.
name install as a different name
scm default git but could say hg and then in src provide a URL to a mercurial repository.
Example:
# install_roles.yml
# from galaxy
- src: yatesr.timezone
# from github
- src: https://github.com/bennojoy/nginx
# from github installing to a relative path
- src: https://github.com/bennojoy/nginx
path: vagrant/roles/
# from github, overriding the name and specifying a specific tag
- src: https://github.com/bennojoy/nginx
version: master
name: nginx_role
# from a webserver, where the role is packaged in a tar.gz
(continues on next page)

30

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

- src: https://some.webserver.example.com/files/master.tar.gz
name: http-role
# from bitbucket, if bitbucket happens to be operational right now :)
- src: git+http://bitbucket.org/willthames/git-ansible-galaxy
version: v1.4
# from bitbucket, alternative syntax and caveats
- src: http://bitbucket.org/willthames/hg-ansible-galaxy
scm: hg

And again install with -r:
ansible-galaxy install -r install_roles.yml

2.18 Facts output
Example output of ‘ansible moth -m setup’ (abridged):
moth | SUCCESS => {
"ansible_facts": {
"ansible_all_ipv4_addresses": [
"172.26.163.45",
"10.28.4.5"
],
"ansible_all_ipv6_addresses": [
"fcae:c8f4:7d93:35ee:162::1",
"fe80::b0f5:3cff:fe75:cff0",
"fe80::33e1:2:9db5:7dc0"
],
"ansible_apparmor": {
"status": "enabled"
},
"ansible_architecture": "x86_64",
"ansible_bios_date": "05/17/2016",
"ansible_bios_version": "G6ETB4WW (2.74 )",
"ansible_cmdline": {
"BOOT_IMAGE": "/boot/vmlinuz-4.15.0-38-generic",
"ro": true,
"root": "UUID=cd980b7e-8c51-4b68-9a36-25bacd7d5ebf"
},
"ansible_date_time": {
"date": "2019-01-11",
"day": "11",
"epoch": "1547232398",
"hour": "13",
"iso8601": "2019-01-11T18:46:38Z",
"iso8601_basic": "20190111T134638560137",
"iso8601_basic_short": "20190111T134638",
"iso8601_micro": "2019-01-11T18:46:38.560229Z",
"minute": "46",
"month": "01",
"second": "38",
"time": "13:46:38",
(continues on next page)

2.18. Facts output

31

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"tz": "EST",
"tz_offset": "-0500",
"weekday": "Friday",
"weekday_number": "5",
"weeknumber": "01",
"year": "2019"
},
"ansible_default_ipv4": {
"address": "10.28.4.5",
"alias": "wlp3s0",
"broadcast": "10.28.4.255",
"gateway": "10.28.4.1",
"interface": "wlp3s0",
"macaddress": "84:3a:4b:73:6c:f8",
"mtu": 1500,
"netmask": "255.255.255.0",
"network": "10.28.4.0",
"type": "ether"
},
"ansible_default_ipv6": {},
"ansible_device_links": {
"ids": {
"sda": [
"ata-SanDisk_SD5SG2256G1052E_124928400505",
"wwn-0x5001b44821e51879"
],
"sda1": [
"ata-SanDisk_SD5SG2256G1052E_124928400505-part1",
"wwn-0x5001b44821e51879-part1"
]
},
"labels": {},
"masters": {},
"uuids": {
"sda1": [
"cd980b7e-8c51-4b68-9a36-25bacd7d5ebf"
]
}
},
"ansible_devices": {
"loop0": {
"holders": [],
"host": "",
"links": {
"ids": [],
"labels": [],
"masters": [],
"uuids": []
},
"model": null,
"partitions": {},
"removable": "0",
"rotational": "1",
"sas_address": null,
"sas_device_handle": null,
"scheduler_mode": "none",
"sectors": "693784",
(continues on next page)

32

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"sectorsize": "512",
"size": "338.76 MB",
"support_discard": "4096",
"vendor": null,
"virtual": 1
},
...
"sda": {
"holders": [],
"host": "SATA controller: Intel Corporation 7 Series Chipset Family 6˓→port SATA Controller [AHCI mode] (rev 04)",
"links": {
"ids": [
"ata-SanDisk_SD5SG2256G1052E_124928400505",
"wwn-0x5001b44821e51879"
],
"labels": [],
"masters": [],
"uuids": []
},
"model": "SanDisk SD5SG225",
"partitions": {
"sda1": {
"holders": [],
"links": {
"ids": [
"ata-SanDisk_SD5SG2256G1052E_124928400505-part1",
"wwn-0x5001b44821e51879-part1"
],
"labels": [],
"masters": [],
"uuids": [
"cd980b7e-8c51-4b68-9a36-25bacd7d5ebf"
]
},
"sectors": "500115456",
"sectorsize": 512,
"size": "238.47 GB",
"start": "2048",
"uuid": "cd980b7e-8c51-4b68-9a36-25bacd7d5ebf"
}
},
"removable": "0",
"rotational": "0",
"sas_address": null,
"sas_device_handle": null,
"scheduler_mode": "cfq",
"sectors": "500118192",
"sectorsize": "512",
"size": "238.47 GB",
"support_discard": "512",
"vendor": "ATA",
"virtual": 1,
"wwn": "0x5001b44821e51879"
}
},
"ansible_distribution": "Ubuntu",
(continues on next page)

2.18. Facts output

33

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"ansible_distribution_file_parsed": true,
"ansible_distribution_file_path": "/etc/os-release",
"ansible_distribution_file_variety": "Debian",
"ansible_distribution_major_version": "18",
"ansible_distribution_release": "bionic",
"ansible_distribution_version": "18.04",
"ansible_dns": {
"nameservers": [
"127.0.0.53"
],
"search": [
"mynet"
]
},
"ansible_domain": "zero",
"ansible_effective_group_id": 1000,
"ansible_effective_user_id": 1000,
"ansible_env": {
"BASH_ENV": "/home/poirier/dotfiles/bash/.bashenvrc",
"DBUS_SESSION_BUS_ADDRESS": "unix:path=/run/user/1000/bus",
"HOME": "/home/poirier",
"LANG": "en_US.UTF-8",
"LOGNAME": "poirier",
"MAIL": "/var/mail/poirier",
"PATH": "/home/poirier/.pyenv/plugins/pyenv-virtualenv/shims:/home/
˓→poirier/.pyenv/shims:/home/poirier/.pyenv/bin:/home/poirier/.pyenv/plugins/pyenv˓→virtualenv/shims:/home/poirier/.pyenv/shims:/home/poirier/.pyenv/bin:/usr/local/
˓→sbin:/usr/local/bin:/home/poirier/.local/bin:/home/poirier/.yarn/bin:/home/poirier/
˓→bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games",
"PWD": "/home/poirier",
"PYENV_ROOT": "/home/poirier/.pyenv",
"PYENV_SHELL": "bash",
"PYENV_VIRTUALENV_INIT": "1",
"SHELL": "/bin/bash",
"SHLVL": "1",
"SSH_AUTH_SOCK": "/tmp/ssh-pH3QNOurzC/agent.26808",
"SSH_CLIENT": "127.0.0.1 33550 22",
"SSH_CONNECTION": "127.0.0.1 33550 127.0.0.1 22",
"TZ": "America/New_York",
"USER": "poirier",
"XDG_RUNTIME_DIR": "/run/user/1000",
"XDG_SESSION_ID": "11860",
"_": "/bin/sh"
},
"ansible_fips": false,
"ansible_form_factor": "Notebook",
"ansible_fqdn": "moth.zero",
"ansible_hostname": "moth",
"ansible_interfaces": [
"zt7nnjxkbi",
"wlp3s0",
"wwp0s20u4i6",
"lo"
],
"ansible_is_chroot": false,
"ansible_iscsi_iqn": "",
"ansible_kernel": "4.15.0-38-generic",
(continues on next page)

34

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"ansible_lo": {
"active": true,
"device": "lo",
"ipv4": {
"address": "127.0.0.1",
"broadcast": "host",
"netmask": "255.0.0.0",
"network": "127.0.0.0"
},
"ipv6": [
{
"address": "::1",
"prefix": "128",
"scope": "host"
}
],
"mtu": 65536,
"promisc": false,
"type": "loopback"
},
"ansible_local": {},
"ansible_lsb": {
"codename": "bionic",
"description": "Ubuntu 18.04.1 LTS",
"id": "Ubuntu",
"major_release": "18",
"release": "18.04"
},
"ansible_machine": "x86_64",
"ansible_machine_id": "d3e0714b1ee94fbd8512d59db7d1cf3f",
"ansible_memfree_mb": 145,
"ansible_memory_mb": {
"nocache": {
"free": 1830,
"used": 5847
},
"real": {
"free": 145,
"total": 7677,
"used": 7532
},
"swap": {
"cached": 32,
"free": 7397,
"total": 7629,
"used": 232
}
},
"ansible_memtotal_mb": 7677,
"ansible_mounts": [
{
"block_available": 16474502,
"block_size": 4096,
"block_total": 61271111,
"block_used": 44796609,
"device": "/dev/sda1",
"fstype": "ext4",
(continues on next page)

2.18. Facts output

35

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"inode_available": 14238018,
"inode_total": 15630336,
"inode_used": 1392318,
"mount": "/",
"options": "rw,relatime,errors=remount-ro,data=ordered",
"size_available": 67479560192,
"size_total": 250966470656,
"uuid": "cd980b7e-8c51-4b68-9a36-25bacd7d5ebf"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 116,
"block_used": 116,
"device": "/dev/loop1",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1721,
"inode_used": 1721,
"mount": "/snap/gnome-logs/43",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 15204352,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 116,
"block_used": 116,
"device": "/dev/loop2",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1720,
"inode_used": 1720,
"mount": "/snap/gnome-logs/40",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 15204352,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 104,
"block_used": 104,
"device": "/dev/loop5",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1598,
"inode_used": 1598,
"mount": "/snap/gnome-characters/139",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 13631488,
"uuid": "N/A"
},
(continues on next page)

36

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

{
"block_available": 0,
"block_size": 131072,
"block_total": 1116,
"block_used": 1116,
"device": "/dev/loop4",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 27651,
"inode_used": 27651,
"mount": "/snap/gnome-3-26-1604/64",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 146276352,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 18,
"block_used": 18,
"device": "/dev/loop8",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1269,
"inode_used": 1269,
"mount": "/snap/gnome-calculator/238",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 2359296,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 1128,
"block_used": 1128,
"device": "/dev/loop6",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 27638,
"inode_used": 27638,
"mount": "/snap/gnome-3-26-1604/70",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 147849216,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 117,
"block_used": 117,
"device": "/dev/loop7",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1720,
(continues on next page)

2.18. Facts output

37

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"inode_used": 1720,
"mount": "/snap/gnome-logs/45",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 15335424,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 30,
"block_used": 30,
"device": "/dev/loop10",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 724,
"inode_used": 724,
"mount": "/snap/gnome-system-monitor/51",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 3932160,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 18,
"block_used": 18,
"device": "/dev/loop11",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1270,
"inode_used": 1270,
"mount": "/snap/gnome-calculator/222",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 2359296,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 338,
"block_used": 338,
"device": "/dev/loop9",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 36056,
"inode_used": 36056,
"mount": "/snap/gtk-common-themes/701",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 44302336,
"uuid": "N/A"
},
{
"block_available": 0,
(continues on next page)

38

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"block_size": 131072,
"block_total": 18,
"block_used": 18,
"device": "/dev/loop12",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1269,
"inode_used": 1269,
"mount": "/snap/gnome-calculator/260",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 2359296,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 30,
"block_used": 30,
"device": "/dev/loop13",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 724,
"inode_used": 724,
"mount": "/snap/gnome-system-monitor/54",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 3932160,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 1126,
"block_used": 1126,
"device": "/dev/loop14",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 27631,
"inode_used": 27631,
"mount": "/snap/gnome-3-26-1604/74",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 147587072,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 30,
"block_used": 30,
"device": "/dev/loop15",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 747,
"inode_used": 747,
"mount": "/snap/gnome-system-monitor/57",
(continues on next page)

2.18. Facts output

39

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 3932160,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 104,
"block_used": 104,
"device": "/dev/loop19",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1597,
"inode_used": 1597,
"mount": "/snap/gnome-characters/117",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 13631488,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 104,
"block_used": 104,
"device": "/dev/loop21",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 1597,
"inode_used": 1597,
"mount": "/snap/gnome-characters/124",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 13631488,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 274,
"block_used": 274,
"device": "/dev/loop23",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 27298,
"inode_used": 27298,
"mount": "/snap/gtk-common-themes/808",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 35913728,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 277,
(continues on next page)

40

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"block_used": 277,
"device": "/dev/loop28",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 27345,
"inode_used": 27345,
"mount": "/snap/gtk-common-themes/818",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 36306944,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 706,
"block_used": 706,
"device": "/dev/loop18",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 12808,
"inode_used": 12808,
"mount": "/snap/core/5897",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 92536832,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 193,
"block_used": 193,
"device": "/dev/loop22",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 20404,
"inode_used": 20404,
"mount": "/snap/heroku/3669",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 25296896,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 194,
"block_used": 194,
"device": "/dev/loop24",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 20430,
"inode_used": 20430,
"mount": "/snap/heroku/3677",
"options": "ro,nodev,relatime",
"size_available": 0,
(continues on next page)

2.18. Facts output

41

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"size_total": 25427968,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 2711,
"block_used": 2711,
"device": "/dev/loop0",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 2577,
"inode_used": 2577,
"mount": "/snap/pycharm-professional/107",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 355336192,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 716,
"block_used": 716,
"device": "/dev/loop3",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 12810,
"inode_used": 12810,
"mount": "/snap/core/6034",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 93847552,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 716,
"block_used": 716,
"device": "/dev/loop17",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 12810,
"inode_used": 12810,
"mount": "/snap/core/6130",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 93847552,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 2712,
"block_used": 2712,
"device": "/dev/loop20",
(continues on next page)

42

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"fstype": "squashfs",
"inode_available": 0,
"inode_total": 2577,
"inode_used": 2577,
"mount": "/snap/pycharm-professional/109",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 355467264,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 194,
"block_used": 194,
"device": "/dev/loop25",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 21319,
"inode_used": 21319,
"mount": "/snap/heroku/3685",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 25427968,
"uuid": "N/A"
},
{
"block_available": 60329506,
"block_size": 131072,
"block_total": 90023018,
"block_used": 29693512,
"device": "syn.mynet:/volume1",
"fstype": "nfs4",
"inode_available": 731447206,
"inode_total": 731684864,
"inode_used": 237658,
"mount": "/v",
"options": "rw,relatime,vers=4.0,rsize=131072,wsize=131072,namlen=255,
˓→soft,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.28.4.5,local_lock=none,
˓→addr=10.28.4.15",
"size_available": 7907509010432,
"size_total": 11799497015296,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 2713,
"block_used": 2713,
"device": "/dev/loop26",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 2583,
"inode_used": 2583,
"mount": "/snap/pycharm-professional/112",
"options": "ro,nodev,relatime",
"size_available": 0,
(continues on next page)

2.18. Facts output

43

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"size_total": 355598336,
"uuid": "N/A"
},
{
"block_available": 0,
"block_size": 131072,
"block_total": 867,
"block_used": 867,
"device": "/dev/loop16",
"fstype": "squashfs",
"inode_available": 0,
"inode_total": 10113,
"inode_used": 10113,
"mount": "/snap/bitwarden/16",
"options": "ro,nodev,relatime",
"size_available": 0,
"size_total": 113639424,
"uuid": "N/A"
}
],
"ansible_nodename": "moth",
"ansible_os_family": "Debian",
"ansible_pkg_mgr": "apt",
"ansible_processor": [
"0",
"GenuineIntel",
"Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz",
"1",
"GenuineIntel",
"Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz",
"2",
"GenuineIntel",
"Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz",
"3",
"GenuineIntel",
"Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz"
],
"ansible_processor_cores": 2,
"ansible_processor_count": 1,
"ansible_processor_threads_per_core": 2,
"ansible_processor_vcpus": 4,
"ansible_product_name": "3443CTO",
"ansible_product_serial": "NA",
"ansible_product_uuid": "NA",
"ansible_product_version": "ThinkPad X1 Carbon",
"ansible_python": {
"executable": "/usr/bin/python3",
"has_sslcontext": true,
"type": "cpython",
"version": {
"major": 3,
"micro": 7,
"minor": 6,
"releaselevel": "final",
"serial": 0
},
"version_info": [
(continues on next page)

44

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

3,
6,
7,
"final",
0

]
},
"ansible_python_version": "3.6.7",
"ansible_real_group_id": 1000,
"ansible_real_user_id": 1000,
"ansible_selinux": {
"status": "Missing selinux Python library"
},
"ansible_selinux_python_present": false,
"ansible_service_mgr": "systemd",
"ansible_ssh_host_key_ecdsa_public":
˓→"AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBOag0MplD833lb8uTuna9XSgqzBb/
˓→chnOJ+JJd5IY3LPkML9vgYGsqM5TzCNIyTJU1Yu0NIAr7viQOYv5nOFVYA=",
"ansible_ssh_host_key_ed25519_public":
˓→"AAAAC3NzaC1lZDI1NTE5AAAAIHlbGrt1d2303ouFG685QFq+DU1xBogZ3zfpba+/EPi6",
"ansible_ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQDOzkRKqn4P/
˓→7q5Yn8vipd5BcwL0nmIpvYmyivH4Y9kci8q1KU71JxQWlFm4kuX9KgrQyY8sI2R0GkIF0jzFiA0Lyd4u7wjPJPIeCwbNn5q54ai
˓→dGFbcK3aSFKkRaiRin9hO1UK27w1dBQ+NsBITM5EBLNdhvdeZqp5ie1QAFqVsfwsVvRHUpY6tsGOx9IhLb7yc4HC6j1iuhjIvpV
˓→",
"ansible_swapfree_mb": 7397,
"ansible_swaptotal_mb": 7629,
"ansible_system": "Linux",
"ansible_system_capabilities": [
""
],
"ansible_system_capabilities_enforced": "True",
"ansible_system_vendor": "LENOVO",
"ansible_uptime_seconds": 5980956,
"ansible_user_dir": "/home/poirier",
"ansible_user_gecos": "Dan Poirier,,,",
"ansible_user_gid": 1000,
"ansible_user_id": "poirier",
"ansible_user_shell": "/bin/bash",
"ansible_user_uid": 1000,
"ansible_userspace_architecture": "x86_64",
"ansible_userspace_bits": "64",
"ansible_virtualization_role": "host",
"ansible_virtualization_type": "kvm",
"ansible_wlp3s0": {
"active": true,
"device": "wlp3s0",
"ipv4": {
"address": "10.28.4.5",
"broadcast": "10.28.4.255",
"netmask": "255.255.255.0",
"network": "10.28.4.0"
},
"ipv6": [
{
"address": "fe80::33e1:2:9db5:7dc0",
"prefix": "64",
"scope": "link"
(continues on next page)

2.18. Facts output

45

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

}
],
"macaddress": "84:3a:4b:73:6c:f8",
"module": "iwlwifi",
"mtu": 1500,
"pciid": "0000:03:00.0",
"promisc": false,
"type": "ether"
},
"ansible_wwp0s20u4i6": {
"active": false,
"device": "wwp0s20u4i6",
"macaddress": "56:42:fa:89:f2:0b",
"module": "cdc_mbim",
"mtu": 1500,
"pciid": "3-4:1.6",
"promisc": false,
"type": "ether"
},
"ansible_zt7nnjxkbi": {
"active": true,
"device": "zt7nnjxkbi",
"ipv4": {
"address": "172.26.163.45",
"broadcast": "172.26.255.255",
"netmask": "255.255.0.0",
"network": "172.26.0.0"
},
"ipv6": [
{
"address": "fcae:c8f4:7d93:35ee:162::1",
"prefix": "40",
"scope": "global"
}
],
"macaddress": "b2:f5:3c:75:cf:f0",
"mtu": 2800,
"promisc": false,
"speed": 10,
"type": "ether"
},
"gather_subset": [
"all"
],
"module_setup": true
},
"changed": false
}

Misc. stuff I need to file somewhere:

2.19 Ad-hoc command
ansible Host Patterns -m <module> [options]
e.g.
46

Chapter 2. Ansible

Dan’s Cheat Sheets Documentation, Release 1

$ ansible all -m ping –ask-pass
Shortcut to run a command:
$ ansible all -a “/bin/echo hello”
options: see output of “ansible –help” for now
See ansible ad-hoc commands doc for ad-hoc commands.

2.19. Ad-hoc command

47

Dan’s Cheat Sheets Documentation, Release 1

48

Chapter 2. Ansible

CHAPTER

3

AWS

Contents:

3.1 S3
3.1.1 Access control
• How S3 evaluates access control
• Guidelines for Using the Available Access Policy Options
“The only recommended use case for the bucket ACL is to grant write permission to the Amazon S3 Log Delivery
group”. . .
“In general, you can use either a user policy or a bucket policy to manage permissions.”
Here’s a bucket policy to grant some IAM user complete access to a bucket:
{
"Statement": [
{
"Sid":"PublicReadForGetBucketObjects",
"Effect":"Allow",
"Principal": {
"AWS": "*"
},
"Action":["s3:GetObject"],
"Resource":["arn:aws:s3:::BUCKET-NAME/*"
]
},
{
"Action": "s3:*",
"Effect": "Allow",
"Resource": [
(continues on next page)

49

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"arn:aws:s3:::BUCKET-NAME",
"arn:aws:s3:::BUCKET-NAME/*"
],
"Principal": {
"AWS": [
"USER-ARN"
]
}
}
]
}

What about read-only access? Let’s see. . .
seems like s3auth.com used this example:
{
"Statement": [
{
"Effect": "Allow",
"Action": ["s3:GetObject", "s3:GetBucketWebsite"],
"Resource": [
"arn:aws:s3:::bucket-1.example.com/*",
"arn:aws:s3:::bucket-2.example.com/*"
]
}
]
}

3.1.2 Updating metadata to improve response headers for caching
Install s3cmd, then do it like this:
s3cmd --recursive modify \
--add-header="Expires: Thu, 31 Dec 2099 20:00:00 GMT" \
--add-header="Cache-Control: max-age=94608000" \
s3://caktus-website-production-2015/media/community_logos

You can use s3cmd ls to get a list of the buckets you can access.

50

Chapter 3. AWS

CHAPTER

4

Bootstrap

Warning: THIS IS NOT DONE AND PROBABLY WRONG.
The grid.
SO what does a class col-SIZE-N mean?
Each SIZE has a BREAKPOINT:
xs: -1 sm: 750px md: 970px lg: 1170px
Call the window width WIDTH.
For a single class col-SIZE-N:
if WIDTH >= BREAKPOINT(SIZE), then
ELEMENT-WIDTH=WIDTH*N/12
display INLINE (same line as previous element if possible)
else
ELEMENT-WIDTH=100%
display BLOCK (element gets its own line)

What if we have col-SIZE1-N1 and col-SIZE2-N2, with BREAKPOINT(SIZE1) < BREAKPOINT(SIZE2)?:
IF WIDTH >= BREAKPOINT(SIZE2), then
ELEMENT_WIDTH = WIDTH * N2 / 12
INLINE
elif WIDTH >= BREAKPOINT(SIZE1), then
ELEMENT_WIDTH = WIDTH * N1 / 12
INLINE
else:
BLOCK display

and so forth - just look at the class with the largest size

51

Dan’s Cheat Sheets Documentation, Release 1

NOTE: Since all widths are >= the breakpoint of XS, then if XS is present, the element will ALWAYS be laid out
inline. Though col-xs-12 is pretty much equivalent to not having an XS class, right???????????/

52

Chapter 4. Bootstrap

CHAPTER

5

Debian

5.1 Services
update-rc.d:
• Make a service run in its default runlevels:
update-rc.d <service> defaults

or:
update-rc.d <service> enable

• Make a service not run in any runlevel:
update-rc.d <service> disable

Making a new init script:
• Read /etc/init.d/README, which will point to other docs
• Copy /etc/init.d/skeleton and edit it.

5.2 Packages
• List packages that match a pattern: dpkg -l <pattern>
• List contents of a package: dpkg -L packagename
• Show packages that installed files matching pattern: dpkg -S pattern
• Show info about an installed package: dpkg-query -s packagename
• show info about a package that is known: apt-cache showpkg packagename
• Reconfigure a package: dpkg-reconfigure packagename
53

Dan’s Cheat Sheets Documentation, Release 1

• Change alternatives: update-alternatives ...

5.3 Alternatives
Change ‘alternatives’ default browser or editor:
sudo update-alternatives --set x-www-browser /usr/bin/chromium-browser
sudo update-alternatives --set editor /usr/bin/emacs24

Be prompted for which alternative you prefer for a link group:
sudo update-alternatives --config x-www-browser

Find out what the top-level link groups are:
sudo update-alternatives --get-selections

Set xdg program to open/browse a directory (DOES NOT WORK) (do NOT use sudo):
xdg-mime default /usr/share/applications/Thunar.desktop x-directory/normal

Change ‘xdg’ default browser (for user):
xdg-settings get default-web-browser
xdg-settings set default-web-browser google-chrome.desktop
xdg-settings set default-web-browser firefox.desktop

Install without any prompts (http://askubuntu.com/questions/146921/how-do-i-apt-get-y-dist-upgrade-without-a-grub-config-prompt):
sudo DEBIAN_FRONTEND=noninteractive apt-get -y \
-o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" \
<COMMAND>

5.4 Desktop applications
Put your own .desktop files in ~/.local/share/applications.
Archlinux on desktop entries
Desktop file spec
To let the system know about new or changed desktop files:
update-desktop-database [directory]

Launch the application from command line that has a <name>.desktop file somewhere:
gtk-launch <name>

54

Chapter 5. Debian

CHAPTER

6

Diet

6.1 Foods with low glycemic index
• Breads
• Dense wholegrain breads
• White corn tortillas
• Grain and seed breads
• Fruit Loaf such as Raisin
• Multigrain breads (look for breads where you can see lots of grains)
• Authentic Sourdough bread
• Breakfast Cereals
• Traditional porridge oats
• Muesli*
• Bircher Muesli
• Wholegrain high fibre cereals
• Vegetables
• Sweetcorn
• Silverbeet
• Carrots
• Zucchini
• Peas, frozen or fresh
• Snowpeas
• CarismaTM Potatoes*
55

Dan’s Cheat Sheets Documentation, Release 1

• Green Beans
• Broccoli
• Eggplant
• Cauliflower
• Squash
• Capsicum
• Salad Vegetables
• Celery
• Leeks
• Tomatoes
• Mushrooms – very low carb or no GI rating
• Butternut Pumpkin (lower GI)
• Avocadoes
• Drinks
• Milo®
• Skim Latte
• Sustagen®
• Soy Drinks
• Fruit Smoothies
• Fruit Juice
• Snacks
• Grain & Fruit bars
• Wholegrain crackers
• Nut & Seed bars
• Dried fruit and nuts
• Legumes
• Split Peas; Green or red Lentils
• Baked Beans
• Canned & Dried beans – kidney, cannellini, butter, borlotti, chickpeas
• Spreads
• Fruit Spreads
• Hummus
• Nut butters
• Main Meal Carbs
• Doongara Low GI White rice
• Fresh Noodles – Hokkein, Udon, Rice

56

Chapter 6. Diet

Dan’s Cheat Sheets Documentation, Release 1

• Low GI Brown rice*
• Soba Noodles
• Basmati rice (lower GI)
• Buckwheat
• Pasta, cooked al dente*
• Vermicelli
• Pearl Couscous*
• Bulgur
• Quinoa*
• Semolina
• Pearl Barley
• Cracked Wheat
• Fruit
• Apples*
• Pears*
• Bananas
• Kiwi Fruit
• Grapes*
• Mango
• Strawberries
• Oranges
• Peaches
• Grapefruits
• Apricots
• Berries, fresh or frozen
• Plums
• Dried fruits such as prunes, raisins, sultanas, apricots
• Canned Fruit in natural juice
• Dairy Foods
• Reduced fat milk
• Reduced fat custard
• Reduced fat yoghurt, plain or fruit flavoured
• Low fat ice-cream*

6.1. Foods with low glycemic index

57

Dan’s Cheat Sheets Documentation, Release 1

6.2 For lowering triglycerides
• Decrease or eliminate:
• Sweets
• Alcohol
• Refined carbohydrates:
• White rice
• bread and pasta made from white flour or semolina
• Saturated fats and fried foods:
• high fat meats
• skin on poultry
• sauces and spreads
• Trans fatty acids and hidden fats:
• hydrogenated vegetable oil
• regular fat meats
• lunchmeats
• hot dogs
• fatty snack foods
• Eat more:
• omega 3 fatty acids:
• fatty fish
• salmon
• mackerel
• sardines
• tuna
• trout
• ground flax seed
• flaxseed oil
• soy products
• legumes
• walnuts
• dark leafy green vegetables
• high fiber foods:
• beans
• whole grains
• ground flaxseed

58

Chapter 6. Diet

Dan’s Cheat Sheets Documentation, Release 1

• pumpkin seeds
• rice bran
• oat bran
• fruits and vegetables
• Eat more plant foods: Vegetable proteins such as
• dried beans,
• peas, and
• soy products;
• White poultry, prepared without the skin, is also a good source of protein without a lot of fat content.

6.2. For lowering triglycerides

59

Dan’s Cheat Sheets Documentation, Release 1

60

Chapter 6. Diet

CHAPTER

7

Django

These are just things I always find myself looking up, so I try to make some notes of the most important parts that I
can refer back to.
Contents:

7.1 Admin
7.1.1 URLs
List {{ app_label }}_{{ model_name }}_changelist Change {{ app_label }}_{{ model_name }}_change object_id
https://docs.djangoproject.com/en/stable/ref/contrib/admin/#reversing-admin-urls

7.1.2 Customize top-right corner of admin pages
Create your own templates/admin/base_site.html that comes ahead of the admin’s default one in the templates path.
At least in Django 1.8+, this gives you a “View site” link for free:
% extends "admin/base.html" %}
{% block title %}{{ title }} | {{ site_title|default:_('Django site admin') }}{%
˓→endblock %}
{% block branding %}
<h1 id="site-name"><a href="{% url 'admin:index' %}">{{ site_header|default:_('Django
˓→administration') }}</a></h1>
{% endblock %}
{% block userlinks %}
<a href="{% url "clear-cache" %}">Clear cache</a> /
(continues on next page)

61

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

{{ block.super }}
{% endblock userlinks %}

Prior to Django 1.8:
{% extends "admin/base.html" %}
{% block title %}{{ title }} | Caktus Admin{% endblock %}
{% block branding %}<h1 id="site-name">Caktus Admin</h1>{% endblock %}
{% block nav-global %}
<div style='display:block; padding:0 1em 0.5em 1em; float:right;'>
<a href='{% url "home" %}'>Return to Caktus Home</a>
| <a href='{% url "clear-cache" %}'>Clear cache</a>
</div>
{% endblock %}

7.2 Applications
https://docs.djangoproject.com/en/stable/ref/applications/#django.apps.AppConfig
In __init__.py:
# programs/__init__.py
default_app_config = 'programs.apps.ProgramsConfig'

In apps.py:
# programs/apps.py
from django.apps import AppConfig
class ProgramsConfig(AppConfig):
name = 'programs' # required: must be the Full dotted path to the app
label = 'programs' # optional: app label, must be unique in Django project
verbose_name = "Rock ’n’ roll" # optional
def ready():
"""
This runs after all models have been loaded, but you may not
modify the database in here.
Here's a trick to run something after each migration, which is often
good enough.
"""
from django.db.models.signals import post_migrate
post_migrate.connect(`callable`)

62

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

7.3 Celery
(Yes, I know Celery isn’t Django-specific.)
http://docs.celeryproject.org/en/latest/

7.3.1 Useful settings
http://docs.celeryproject.org/en/latest/configuration.html
CELERY_ALWAYS_EAGER: If this is True, all tasks will be executed locally by blocking until the task returns.
apply_async() and Task.delay() will return an EagerResult instance, which emulates the API and behavior of AsyncResult, except the result is already evaluated.
That is, tasks will be executed locally instead of being sent to the queue.
CELERY_EAGER_PROPAGATES_EXCEPTIONS: If this is True, eagerly executed tasks (applied by task.apply(),
or when the CELERY_ALWAYS_EAGER setting is enabled), will propagate exceptions.
It’s the same as always running apply() with throw=True.
CELERY_IGNORE_RESULT: Whether to store the task return values or not (tombstones). If you still want to store
errors, just not successful return values, you can set CELERY_STORE_ERRORS_EVEN_IF_IGNORED.
CELERYD_HIJACK_ROOT_LOGGER: By default any previously configured handlers on the root logger will be removed. If you want to customize your own logging handlers, then you can disable this behavior by setting CELERYD_HIJACK_ROOT_LOGGER = False.
CELERYBEAT_SCHEDULE: In each task, you can add an ‘options’ dictionary and set ‘expires’ to a number of
seconds. If the task doesn’t run within that time, it’ll be discarded rather than run when it finally gets to a worker. This
can help a lot with periodic tasks when workers or the queue gets hung up for a while and then unjammed - without
this, the workers will have to work through a huge backlog of the same periodic tasks over and over, for no reason.
Example:
CELERYBEAT_SCHEDULE = {
'process_new_scans': {
'task': 'tasks.process_new_scans',
'schedule': timedelta(minutes=15),
'options': {
'expires': 10*60, # 10 minutes
}
},
}

CELERY_DEFAULT_QUEUE: In the absence of more complicated configuration, celery will use this queue name for
everything. Handy when multiple instances of a site are sharing a queue manager:
CELERY_DEFAULT_QUEUE = 'queue_%s' % INSTANCE

7.4 django-compressor
django-compressor docs
Warning: much of the documentation is casual about saying things that are only true in some scenarios, without
making clear that that’s the case.

7.3. Celery

63

Dan’s Cheat Sheets Documentation, Release 1

7.4.1 ACTUALLY USING
Here are some practical scenarios for using django-compressor.
For what to put in your templates, you can go by the django-compressor documentation, and be sure to use {% static
%} and not STATIC_URL.
For what to put in your settings. . . it’s a lot more complicated. Set the compressor filters and precompilers however
you want. For the rest, keep reading.
Scenario: Development using runserver, DEBUG, not offline
If DEBUG is True, then compressor won’t even do anything and so everything should just work.
Scenario: Running using local files, not offline
This is the typical small server situation. You unpack your project on the server, run collectstatic, point nginx or some
other server at STATIC_ROOT and go.
Example settings:
# Django settings
DEBUG = False
STATIC_ROOT = '/var/www/static/'
STATIC_URL = '/static/'
# set compressor filters and precompilers as desired.
# leave other compressor settings at defaults.
# nginx settings
location /static {
alias /var/www/static;
}

Scenario: running using local files, with offline
Like the previous scenario, but you want compressor to do all its work at deploy time so the results are cached and
ready to go immediately when you start your server.
# Django settings like before, plus:
COMPRESS_OFFLINE = True

Now at deploy time you have more steps:
$ python manage.py collectstatic
$ python manage.py compress

Run compress after collectstatic so that compressor can find its input files. It’ll write its output files under
{STATIC_ROOT}/CACHE, and get them from there at runtime.
Scenario: running with storage on the network, with offline
In this scenario, you’re putting your static files somewhere off of the server where you’re running Django. For example,
S3. Or just your own static file server somewhere. Whatever.

64

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

Let’s start with how this would be setup without django-compressor, then we can modify it to add django-compressor.
# settings/no_compressor.py
STATIC_ROOT = None # Unused
STATIC_URL = None # Unused
STATIC_FILE_STORAGE = 'package.of.FileStorageClass'

At deploy time you can just run collectstatic, and all your static files will be pushed to the network:
$ python manage.py collectstatic

And at runtime, {% static %} will ask your file storage class to come up with a URL for each file, which will turn
out to be on your other server, or S3, or whatever.
Now, suppose we want to add compressor with offline processing (not using offline makes no sense with network
storage). Here are the settings you can use at runtime for that, assuming things have been prepared correctly:
# settings/deployed.py
# Django settings we'll use in production
STATIC_ROOT = None # Unused
STATIC_URL = None # Unused
STATIC_FILE_STORAGE = 'path.to.network.filestorage'
COMPRESS_ENABLED = True
COMPRESS_OFFLINE = True

The preparation is the tricky part. It turns out that for compress to work, a copy of the static files must be gathered in
a local directory first. Most of the tools we might use to compile, compress, etc. are going to read local files and write
local output.
To gather the static files into a local directory, we might, for example, use a different settings file that uses the default
file storage class, and run collectstatic. E.g.:
# settings/gather.py
# Django settings when first running collectstatic
from .deployed import *
# Override a few settings to make storage local
STATIC_ROOT = '/path/to/tmp/dir'
STATIC_URL = None # Unused
STATIC_FILE_STORAGE = 'django.core.files.storage.FileSystemStorage'
$ python manage.py collectstatic --settings=settings.gather

After running collectstatic with these settings, all your source static files will be gathered under
‘/path/to/tmp/dir’.
Now you could run compress, and the resulting files would be added under /path/to/tmp/dir. There’s an important
gotcha that will cause problems, though - for compressor to match up the output it makes now with what it’ll be
looking for later, the contents of each {% compress %} tag must be identical now to what it’ll be then, which
means the URLs must point at the production file server. We can accomplish this by setting STATIC_URL before
running the compress:
# settings/compress.py
# Django settings when running compress
from .deployed import *
# Override a few settings to make storage local, but URLs look remote
STATIC_ROOT = '/path/to/tmp/dir'
(continues on next page)

7.4. django-compressor

65

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

STATIC_URL = 'https://something.s3.somewhere/static/' # URL prefix for runtime
STATIC_FILE_STORAGE = 'django.core.files.storage.FileSystemStorage'
$ python manage.py compress --settings=settings.compress

The problem now is to get all these files onto the remote server. You could just use rsync or s3cmd or something,
which will work fine. But for maximum flexibility, let’s figure out a way to do it using Django. Our approach will be
to tell Django that our SOURCE static files are in ‘/path/to/tmp/dir’, and we want them collected using our production
file storage class, which will put them where we want them.
# Django settings when running collectstatic again after compress,
# to copy the resulting files to the network
# settings/copy_upstream.py
from .deployed import * # Set up for network file storage
# Tell collectstatic to use the files we collected and compressed
STATICFILES_FINDERS = ['django.contrib.staticfiles.finders.FileSystemFinder']
STATICFILES_DIRS = ['/path/to/tmp/dir']
$ python manage.py collectstatic --settings=settings.copy_upstream

That should copy things to the network. Then if you run using the ‘deployed’ settings, things should work!
TODO: TEST THAT!!!!!!!!!!!!!!!!!!!!
Other approaches
The compressor docs suggest a different approach – hack the storage class you’re using so when you run collectstatic,
it saves a copy of each file into a local directory in addition to pushing it upstream. Then you can use the same storage
class for collectstatic, compress, and runtime.

7.4.2 More detailed notes
Cache
For some things, compressor uses the cache named by COMPRESS_CACHE_BACKEND, which defaults to None,
which gives us the default Django cache.
Principles of compression
Whether compressor is processing templates offline ahead of time or at runtime, there are some common principles.
First, if COMPRESS_ENABLED is False, the {% compress %} tag will simply render as its contents; compressor
won’t change anything.
Otherwise, compressor will
1. parse the contents of the tag and figure out which css and javascript files would be included
2. fetch those files (See “accessing the files to be compressed”)
3. run those files through any configured preprocessors
4. concatenate the result and save it using COMPRESS_STORAGE

66

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

5. at rendering, the tag and contents will be replaced with one or two HTML elements that will load the compressed
file instead of the original ones.
Offline
If COMPRESS_OFFLINE is True, compressor expects all uses of {% compress ... %} in templates to have
been pre-processed by running manage.py compress ahead of time, which puts the results in compressor’s offline
cache. If anything it needs at run-time is not found there, things break/throw errors/render wrong etc.
Note: If COMPRESS_OFFLINE is True and files have not been pre-compressed, compressor will not compress them
at runtime. Things will break.
The offline cache manifest is a json file, stored using COMPRESS_STORAGE, in the subdirectory
COMPRESS_OUTPUT_DIR (default: CACHE), using the filename COMPRESS_OFFLINE_MANIFEST (default:
manifest.json).
The keys in the offline cache manifest are generated from the template content inside each compress tag, not the
contents of the compressed files. So, you must arrange to re-run the offline compression anytime your content files
might have changed, or it’ll be serving up compressed files generated from the old file contents.
Note: It sounds like you must also be sure the contents of the compress tags don’t change between precompressing
and runtime, for example by changing the URL prefix!
The values in the offline cache manifest are paths of the compressed files in COMPRESS_STORAGE.
Note: RECOMMENDATION FROM DOCS: make COMPRESS_OFFLINE_MANIFEST change depending on the
current code revision, so that during deploys, servers running different versions of the code will each use the manifest
appropriate for the version of the code they’re running. Otherwise, servers might use the wrong manifest and strange
things could happen.

Not offline
If COMPRESS_OFFLINE is False, compressor will look in COMPRESS_STORAGE for previously processed results,
but if not found, will create them on the fly and save them to use again.
Storage
Compressor uses a Django storage class for some of its operations, controlled by the setting COMPRESS_STORAGE.
The default storage class is compressor.storage.CompressorFileStorage, which is a subclass of the
standard filesystem storage class. It uses COMPRESS_ROOT as the base directory in the local filesystem to store files
in, and builds URLs by prefixing file paths within the storage with COMPRESS_URL.
If you change COMPRESS_STORAGE, then ignore anything in the docs about COMPRESS_ROOT and
COMPRESS_URL as they won’t apply anymore (except in a few cases. . . see exceptions noted as they come up,
below).

7.4. django-compressor

67

Dan’s Cheat Sheets Documentation, Release 1

Accessing the files to be compressed
For each file to be compressed, compressor starts with the URL from the rendered original content inside the compress
tag. For example, if part of the content is <script src="http://example.com/foo.js"></script>,
then it extracts "http://example.com/foo.js" as the URL.
It checks that the URL starts with COMPRESS_STORAGE’s base_url, or if accessing that fails (quite possible
since base_url is not a standard part of the file storage class API), uses COMPRESS_URL.
Note: This is a place where compressor can use COMPRESS_URL even if it’s not using its default storage.
If the URL doesn’t start with that string, compressor throws a possibly misleading error, “’%s’ isn’t accessible via
COMPRESS_URL (‘%s’) and can’t be compressed”.
Otherwise, compressor tries to come up with a local filepath to access the file, as follows:
• Try to get a local filepath from COMPRESS_STORAGE using .path().
• If that’s not implemented (for example, for remote storages), it tries again using compressor.storage.
CompressorFileStorage (regardless of what COMPRESS_STORAGE is set to), so basically it’s going
to look for it under COMPRESS_ROOT.
• If it still can’t get a local filepath, throws an error: “’%s’ could not be found in the COMPRESS_ROOT ‘%s’%s”
which is very misleading if you’re not using a storage class that looks at COMPRESS_ROOT.

7.5 Data fixtures
Export/dump data to use as a fixture:
python manage.py dumpdata --format=yaml --natural app.model >data.yaml

Load it again:
python manage.py loaddata data.yaml

7.5.1 Natural keys
https://docs.djangoproject.com/en/stable/topics/serialization/#natural-keys
from django.db import models
class PersonManager(models.Manager):
def get_by_natural_key(self, first_name, last_name):
return self.get(first_name=first_name, last_name=last_name)
class Person(models.Model):
objects = PersonManager()
...
def natural_key(self):
return (self.first_name, self.last_name)
class Meta:
unique_together = (('first_name', 'last_name'),)

68

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

Dependencies
If part of the natural key is a reference to another model, then that model needs to be deserialized first:
class Book(models.Model):
name = models.CharField(max_length=100)
author = models.ForeignKey(Person)
def natural_key(self):
return (self.name,) + self.author.natural_key()
natural_key.dependencies = ['example_app.person']

7.6 Databases
7.6.1 Performance
From Django 1.6 on, always add CONN_MAX_AGE to database settings to enable persistent connections. 300 is a
good starting value (5 minutes). None will keep them open indefinitely.
BUT - keep in mind that every open connection to Postgres consumes database server resources. So you might want
instead to run pgbouncer locally.

7.7 Django Debug Toolbar
Install/config
Install:
pip install django-debug-toolbar

settings.py:
DEBUG = True
INTERNAL_IPS = ['127.0.0.1']
INSTALLED_APPS += [
'debug_toolbar',
]
# The order of MIDDLEWARE and MIDDLEWARE_CLASSES is important. You should include
# the Debug Toolbar middleware as early as possible in the list. However, it must
# come after any other middleware that encodes the response’s content, such as
# GZipMiddleware.
MIDDLEWARE = [
'debug_toolbar.middleware.DebugToolbarMiddleware',
] + MIDDLEWARE

urls.py:
from django.conf import settings
from django.conf.urls import include, url
if settings.DEBUG:
import debug_toolbar
urlpatterns += [
(continues on next page)

7.6. Databases

69

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

url(r'^__debug__/', include(debug_toolbar.urls)),
]

7.8 Dokku
Readying a Django project for deploying to Dokku.
This lists the things to add or change to easily deploy a Django application to Dokku.
It started out not trying to cover all of setting up a site on Dokku, only the parts relevant to a Django project – but it has
grown. Still, you should read the Dokku getting started docs, then use this as a cheatsheet to quickly enable existing
Django projects to deploy on Dokku.
Start with the pages in this list, in order, then come back to this page and continue reading:

7.8.1 Dokku server administration
This page has information for those who have to set up and maintain a Dokku server. If you’re just using one, you can
ignore this.
Initial install
The Dokku docs recommend setting up a new OS install of a supported operating system, then running the Dokku
install script.
Experience suggests that that approach is more likely to work than trying to install Dokku on a system that has already
had some configuration done for other things.
Simple hostnames
The simple way to set up hostnames is:
• Pick a hostname you can control, e.g. dokku.me.
• During initial setup of Dokku, configure that as the server’s name.
• Create a DNS A record pointing dokku.me at the server’s IP address.
• Add a wildcard entry for *.dokku.me at the same address.
• For each app you put on that server, give the app the same name you want to use for its subdomain. For example,
an app named foo would be accessible on the internet at foo.dokku.me, without having to make any more
changes to your DNS settings.
Managing users
In other words, who can mess with the apps on a dokku server?
The way this currently works is that everybody ends up sshing to the server as the dokku user to do things. To let
them do that, we want to add a public key for them to the dokku config, by doing this (from any system):
$ cat /path/to/ssh_keyfile.pub | ssh dokku ssh-keys:add <KEYNAME>

70

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

The <KEYNAME> is just to identify the different keys. I suggest using the person’s typical username. Just remember
there will not be a user of that name on the dokku server.
When it’s time to revoke someone’s access:
$ ssh dokku ssh_keys:remove <KEYNAME>

and now you see why the <KEYNAME> is useful.
For now, there’s not a simple way to limit particular users to particular apps or commands.

7.8.2 Files
Setting up files in a Django project for deploying it to Dokku
requirements.txt
There needs to be a requirements.txt file at the top level. If you prefer to keep your requirements somewhere
else, the top-level one can just look like:
-r path/to/real/requirements.txt

Wherever your requirements are, add the latest versions of:
dj-database-url
gunicorn
whitenoise

settings
Add a .../deploy.py settings file, e.g. <appname>/settings/deploy.py.
It can start out looking like this (edit the top line if your main settings file isn’t base.py):
# Settings when deployed to Dokku
from .base import * # noqa
import dj_database_url
# Disable Django's own staticfiles handling in favour of WhiteNoise, for
# greater consistency between gunicorn and `./manage.py runserver`. See:
# http://whitenoise.evans.io/en/stable/django.html#using-whitenoise-in-development
INSTALLED_APPS.remove('django.contrib.staticfiles')
INSTALLED_APPS.extend([
'whitenoise.runserver_nostatic',
'django.contrib.staticfiles',
])
MIDDLEWARE.remove('django.middleware.security.SecurityMiddleware')
MIDDLEWARE = [
'django.middleware.security.SecurityMiddleware',
'whitenoise.middleware.WhiteNoiseMiddleware',
] + MIDDLEWARE
# Update database configuration with $DATABASE_URL.
db_from_env = dj_database_url.config(conn_max_age=500)
(continues on next page)

7.8. Dokku

71

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

DATABASES['default'].update(db_from_env)
# Honor the 'X-Forwarded-Proto' header for request.is_secure()
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
# Allow all host headers (feel free to make this more specific)
ALLOWED_HOSTS = ['*']
# Simplified static file serving.
# https://warehouse.python.org/project/whitenoise/
STATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'

wsgi.py
Find your wsgi.py file.
1. Edit to change the default settings module to <appname>.settings.deploy (the path to the new settings
file you created above).
2. Add to the end:
from whitenoise.django import DjangoWhiteNoise
application = DjangoWhiteNoise(application)

Procfile
Create Procfile (more on dokku Procfile) in the top directory. For our simple case, it can just contain one line, starting
with web: and containing the command to start gunicorn for our site:
web: gunicorn {{ project_name }}.wsgi

See also the section on running Celery and other processes.
runtime.txt
Create runtime.txt in the top directory. It only needs one line, e.g.:
python-3.6.1

This has to be specific. E.g. python-3.5.2 or python-3.6.1 might work if the dokku server supports it, but
python-3.5 or python-3.6 probably won’t.
app.json
Create app.json in the top-level project directory. You might see examples on the Interwebs with lots of things
in app.json (because Heroku uses app.json for lots of things), but as of this writing, dokku ignores everything but
scripts.dokku.predeploy and scripts.dokku.postdeploy. Example:
{
"scripts": {
"dokku": {
(continues on next page)

72

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

"predeploy": "python manage.py migrate --noinput"
}
}
}

Note: Dokku automatically runs collectstatic for you, so you don’t need to do that from app.json.

buildpacks
If your app is not pure Python - e.g. if it uses node - you’ll need to override the automatic buildpack detection, because
it only works for a single application type.
Do this by adding a top-level .buildpacks file, containing links to the buildpacks to use:
https://github.com/heroku/heroku-buildpack-nodejs.git
https://github.com/heroku/heroku-buildpack-python.git
https://github.com/heroku/heroku-buildpack-apt

Heroku maintains a list of buildpacks.

7.8.3 Postgres with Dokku
There’s nothing Django-specific about this, but I’m including it just because we probably want to do it on every single
Django deploy.
To install the postgresql plugin, inside your server run (because plugins must be installed as root):
$ sudo dokku plugin:install https://github.com/dokku/dokku-postgres.git

Now you need to create a database, and link the database to the app. You can do this from your own system:
$ ssh dokku postgres:create example-database
$ ssh dokku postgres:link example-database django-tutorial

Now when dokku runs your app, it’ll set an env var to tell it where its DB is, e.g.:
DATABASE_URL=postgres://user:pass@host:port/db

For Django, install the tiny dj_database_url package, then in settings.py:
import dj_database_url
db_from_env = dj_database_url.config(conn_max_age=500)
DATABASES['default'].update(db_from_env)

There are built-in commands making it easy to backup and restore databases:
$ ssh dokku postgres:export [db_name] > [db_name].dump
$ ssh dokku postgres:import [db_name] < [db_name].dump

7.8. Dokku

73

Dan’s Cheat Sheets Documentation, Release 1

7.8.4 SSL for Dokku (Letsencrypt etc.)
Letsencrypt
Note: Get the site up and running, and accessible from the Internet, first. Let’s Encrypt will not be able to get you a
certificate until then.
There’s nothing Django-specific about this part, but I’m including it just because we probably want to do it on every
single Django deploy.
To add SSL with the Let’s Encrypt plugin (more), first install the plugin by running on the dokku server (plugins must
be installed as root):
$ sudo dokku plugin:install https://github.com/dokku/dokku-letsencrypt.git

Then on your system, to configure your app and tell letsencrypt to manage its certs and renew them periodically:
$ ssh dokku config:set --no-restart <appname> DOKKU_LETSENCRYPT_EMAIL=your@email.tld
$ ssh dokku letsencrypt myapp
$ ssh dokku letsencrypt:cron-job --add <appname>

Forcing SSL from Django
If we don’t want to figure out how to override the default nginx config to redirect non-SSL requests to SSL, we can
have Django do it with a few settings.
First, set SECURE_SSL_REDIRECT to True. This will tell Django to do the redirect.
SECURE_SSL_REDIRECT = True

Commit, deploy, and make sure the site still works.
Second, set SECURE_HSTS_SECONDS to a relatively small number of seconds.
SECURE_HSTS_SECONDS = 1800

This adds a header to all responses, telling any browser that receives it that this site should only be accessed via SSL,
for that many seconds.
Commit, deploy, and make sure the site still works.
If everything still seems good, bite the bullet, increase SECURE_HSTS_SECONDS to a large number (e.g. 31536000
seconds, or 1 year), commit, deploy, and test again.
Additional info (move to their own files as they’re ready). . .

7.8.5 Environment variables
I can’t find docs on what environment variables Dokku sets globally when running apps. But just about any Django
app is going to be linked to a database, so if you need to detect whether the app is running under Dokku or Heroku,
looking for DATABASE_URL should be good enough.

7.8.6 Static files
We use whitenoise to serve static files from Django. If the site gets incredible amounts of traffic, throw a CDN in
front, but honestly, very few sites actually need that. (If you have a philosophical objection to serving static files from
74

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

Django, you can customize the nginx config through Dokku and probably manage to get nginx to do the static file
serving, but I haven’t bothered figuring it out myself.)
Or put your static files on S3.

7.8.7 Django media
If your site requires uploaded files to be persisted, remember that the container running your code is ephemeral and
any changes made to files inside it will vanish at the next deploy.
First, you can use S3 for your media files.
Or you can use persistent storage on Dokku, which is a way of mounting directories from the dokku server inside
the running container where your site code can store and read files that will continue to exist past the lifetime of that
particular container.

7.8.8 Simple hostnames
If the server is set up properly, assuming the server’s domain name is dokkuserver.domain, creating an app
named foo will automatically foo.dokkuserver.domain resolve to the server’s address, and requests with host
foo.dokkuserver.domain to be routed to that app.
If you want to get fancier, http://dokku.viewdocs.io/dokku/configuration/domains/.
Also, note that any requests simply addressed to dokku.me will get routed to the alphabetically first app on the
server, but you can change that: http://dokku.viewdocs.io/dokku/configuration/domains/ or just set up a “00default”
app.

7.8.9 Zero downtime deploys
WRITEME - see http://dokku.viewdocs.io/dokku/deployment/zero-downtime-deploys/

7.8.10 Behind a load balancer
If requests are being terminated at a load balancer and then proxied to our dokku server, some nginx config customization will be needed so your app can see the actual origin of the requests: http://dokku.viewdocs.io/dokku/configuration/
ssl/#running-behind-a-load-balancer

7.8.11 Run a command
Suppose you want to run something like python manage.py createsuperuser in the app environment?
$ ssh dokku run <appname> python manage.py createsuperuser

will do it.

7.8.12 Running other daemons (like Celery)
Suppose you need to run another instance of your app in another way, for example to run celery beat and celery
worker.
Use the Procfile to tell Dokku what processes to run. E.g. if your Procfile is:

7.8. Dokku

75

Dan’s Cheat Sheets Documentation, Release 1

web: gunicorn path/to/file.wsgi

try editing it to:
web: gunicorn path/to/file.wsgi
beat: celery beat -A appname -linfo
worker: celery worker -A appname -linfo

With just that, the extra processes won’t run automatically. You can run them by telling Dokku to scale them up, e.g.:
$ ssh dokku ps:scale <appname> beat=1 worker=4

You can check the current scaling settings:
$ ssh dokku ps:scale <appname>
-----> Scaling for <appname>
-----> proctype
qty
-----> --------------> web
1
-----> beat
1
-----> worker
4

and see what’s actually running (example from another app that only has one process):
$ ssh dokku ps:report <appname>
=====> <appname>
Processes:
1
Deployed:
true
Running:
true
Restore:
true
Restart policy:
on-failure:10
Status web.1
true
(CID: 03ea8977f37e)

Since we probably don’t want to have to remember to manually scale these things up and check that they’re running,
we can add a DOKKU_SCALE file to our repo:
web=1
beat=1
worker=4

which is equivalent to running ps:scale web=1 beat=1 worker=4

7.8.13 Secrets
First, if possible, use Dokku plugin integrations for things like databases, Redis, cache, etc. They automatically set
environment variables in each app that your settings can read, so you don’t have to manage different settings for each
environment. See each plugin’s doc, of course, for more on that.
The way to handle other secrets for each environment is to set them as config on the app, which will add them as
environment variables, again so your settings can read them at runtime.
The downside is that the secrets aren’t being managed/versioned etc for us. . . but I think we can handle the few we’ll
need by manually keeping them in Lastpass or something.
Here are the docs for setting config.
Before setting any config, note that by default, making any change to the config triggers a new deploy. If you’re not
ready for that, include --no-restart in the command, as these examples will do.
76

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

To set config variables:
$ ssh dokku config:set <appname> --no-restart VAR1=VAL1 VAR2=VAL2 ...

To remove a variable:
$ ssh dokku config>unset <appname> --no-restart VAR1

Check the value of some variable:
$ ssh dokku config:get <appname> VAR1
VAL1

Get all the settings in a single line, handy for use in shell commands or to set on another app:
$ ssh dokku config <appname> --shell
VAR1=VAL1 VAR2=VAL2
$ export $(ssh dokku config <appname> --shell)
$ ssh dokku config:set <appname1> $(ssh dokku config <appname2> --shell)

Get all the settings in a format handy to save in a file for later sourcing in a local shell:
$ ssh dokku config <appname> --export
export VAR1=VAL1
export VAR2=VAL2
$ ssh dokku config <appname> --export >appname.env
$ . appname.env

Note: you can also set config vals globally - just change <appname> to --global in any of these commands.

7.8.14 Logs
Dokku collects stdout from your processes and you can view it with the dokku logs command.
nginx logs are similarly stored on the server and can be accessed using dokku nginx:access-log <appname>
or dokku nginx:error-log <appname>.
Dokku event logging can be enabled with dokku events:on and then viewed with dokku events. This shows things
like deploy steps.

7.8.15 Deploying from private git repos
Note: this doesn’t apply to your main project repo. That can be private and Dokku doesn’t care, because you’re
pushing it directly from your development system to the Dokku server.
But if your requirements include references to private git repos, then you’ll need to arrange for Dokku to get access to
those repos when it’s pip installing your requirements.
Dokku docs, such as they are. . .
I think the upshot is:
• Create a new ssh key for deploying
• Add it to the repo on Github (or whatever) as an authorized deploy key (TODO: Link to github docs on that)
• Drop a copy of the public key file into /home/dokku/.ssh/ on the Dokku system (with appropriate permissions)

7.8. Dokku

77

Dan’s Cheat Sheets Documentation, Release 1

7.8.16 Deploying non-master branch
The docs
By default, dokku deploys when the app’s master branch on the dokku server is updated. There are (at least) two ways
to deploy a branch other than master.
1. Push your non-master local branch to the master branch on the server:
$ git push dokku <local branch>:master

but that requires you to always remember that if you have apps that are always supposed to use a different branch than
master.
2. Configure your app so the default branch is different, by using the git:set command:
$ ssh dokku git:set appname deploy-branch SOME_BRANCH_NAME

This seems like a more useful approach. Just “git push dokku some-branch” every time you want to deploy your app.

7.8.17 Developing with multiple remote apps
Suppose you have local development and sometimes you want to push to staging and sometimes to production. Maybe
you have other apps too.
The key is to set up a different git remote for each remote app. E.g.:
$ ssh dokku app:create staging
$ ssh dokku git:set staging deploy-branch develop
$ git remote add staging dokku@my-dokku-server.com:staging
$ ssh dokku app:create production
$ ssh dokku git:set production deploy-branch master
$ git remote add production dokku@my-dokku-server.com:production

Then to deploy, push the approprate branch to the appropriate branch:
$ git push staging develop
$ git push production master

7.8.18 Customizing nginx config
If you need to completely override the nginx config, you’ll need to provide an nginx config file template.
Luckily, much customization can be done just by providing snippets of configuration for nginx to include after it’s
base config file.
To do this, arrange for the snippets to get copied to /home/dokku/<appname>/nginx.conf.d/ during deployment, probably in a pre- or post-deploy script.

7.8.19 Logging to papertrail
Use the logspout plugin.

78

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

7.8.20 Adding Sentry service
https://github.com/darklow/dokku-sentry

7.9 Django REST Framework - Serializers
7.9.1 URLs from viewsets
WRITE ME

7.9.2 Relationship between serializers and API calls
It’s helpful to know what DRF does with its views, serializers, etc when a user of the API makes various calls.
Let’s assume a very simple model and serializer:
class Thing(models.Model):
text = models.TextField()
class ThingSerializer(ModelSerializer):
class Meta:
model = Thing

Getting an existing object
Suppose we request GET /api/obj/27/. Here’s some of the DRF code that gets invoked:
# rest_framework/mixins.py
class RetrieveModelMixin(object):
"""
Retrieve a model instance.
"""
def retrieve(self, request, *args, **kwargs):
instance = self.get_object()
serializer = self.get_serializer(instance)
return Response(serializer.data)
# rest_framework/generics.py
class GenericAPIView(views.APIView):
...
def get_serializer(self, *args, **kwargs):
"""
Return the serializer instance that should be used for validating and
deserializing input, and for serializing output.
"""
serializer_class = self.get_serializer_class()
kwargs['context'] = self.get_serializer_context()
return serializer_class(*args, **kwargs)

To unwind and simplify that a little:

7.9. Django REST Framework - Serializers

79

Dan’s Cheat Sheets Documentation, Release 1

# id is from the request URL
instance = Thing.objects.get(id=id)
serializer = ThingSerializer(instance)
return serializer.data

and the returned data looks like:
{'id': 1, 'text': 'Text'}

That’s very straightforward.
Creating a new object
POST /api/obj/ with data {text:

"foo"}}:

# rest_framework/mixins.py
class CreateModelMixin(object):
"""
Create a model instance.
"""
def create(self, request, *args, **kwargs):
serializer = self.get_serializer(data=request.data)
serializer.is_valid(raise_exception=True)
self.perform_create(serializer)
headers = self.get_success_headers(serializer.data)
return Response(serializer.data, status=status.HTTP_201_CREATED,
˓→headers=headers)
def perform_create(self, serializer):
serializer.save()
def get_success_headers(self, data):
try:
return {'Location': str(data[api_settings.URL_FIELD_NAME])}
except (TypeError, KeyError):
return {}

Again, the simple version:
serializer = ThingSerializer(data=request.data)
serializer.is_valid(raise_exception=True)
serializer.save()
return serializer.data

and the returned data looks like:
{'id': 1, 'text': 'Text'}

PUTTING an object
PUT /api/object/1/ with data {id:

1, text:

"new text"}:

class UpdateModelMixin(object):
"""
(continues on next page)

80

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

Update a model instance.
"""
def update(self, request, *args, **kwargs):
partial = kwargs.pop('partial', False)
instance = self.get_object()
serializer = self.get_serializer(instance, data=request.data, partial=partial)
serializer.is_valid(raise_exception=True)
self.perform_update(serializer)
if getattr(instance, '_prefetched_objects_cache', None):
# If 'prefetch_related' has been applied to a queryset, we need to
# forcibly invalidate the prefetch cache on the instance.
instance._prefetched_objects_cache = {}
return Response(serializer.data)
def perform_update(self, serializer):
serializer.save()
def partial_update(self, request, *args, **kwargs):
kwargs['partial'] = True
return self.update(request, *args, **kwargs)

or:
instance = self.get_object() # uses PK from URL
serializer = ThingSerializer(instance, data=request.data, partial=False)
serializer.is_valid(raise_exception=True)
serializer.save()
return serializer.data

and the returned data looks like:
{'id': 1, 'text': 'Text'}

PATCHing an object
Close enough to PUT for now.
Nested objects
Nested objects are where things get more complicated. Let’s add another model, serializer, and view:
class Wrapper(models.Model):
thing = models.ForeignKey(Thing, on_delete=models.PROTECT)
other = models.TextField()
class WrapperSerializer(ModelSerializer):
class Meta:
fields = ['id', 'thing', 'other']
model = Wrapper
class WrapperView(ModelViewSet):
(continues on next page)

7.9. Django REST Framework - Serializers

81

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

serializer_class = WrapperSerializer
queryset = Wrapper.objects.all()

If we try just serializing a wrapper:
wrapper = Wrapper.objects.create(
thing=Thing.objects.create(
text='foo'
),
other='bar')
print(WrapperSerializer(instance=wrapper).data)

The output is:
{'id': 1, 'thing': 1, 'other': 'bar'}

We’d probably prefer to see the Thing object’s contents in there, which we can do by setting depth:
class WrapperSerializer(ModelSerializer):
class Meta:
depth = 1
fields = ['id', 'thing', 'other']
model = Wrapper

and now we get:
{'id': 1, 'thing': {'id': 1, 'text': 'foo'}, 'other': 'bar'}

Which looks reasonable.
Now suppose we try creating a new Wrapper object from scratch:
data = {
'other': 'Other text',
'thing': {
'text': 'thing text'
}
}
serializer = WrapperSerializer(data=data)
serializer.is_valid(raise_exception=True)

That will fail:
ValidationError: {'model': [ErrorDetail(string='Incorrect type. Expected pk value,
˓→received dict.', code='incorrect_type')]}

Maybe DRF expects an ID in the data for model? Which would mean creating one first.:
thing_data = {'text': 'thing text'}
thing_serializer = ThingSerializer(data=model_data)
thing_serializer.is_valid(raise_exception=True)
thing = thing_serializer.save()
data = {
'other': 'Other text',
'thing': {
'id': thing.id,
(continues on next page)

82

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

'text': 'thing text'
}
}
serializer = WrapperSerializer(data=data)
serializer.is_valid(raise_exception=True)

But this doesn’t seem to be good enough:
ValidationError: {'model': [ErrorDetail(string='Incorrect type. Expected pk value,
˓→received dict.', code='incorrect_type')]}

Maybe we have to do pass just the PK of the model object to use the serializer as-is, and this works:
thing_data = {'text': 'thing text'}
thing_serializer = ThingSerializer(data=model_data)
thing_serializer.is_valid(raise_exception=True)
thing = thing_serializer.save()
data = {
'other': 'Other text',
'thing': thing.id
}
serializer = WrapperSerializer(data=data)
serializer.is_valid(raise_exception=True)
instance = serializer.save()
print(data)

No, that fails too:
IntegrityError: NOT NULL constraint failed: drf_wrapper.model_id

Apparently the model ID is not getting where it needs to be.
Ah, this comment:
The default implementation also does not handle nested relationships.
If you want to support writable nested relationships you'll need
to write an explicit `.create()` method.

in the DRF code seems to cover this - ModelSerializer does not support writable nested relationships? Though, we’ve
giving it an ID to put into the foreignkey field, it doesn’t seem as if it should need to do anything special. But it does,
I guess.
If we create a ModelSerializer for Wrapper without overriding any of the fields, here’s what DRF gives us:
WrapperSerializer():
id = IntegerField(label='ID', read_only=True)
thing = NestedSerializer(read_only=True):
id = IntegerField(label='ID', read_only=True)
text = CharField(style={'base_template': 'textarea.html'})
other = CharField(style={'base_template': 'textarea.html'})

What is this NestedSerializer? It’s not documented, though it’s mentioned in the DRF 3.2.0 release notes. Whatever it
is, it doesn’t do what we want.
Let’s try this serializer:

7.9. Django REST Framework - Serializers

83

Dan’s Cheat Sheets Documentation, Release 1

class WrapperSerializer(ModelSerializer):
class Meta:
depth = 1
fields = ['id', 'thing', 'other']
model = Wrapper
thing = ThingSerializer()

This gives us:
The `.create()` method does not support writable nested fields by default.
Write an explicit `.create()` method for serializer `drf.serializers.
˓→WrapperSerializer`, or set `read_only=True` on nested serializer fields.

So let’s do that:
class WrapperSerializer(ModelSerializer):
class Meta:
depth = 1
fields = ['id', 'thing', 'other']
model = Wrapper
thing = ThingSerializer()
def create(self, validated_data):
thing_data = validated_data.pop('model')
thing_serializer = ThingSerializer(data=thing_data)
thing_serializer.is_valid(raise_exception=True)
validated_data['thing'] = thing_serializer.save()
instance = super().create(validated_data)
return instance

Now if we pass in:
{'other': 'Other text', 'thing': {'text': 'thing text'}}

We end up with a Thing object, and a Wrapper object whose thing field points to that new Thing object.
Nesting an existing object
We’ve worked out the non-obvious way to implement creating a new object with a new nested object. Now suppose
we want to create a new object, but have it point to an existing object. Will what we have do what we want?
No, it will not. We might think we could tweak our create() method to look for an ‘id’ in the nested object data, but
our create() method is not being given an ‘id’ in its validated_data even if we provided one.
We pass in:
{'other': 'Some text', 'thing': {'id': 1, 'text': 'thing!'}}

but validated_data as passed to clean() is:
{'other': 'Some text', 'thing': OrderedDict([('text', 'thing!')])}

Just for grins, we can try just passing:

84

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

{'other': 'Some text', 'thing': 1}

but that doesn’t work any better now than it did before.
What if we temporarily get rid of our “depth”?

7.10 Elastic Beanstalk with Django
SSH into a random instance. This assumes that you have copied the SSH private key into your $HOME/.ssh directory:
(bringfido)$ eb ssh staging

Open the AWS Elasticbeanstalk web console:
(bringfido)$ eb console staging

Scale the application to N web instances:
(bringfido)$ eb scale <N> staging

Check the overall status of the environment, or detailed info about each instance:
(bringfido)$ eb status -v staging
(bringfido)$ eb health staging

If you need to work with Django on a server, after ssh’ing in:
$ . /opt/python/current/env
$ cd /opt/python/current/app
$ python manage.py ....

7.11 Email
https://docs.djangoproject.com/en/stable/topics/email/

7.11.1 API
Send one email:
send_mail(subject, message, from_email, recipient_list, fail_silently=False, auth_
˓→user=None, auth_password=None, connection=None)

7.11.2 Attachments
msg = EmailMessage(...)
msg.attach(
filename="any string",
content=b"the contents",
(continues on next page)

7.10. Elastic Beanstalk with Django

85

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

mimetype="application/sunshine"
)

or
msg.attach(instance of MIMEBase)

7.11.3 Email backends/handlers
https://docs.djangoproject.com/en/stable/topics/email/#email-backends
For development:
EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'

For real:
EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'

In-memory backend - The ‘locmem’ backend stores messages in a special attribute of the django.core.mail module.
The outbox attribute is created when the first message is sent. It’s a list with an EmailMessage instance for each
message that would be sent:
EMAIL_BACKEND = 'django.core.mail.backends.locmem.EmailBackend'

This backend is not intended for use in production – it is provided as a convenience that can be used during development
and testing.

7.11.4 Settings for email addresses
ADMINS A tuple that lists people who get code error notifications:
(('John', 'john@example.com'), ('Mary', 'mary@example.com'))

MANAGERS Not needed
DEFAULT_FROM_EMAIL Default email address to use for various automated correspondence from the site manager(s). This doesn’t include error messages sent to ADMINS and MANAGERS; for that, see SERVER_EMAIL.
SERVER_EMAIL The email address that error messages come from, such as those sent to ADMINS and MANAGERS.

7.12 Fabric
Sample tasks:
@task
def db_backup():
"""
Backup the database to S3 just like the nightly cron job
"""
require('environment')
require('instance', provided_by='instance')
(continues on next page)

86

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

manage_run("dbbackup --encrypt")

def db_exists(dbname):
"""
Return True if a db named DBNAME exists on the remote host.
"""
require('environment', provided_by=SERVER_ENVIRONMENTS)
output = sudo('psql -l --pset=format=unaligned', user='postgres')
dbnames = [line.split('|')[0] for line in output.splitlines()]
return dbname in dbnames

@task
def db_dump(file):
"""
Dump an instance's database to a remote file.
Example:
`fab staging instance:iraq db_dump:/tmp/staging_iraq.dump`
dumps to staging_iraq.dump
"""
require('environment', provided_by=SERVER_ENVIRONMENTS)
require('instance', provided_by='instance')
remote_file = file
if files.exists(file):
if not confirm("Remote file {file} exists and will be overwritten.
.format(file=remote_file)):
abort("ERROR: aborting")

Okay?"

# Don't need remote DB user and password because we're going to run pg_dump as
user postgres
sudo('pg_dump --format=custom --file={outputfile} {dbname}'
.format(dbname=env.db_name, outputfile=remote_file),
user='postgres')
print("Database from {environment} {instance} has been dumped to remote file
˓→{file}"
.format(environment=env.environment, instance=env.instance, file=remote_
˓→file))

˓→

@task
def local_restore(file):
"""
Restore a local dump file to the local instance's database.
:param file:
:return:
"""
# Find out the local DB settings
import sys
sys.path[0:0] = ['.']
from cts.settings.local import DATABASES
DB = DATABASES['default']
assert DB['ENGINE'] == 'django.contrib.gis.db.backends.postgis'
(continues on next page)

7.12. Fabric

87

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

dbname = DB['NAME']
owner = DB['USER'] or os.getenv('USER')
local('dropdb {dbname} || true'.format(dbname=dbname), shell="/bin/sh")
local('createdb --encoding UTF8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8 -˓→template=template0 --owner {owner} {dbname}'.format(owner=owner, dbname=dbname))
local('sudo -u postgres pg_restore -Ox -j4 --dbname={dbname} {file}'.
˓→format(dbname=dbname, file=file))

@task
def db_restore(file):
"""
Restore a remote DB dump file to a remote instance's database.
This will rename the existing database to {previous_name}_bak
and create a completely new database with what's in the dump.
If there's already a backup database, the restore will fail.
Example:
`fab staging instance:iraq db_restore:/tmp/staging_iraq.dump`
:param file: The remote file to restore.
"""
require('environment', provided_by=SERVER_ENVIRONMENTS)
require('instance', provided_by='instance')
renamed = False
restored = False
if not files.exists(file):
abort("Remote file {file} does not exist".format(file=file))
try:
if db_exists(env.db_name):
# Rename existing DB to backup
db_backup = '{dbname}_bak'.format(dbname=env.db_name)
if db_exists(db_backup):
if confirm("There's already a database named {db_backup}. Replace
˓→with new backup?"
.format(db_backup=db_backup)):
sudo('dropdb {db_backup}'.format(db_backup=db_backup),
user='postgres')
else:
abort("ERROR: There's already a database named {db_backup}. "
"Restoring would clobber it."
.format(db_backup=db_backup))
sudo('psql -c "ALTER DATABASE {dbname} RENAME TO {db_backup}"'
.format(dbname=env.db_name, db_backup=db_backup),
user='postgres')
renamed = True
print("Renamed {dbname} to {db_backup}".format(dbname=env.db_name, db_
˓→backup=db_backup))
remote_file = file
(continues on next page)

88

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

# Create new, very empty database.
# * We can't use --create on the pg_restore because that will always restore
˓→to whatever
#
db name was saved in the dump file, and we don't want to be restricted
˓→that way.
# * Any extensions the backed-up database had will be included in the restore,
˓→ so we
#
don't need to enable them now.
# If these parameters change, also change the parameters in conf/salt/project/
db/init.sls
# (TODO: we could use the output of psql -l to copy most of these settings
˓→from the
# existing database.)
sudo('createdb --encoding UTF8 --lc-collate=en_US.UTF-8 '
'--lc-ctype=en_US.UTF-8 --template=template0 --owner {owner} {dbname}'
.format(dbname=env.db_name, owner=env.db_owner),
user='postgres')
˓→

# Don't need remote DB user and password because we're going to
# run pg_restore as user postgres
sudo('pg_restore -1 --dbname={dbname} {filename}'
.format(dbname=env.db_name, filename=remote_file),
user='postgres')
restored = True
# Run ANALYZE on the db to help Postgres optimize how it accesses it
sudo('psql {dbname} -c ANALYZE'.format(dbname=env.db_name),
user='postgres')
print("Database for {environment} {instance} has been restored from remote
file {file}"
.format(environment=env.environment, instance=env.instance, file=remote_
˓→file))
finally:
if renamed and not restored:
print("Error occurred after renaming current database, trying to rename
˓→it back")
if db_exists(env.db_name):
# We already created the new db, but restore failed; delete it
sudo('dropdb {dbname}'.format(dbname=env.dbname), user='postgres')
sudo('psql -c "ALTER DATABASE {db_backup} RENAME TO {dbname}"'
.format(dbname=env.db_name, db_backup=db_backup),
user='postgres')
print("Successfully put back the original database.")
˓→

7.13 Filtering and Pagination with Django
If you want to build a list page that allows filtering and pagination, you have to get a few separate things to work
together. Django provides some tools for pagination, but the documentation doesn’t tell us how to make that work
with anything else. Similarly, django_filter makes it relatively easy to add filters to a view, but doesn’t tell you how to
add pagination (or other things) without breaking the filtering.
The heart of the problem is that both features use query parameters, and we need to find a way to let each feature
control its own query parameters without breaking the other one.
7.13. Filtering and Pagination with Django

89

Dan’s Cheat Sheets Documentation, Release 1

7.13.1 Filters
Let’s start with a review of filtering, with an example of how you might subclass ListView to add filtering. To make
it filter the way you want, you need to create a subclass of FilterSet and set filterset_class to that class. (See
that link for how to write a filterset.)
class FilteredListView(ListView):
filterset_class = None
def get_queryset(self):
# Get the queryset however you usually would. For example:
queryset = super().get_queryset()
# Then use the query parameters and the queryset to
# instantiate a filterset and save it as an attribute
# on the view instance for later.
self.filterset = self.filterset_class(self.request.GET, queryset=queryset)
# Return the filtered queryset
return self.filterset.qs.distinct()
def get_context_data(self, **kwargs):
context = super().get_context_data(**kwargs)
# Pass the filterset to the template - it provides the form.
context['filterset'] = self.filterset
return context

Here’s an example of how you might create a concrete view to use it:
class BookListView(FilteredListView):
filterset_class = BookFilterset

And here’s part of the template that uses a form created by the filterset to let the user control the filtering.
<h1>Books</h1>
<form action="" method="get">
{{ filterset.form.as_p }}
<input type="submit" />
</form>
<ul>
{% for object in object_list %}
<li>{{ object }}</li>
{% endfor %}
</ul>

filterset.form is a form that controls the filtering, so we just render that however we want and add a way to
submit it.
That’s all you need to make a simple filtered view.

7.13.2 Default values for filters
I’m going to digress slightly here, and show a way to give filters default values, so when a user loads a page initially,
for example, the items will be sorted with the most recent first. I couldn’t find anything about this in the django_filter
documentation, and it took me a while to figure out a good solution.
To do this, I override __init__ on my filter set and add default values to the data being passed:

90

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

class BookFilterSet(django_filters.FilterSet):
def __init__(self, data, *args, **kwargs):
data = data.copy()
data.setdefault('format', 'paperback')
data.setdefault('order', '-added')
super().__init__(data, *args, **kwargs)

I tried some other approaches, but this seemed to work out the simplest, in that it didn’t break or complicate things
anywhere else.

7.13.3 Pagination
Now let’s review pagination in Django.
Django’s ListView has some built-in support for pagination, which is easy enough to enable:
class BookListView(FilteredListView):
paginate_by = 50

Once paginate_by is set to the number of items you want per page, object_list will contain only the items
on the current page, and there will be some additional items in the context:
paginator A Paginator object
page_obj A Page object
is_paginated True if there are pages
We need to update the template so the user can control the pages.
Let’s start our template updates by just telling the user where we are:
{% if is_paginated %}
Page {{ page_obj.number }} of {{ paginator.num_pages }}
{% endif %}

To tell the view which page to display, we want to add a query parameter named page whose value is a page number.
In the simplest case, we can just make a link with ?page=N, e.g.:
<a href="?page=2">Goto page 2</a>

You can use the page_obj and paginator objects to build a full set of pagination links, but there’s a problem we
should solve first.

7.13.4 Combining filtering and pagination
Unfortunately, linking to pages as described above breaks filtering. More specifically, whenever you follow one of
those links, the view will forget whatever filtering the user has applied, because that filtering is also controlled by
query parameters, and these links don’t include the filter’s parameters.
So if you’re on a page https://example.com/objectlist/?type=paperback and then follow a page
link, you’ll end up at https://example.com/objectlist/?page=3 when you wanted to be at https://
example.com/objectlist/?type=paperback&page=3.
It would be nice if Django helped out with a way to build links that set one query parameter without losing the existing
ones, but I found a nice example of a template tag on StackOverflow and modified it slightly into this custom template
tag that helps with that:

7.13. Filtering and Pagination with Django

91

Dan’s Cheat Sheets Documentation, Release 1

# <app>/templatetags/my_tags.py
from django import template
register = template.Library()

@register.simple_tag(takes_context=True)
def param_replace(context, **kwargs):
"""
Return encoded URL parameters that are the same as the current
request's parameters, only with the specified GET parameters added or changed.
It also removes any empty parameters to keep things neat,
so you can remove a parm by setting it to ``""``.
For example, if you're on the page ``/things/?with_frosting=true&page=5``,
then
<a href="/things/?{% param_replace page=3 %}">Page 3</a>
would expand to
<a href="/things/?with_frosting=true&page=3">Page 3</a>
Based on
https://stackoverflow.com/questions/22734695/next-and-before-links-for-a-django˓→paginated-query/22735278#22735278
"""
d = context['request'].GET.copy()
for k, v in kwargs.items():
d[k] = v
for k in [k for k, v in d.items() if not v]:
del d[k]
return d.urlencode()

Here’s how you can use that template tag to build pagination links that preserve other query parameters used for things
like filtering:
{% load my_tags %}
{% if is_paginated %}
{% if page_obj.has_previous %}
<a href="?{% param_replace page=1 %}">First</a>
{% if page_obj.previous_page_number != 1 %}
<a href="?{% param_replace page=page_obj.previous_page_number %}">Previous</a>
{% endif %}
{% endif %}
Page {{ page_obj.number }} of {{ paginator.num_pages }}
{% if page_obj.has_next %}
{% if page_obj.next_page_number != paginator.num_pages %}
<a href="?{% param_replace page=page_obj.next_page_number %}">Next</a>
{% endif %}
<a href="?{% param_replace page=paginator.num_pages %}">Last</a>
{% endif %}
(continues on next page)

92

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<p>Objects {{ page_obj.start_index }}&mdash;{{ page_obj.end_index }}</p>
{% endif %}

Now, if you’re on a page like https://example.com/objectlist/?type=paperback&page=3, the
links will look like ?type=paperback&page=2, ?type=paperback&page=4, etc.

7.13.5 Useful links
• django_filter
• Django pagination
• param_replace template tag
I haven’t tried it, but if you need something more sophisticated for building these kinds of links, django-qurltemplatetag might be worth looking at.

7.14 Forms
• https://docs.djangoproject.com/en/stable/topics/forms/
• https://docs.djangoproject.com/en/stable/ref/forms/api/
A basic form:
from django import forms
class ContactForm(forms.Form):
subject = forms.CharField(max_length=100)

Processing a form in a view function:
def contact(request):
if request.method == 'POST': # If the form has been submitted...
form = ContactForm(request.POST) # A form bound to the POST data
if form.is_valid(): # All validation rules pass
# Process the data in form.cleaned_data
# ...
return HttpResponseRedirect('/thanks/') # Redirect after POST
else:
form = ContactForm() # An unbound form
return render_to_response('contact.html', {
'form': form,
})

https://docs.djangoproject.com/en/stable/topics/forms/modelforms/
A model form:
from django.forms import ModelForm, ValidationError
# Create the form class.
class ArticleForm(ModelForm):
class Meta:
(continues on next page)

7.14. Forms

93

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

model = Article
fields = ('name', 'title')
# or
exclude = ('birth_date')
def clean_fieldname(self):
if 'fieldname' in self.cleaned_data:
data = self.cleaned_data['fieldname']
if not /valid/:
raise ValidationError("msg")
return data
def clean(self):
data = self.cleaned_data
if not /valid/:
raise ValidationError("msg")
return data
# Creating a form to add an article.
form = ArticleForm()
...
new_article = form.save()
# Creating a form to change an existing article.
article = Article.objects.get(pk=1)
form = ArticleForm(instance=article)
...
form.save()
# Create a form to edit an existing Article, but use POST data to populate the form.
a = Article.objects.get(pk=1)
f = ArticleForm(request.POST, instance=a)
f.save()

Render form in template:
<!-- Using table - avoid that part - but this does show how to render the fields
˓→individually -->
<form {% if form.is_multipart %}enctype="multipart/form-data"{% endif %} action=
˓→"" method="post" class="uniForm">{% csrf_token %}
<table>
<fieldset>
{% if form.non_field_errors %}
<tr><td colspan="2">{{ form.non_field_errors }}</td></tr>
{% endif %}
{% for field in form %}
<tr{% if field.field.required %} class="required"{% endif %}>
<th style="text-align: left"><label for="{{ field.id_for_label }}">{{
˓→field.label }}:</label></th>
<td>{% if field.errors %}
{{ field.errors }}<br/>
{% endif %}
{{ field }}
or even
(continues on next page)

94

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<input id="{{ field.id_for_label }}"
name="{{ field.html_name }}"
value="{{ field.value }}"
{% if field.field.max_length != None %}
maxlength="{{ field.field.max_length }}"
{% endif %}
{% if field.field.min_length != None %}
minlength="{{ field.field.min_length }}"
{% endif %}
>
{% if field.help_text %}
<br/><span class="helptext">{{ field.help_text }}</span>
{% endif %}
</td>
</tr>
{% endfor %}
</fieldset>
</table>
<div class="ctrlHolder buttonHolder">
<button type="submit" class="primaryAction" name="submit_changes">Submit
˓→changes</button>
</div>
</form>
<!-- Using a list, which is preferred -->
<form {% if form.is_multipart %}enctype="multipart/form-data"{% endif %} action="
" method="post" class="uniForm">{% csrf_token %}
<fieldset>
<ul>
{{ form.as_ul }}
<li>
<div class="ctrlHolder buttonHolder">
<button type="submit" class="primaryAction" name="submit_
˓→changes">Submit changes</button>
</div>
</li>
</ul>
</fieldset>
</form>

˓→

7.15 Read-only form
Call this on the form:
def make_form_readonly(form):
"""
Set some attributes on a form's fields that, IN COMBINATION WITH TEMPLATE CHANGES,
allow us to display it as read-only.
"""
# Note that a new BoundField is constructed on the fly when you access
# form[name], so any data we want to persist long enough for the template
# to access needs to be on the "real" field. We just use the BoundField
(continues on next page)

7.15. Read-only form

95

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

# to get at the field value.
for name in form.fields:
field = form.fields[name]
bound_field = form[name]
if hasattr(field.widget, 'choices'):
try:
display_value = dict(field.widget.choices)[bound_field.value()]
except KeyError:
display_value = ''
else:
display_value = bound_field.value()
field.readonly = True
field.display_value = display_value

Do things like this in the templates:
{# Date field #}
{% if field.field.readonly %}
<span class="form-control">{{ field.value|date:'c' }}</span>
{% else %}
<input type="date" class="form-control" id="{{ field.id_for_label }}" name="{{
˓→field.html_name }}" value="{{ field.value|date:'c' }}">
{% endif %}
{# input fields #}
{% if field.field.readonly %}
<span class="form-control">{{ field.value }}</span>
{% else %}
<input type="{% block input_field_type %}text{% endblock %}" class="form-control"
˓→id="{{ field.id_for_label }}" name="{{ field.html_name }}" value="{{ field.value }}
˓→" {% if field.field.widget.attrs.placeholder %}placeholder="{{ field.field.widget.
˓→attrs.placeholder }}"{% endif %} {% block input_attrs %}{% endblock %}>
{% endif %}
{# select fields #}
{% if field.field.readonly %}
<span class="form-control">{{ field.field.display_value }}</span>
{% else %}
<select class="form-control" id="{{ field.id_for_label }}" name="{{ field.html_
˓→name }}" placeholder="">
{% for val, label in field.field.widget.choices %}
<option value="{{ val }}"{% if field.value|stringformat:'s' ==
˓→val|stringformat:'s' %} selected{% endif %}>{{ label }}</option>
{% endfor %}
</select>
{% endif %}

7.16 Quick And Dirty Home Page
In urls.py:

96

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

from django.views.generic import TemplateView
urlpatterns = [
...
url(r'^$', TemplateView.as_view(template_name='home.html'), name='home'),
]

7.17 Logging
Some best practices for Django logging.
https://docs.djangoproject.com/en/stable/topics/logging/
#configuring-logging

https://docs.djangoproject.com/en/stable/topics/logging/

https://docs.python.org/2/howto/logging.html
https://docs.python.org/2/library/logging.handlers.html#rotatingfilehandler https://docs.python.org/2/library/logging.
handlers.html#timedrotatingfilehandler
INFO level logging for celery is very verbose
If you have DEBUG on, Django logs all SQL queries

7.17.1 Default
Here’s what Django uses (around 1.7, anyway) if you don’t configure logging:
# Default logging for Django. This sends an email to the site admins on every
# HTTP 500 error. Depending on DEBUG, all other log records are either sent to
# the console (DEBUG=True) or discarded by mean of the NullHandler (DEBUG=False).
LOGGING = {
'version': 1,
'disable_existing_loggers': False,
'filters': {
'require_debug_false': {
'()': 'django.utils.log.RequireDebugFalse',
},
'require_debug_true': {
'()': 'django.utils.log.RequireDebugTrue',
},
},
'handlers': {
'console': {
'level': 'INFO',
'filters': ['require_debug_true'],
'class': 'logging.StreamHandler',
},
'null': {
'class': 'logging.NullHandler',
},
'mail_admins': {
'level': 'ERROR',
'filters': ['require_debug_false'],
'class': 'django.utils.log.AdminEmailHandler'
}
(continues on next page)

7.17. Logging

97

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

},
'loggers': {
'django': {
'handlers': ['console'],
},
'django.request': {
'handlers': ['mail_admins'],
'level': 'ERROR',
'propagate': False,
},
'django.security': {
'handlers': ['mail_admins'],
'level': 'ERROR',
'propagate': False,
},
'py.warnings': {
'handlers': ['console'],
},
}
}

7.17.2 Console
Log errors to console in local.py:
LOGGING.setdefault('formatters', {})
LOGGING['formatters']['verbose'] = {
'format': '[%(name)s] Message "%(message)s" from %(pathname)s:%(lineno)d in
˓→%(funcName)s'
}
LOGGING['handlers']['console'] = {
'class': 'logging.StreamHandler',
'formatter': 'verbose',
'level': 'ERROR',
}
LOGGING['loggers']['django'] = {
'handlers': ['console'],
'level': 'ERROR',
'propagate': True,
}

7.17.3 Development
For local development, we want lots of output saved to a log file in case we need to look back at a problem, but no
emailing of exceptions and such.
In settings:
LOG_DIR = os.path.join(PROJECT_ROOT, '..', 'log')
LOGGING = {
'version': 1,
'disable_existing_loggers': False,
(continues on next page)

98

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

'handlers': {
'console': { # Log to stdout
'level': 'INFO',
'class': 'logging.StreamHandler',
},
'file': {
'level': 'DEBUG',
'class': 'logging.FileHandler',
'filename': os.path.join(LOG_DIR, 'django_debug.log',
}
},
'root': { # For dev, show errors + some info in the console
'handlers': ['console'],
'level': 'INFO',
},
'loggers': {
'django.request': { # debug logging of things that break requests
'handlers': ['file'],
'level': 'DEBUG',
'propagate': True,
},
},
}

Or how about:
LOGGING = {
'version': 1,
'disable_existing_loggers': False,
'formatters': {
'simple': {
'format': '%(name)-20s %(levelname)-8s %(message)s',
},
},
'handlers': {
'console': { # Log to stdout
'level': 'INFO',
'class': 'logging.StreamHandler',
'formatter': 'simple',
},
},
'root': { # For dev, show errors + some info in the console
'handlers': ['console'],
'level': 'INFO',
},
}

7.17.4 Staging
FIXME: Add celery exceptions
@tobiasmcnulty also mentioned: “re: celery error emails, this is a good setting to have enabled: http://celery.
readthedocs.org/en/latest/configuration.html#celery-send-task-error-emails”
On staging, we still want lots of info logged semi-permanently (to files), but we also want to be emailed about exceptions to make sure we find out about problems before we deploy them to production.

7.17. Logging

99

Dan’s Cheat Sheets Documentation, Release 1

Emails should go to the devs, not the client or production site admins.
Like so:
ADMINS = (
('XXX DevTeam', 'xxx-dev-team@example.com'),
)
LOG_DIR = os.path.join(PROJECT_ROOT, '..', 'log')
LOGGING = {
'version': 1,
'disable_existing_loggers': False,
'handlers': {
'file': { # Rotate log file daily, only keep 1 backup
'level': 'DEBUG',
'class': 'logging.handlers.TimedRotatingFileHandler',
'filename': os.path.join(LOG_DIR, 'django_debug.log',
'when': 'd',
'interval': 1,
'backupCount': 1,
},
'mail_admins': {
'level': 'ERROR',
'class': 'django.utils.log.AdminEmailHandler'
},
},
# EMAIL all errors (might not want this, but let's try it)
'root': {
'handlers': ['mail_admins'],
'level': 'ERROR',
},
'loggers': {
'django.request': {
'handlers': ['file'],
'level': 'INFO',
'propagate': True,
},
},
}

7.17.5 Production
Mark says: for production I like to log to syslog which can then be shipped elsewhere without changing the application
(https://docs.python.org/2/library/logging.handlers.html#logging.handlers.SysLogHandler ?)
@Scottm and I have been talking about making that more common: log to syslog, ship to Logstash, monitor via
Kibana http://www.elasticsearch.org/overview/kibana/
getting Nginx to log to syslog is kind of a pain you basically have to get syslog to monitor the file and ship it Logstash
+ Kibana looks much easier to manage/configure than Graylog2
the plan was to add it to Ona but that isn’t done yet (as of Aug 28, 2014) CCSR was/is using Graylog2 Minidam does
syslog –> Loggly libya is using logstash -> graylog (in addition to sentry)

100

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

7.17.6 Example
Here’s what we’ve got set up for Django logging on one project. This sends everything level INFO and higher to a
local log file and a Graylog instance. Anything ERROR and higher is emailed to admins and sent to a Sentry instance,
which can send more notifications.
In environment:
SENTRY_DSN: http://long_hex_string:long_hex_string@hostname:9000/3

Requirements:
raven==3.6.1

Settings:
INSTALLED_APPS = (
...
'raven.contrib.django.raven_compat',
...
}

# Sentry logging client

CELERY_SEND_TASK_ERROR_EMAILS = True
# Send ERRORS to email and sentry.
# Send a fair bit of info to graylog and a local log file
# (but not debug level messages, ordinarily).
LOGGING = {
'version': 1,
'disable_existing_loggers': True,
'filters': {
# This filter strips out request information from the message record
# so it can be sent to Graylog (the request object is not picklable).
'django_exc': {
'()': 'our_filters.RequestFilter',
},
'require_debug_false': {
'()': 'django.utils.log.RequireDebugFalse'
},
# This filter adds some identifying information to each message, to make
# it easier to filter them further, e.g. in Graylog.
'static_fields': {
'()': 'our_filters.StaticFieldFilter',
'fields': {
'deployment': 'project_name',
'environment': 'staging'
# can be overridden, e.g. 'staging' or
˓→'production'
},
},
},
'formatters': {
'basic': {
'format': '%(asctime)s %(name)-20s %(levelname)-8s %(message)s',
},
},
'handlers': {
'file': {
'level': 'DEBUG', # Nothing here logs DEBUG level messages ordinarily
(continues on next page)

7.17. Logging

101

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

'class': 'logging.handlers.RotatingFileHandler',
'formatter': 'basic',
'filename': os.path.join(LOG_ROOT, 'django.log'),
'maxBytes': 10 * 1024 * 1024, # 10 MB
'backupCount': 10,
},
'graylog': {
'level': 'INFO',
'class': 'graypy.GELFHandler',
'host': env_or_default('GRAYLOG_HOST', 'monitor.caktusgroup.com'),
'port': 12201,
'filters': ['static_fields', 'django_exc'],
},
'mail_admins': {
'level': 'ERROR',
'class': 'django.utils.log.AdminEmailHandler',
'include_html': False,
'filters': ['require_debug_false'],
},
'sentry': {
'level': 'ERROR',
'class': 'raven.contrib.django.raven_compat.handlers.SentryHandler',
},
},
'root': {
# graylog (or any handler using the 'django_exc' filter ) should be last
# because it will alter the LogRecord by removing the `request` field
'handlers': ['file', 'mail_admins', 'sentry', 'graylog'],
'level': 'WARNING',
},
'loggers': {
# These 2 loggers must be specified, otherwise they get disabled
# because they are specified by django's DEFAULT_LOGGING and then
# disabled by our 'disable_existing_loggers' setting above.
# BEGIN required loggers #
'django': {
'handlers': [],
'propagate': True,
},
'py.warnings': {
'handlers': [],
'propagate': True,
},
# END required loggers #
# The root logger will log anything WARNING and higher, so there's
# no reason to add loggers here except to add logging of lower-level
˓→information.
'libya_elections': {
'handlers': ['file', 'graylog'],
'level': 'INFO',
},
'nlid': {
'handlers': ['file', 'graylog'],
'level': 'INFO',
},
'register': {
'handlers': ['file', 'graylog'],
(continues on next page)

102

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

'level': 'INFO',
},
'bulk_sms': {
'handlers': ['file', 'graylog'],
'level': 'INFO',
},
}
}
#
# our_filters.py
#
import logging

class QuotelessStr(str):
"""
Return the repr() of this string *without* quotes. This is a
temporary fix until https://github.com/severb/graypy/pull/34 is resolved.
"""
def __repr__(self):
return self

class StaticFieldFilter(logging.Filter):
"""
Python logging filter that adds the given static contextual information
in the ``fields`` dictionary to all logging records.
"""
def __init__(self, fields):
self.static_fields = fields
def filter(self, record):
for k, v in self.static_fields.items():
setattr(record, k, QuotelessStr(v))
return True

class RequestFilter(logging.Filter):
"""
Python logging filter that removes the (non-pickable) Django ``request``
object from the logging record.
"""
def filter(self, record):
if hasattr(record, 'request'):
del record.request
return True

7.17.7 Including info like the emailed errors do
from django.views.debug import TECHNICAL_500_TEXT_TEMPLATE, get_safe_settings, \
get_exception_reporter_filter
from django.views.decorators.debug import sensitive_post_parameters
t = Template(TECHNICAL_500_TEXT_TEMPLATE)
(continues on next page)

7.17. Logging

103

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

filter = get_exception_reporter_filter(request)
r = t.render(Context({
'request': request,
'is_email': True,
'filtered_POST': filter.get_post_parameters(request),
'settings': get_safe_settings(),
'server_time': timezone.now(),
'django_version_info': get_version(),
}, autoescape=False))
logger.error(
"Got CSRF failure, reason=%s. %s", reason, r,
)

7.18 Django login and logout
Django doc
• In settings.py, add:
LOGIN_URL = '/login/'

• In urls.py, add:
urlpatterns += patterns('',
(r'^login/$', django.contrib.auth.views.login),
(r'^logout/$', django.contrib.auth.views.logout),
)

• Create a template “registration/login.html”, copying from the sample in the doc
• Add a logout link to your base template:
<a href="/logout/">Logout</a>

• On each view function where users should be logged in before using, add the decorator:
@login_required
def myview(...)

7.19 Middleware
7.19.1 Middleware ordering
Middleware ordering docs
Re: whitenoise middleware: The WhiteNoise middleware should be placed directly after the Django SecurityMiddleware (if you are using it) and before all other middleware:
Mostly copy of the Django middleware docs (2.1):
Here are some hints about the ordering of various Django middleware classes:

104

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

1. SecurityMiddleware
It should go near the top of the list if you’re going to turn on the SSL redirect as that avoids running through a
bunch of other unnecessary middleware.
2. UpdateCacheMiddleware
Before those that modify
LocaleMiddleware).

the

Vary

header

(SessionMiddleware,

GZipMiddleware,

3. GZipMiddleware
Before any middleware that may change or use the response body.
After UpdateCacheMiddleware: Modifies Vary header.
4. SessionMiddleware
After UpdateCacheMiddleware: Modifies Vary header.
5. ConditionalGetMiddleware
Before any middleware that may change the response (it sets the ETag header).
After GZipMiddleware so it won’t calculate an ETag header on gzipped contents.
6. LocaleMiddleware
One of the topmost, after SessionMiddleware (uses session data) and UpdateCacheMiddleware
(modifies Vary header).
7. CommonMiddleware
Before any middleware that may change the response (it sets the Content-Length header). A middleware
that appears before CommonMiddleware and changes the response must reset Content-Length.
Close to the top: it redirects when APPEND_SLASH or PREPEND_WWW are set to True.
8. CsrfViewMiddleware
Before any view middleware that assumes that CSRF attacks have been dealt with.
It must come after SessionMiddleware if you’re using CSRF_USE_SESSIONS.
9. AuthenticationMiddleware
After SessionMiddleware: uses session storage.
10. MessageMiddleware
After SessionMiddleware: can use session-based storage.
11. FetchFromCacheMiddleware
After any middleware that modifies the Vary header: that header is used to pick a value for the cache hash-key.
12. FlatpageFallbackMiddleware
Should be near the bottom as it’s a last-resort type of middleware.
13. RedirectFallbackMiddleware
Should be near the bottom as it’s a last-resort type of middleware.

7.19. Middleware

105

Dan’s Cheat Sheets Documentation, Release 1

7.20 Migrations
Data migration:
def no_op(apps, schema_editor):
pass
def create_types(apps, schema_editor):
ServiceType = apps.get_model('services', 'ServiceType')
db_alias = schema_editor.connection.alias
# do stuff
ServiceType.objects.using(db_alias)....

class Migration(migrations.Migration):
...
operations = [
migrations.RunPython(create_types, no_op),
]

7.20.1 Getting past bad migrations
For example, earlier migrations refer to models in apps that no longer exist.
The simplest thing is to start from an existing database so you don’t have to migrate.
If you need to start from scratch, you should be able to:
syncdb --all
migrate --fake

7.21 NGINX
Some tips on Nginx for use with Django

7.21.1 Files
Just add a new file to /etc/nginx/sites-enabled for each site, making sure server_name is set correctly
in each.

7.21.2 Redirecting to SSL
We usually want to force SSL:
server {
listen *:80;
listen [::]:80;
server_name DOMAIN;
access_log PATH_access.log;
error_log PATH_error.log;
return 301 https://DOMAIN$request_uri;
}

106

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

7.21.3 Proxying to gunicorn
Serve static and media files with nginx, and proxy everything else to Django:
upstream django {
server unix:/tmp/PATH fail_timeout=0;
}
server {
listen *:443 ssl;
# add spdy here too if you want
listen [::]:443 ssl;
server_name DOMAIN;
ssl_certificate PATH.crt;
ssl_certificate_key PATH.key;
access_log PATH_access.log;
error_log PATH_error.log;
root PATH;
location /media {
alias PATH;
}
location /static {
alias PATH;
}
location / {
client_max_body_size 500M;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header Host $host;
proxy_redirect off;
proxy_buffering on;
proxy_intercept_errors on;
proxy_pass http://django;
}
# See https://www.trevorparker.com/hardening-ssl-in-nginx/
ssl_protocols
TLSv1 TLSv1.1 TLSv1.2;
ssl_prefer_server_ciphers on;
ssl_ciphers
DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:ECDHE˓→RSA-AES1\
28-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA˓→AES256-GCM\
-SHA384:kEDH+AESGCM:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128˓→SHA256:DHE-RSA-AES\
256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA˓→AES128-SH\
A256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA˓→AES256-SH\
A384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM˓→SHA384:AES128-SH\
A256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!
˓→EXPORT:!DES:\
!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA;
ssl_session_timeout
5m;
ssl_session_cache
shared:SSL:10m;
add_header Strict-Transport-Security max-age=31536000;
(continues on next page)

7.21. NGINX

107

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

}

7.22 Permissions
(Note: this page is about authorization, not authentication.)
Link: https://docs.djangoproject.com/en/stable/topics/auth/default/#topic-authorization
User objects have two many-to-many fields: groups and user_permissions. User objects can access their related objects
in the same way as any other Django model:
myuser.groups = [group_list]
myuser.groups.add(group, group, ...)
myuser.groups.remove(group, group, ...)
myuser.groups.clear()
myuser.user_permissions = [permission_list]
myuser.user_permissions.add(permission, permission, ...)
myuser.user_permissions.remove(permission, permission, ...)
myuser.user_permissions.clear()

Assuming you have an application with an app_label foo and a model named Bar, to test for basic permissions you
should use:
• add: user.has_perm(‘foo.add_bar’)
• change: user.has_perm(‘foo.change_bar’)
• delete: user.has_perm(‘foo.delete_bar’)
Note: There is no default permission for read access.
The Permission model is rarely accessed directly, but here it is:
permission = Permission.objects.create(codename='can_publish',
name='Can Publish Posts', # verbose human˓→readable name
content_type=content_type)

Permissions are more commonly referred to by a string, of the form “app_label.codename”. E.g., if user.
has_perm('myapp.codename'): do something.
Confusingly, the Permission model has no app_label field. It uses content_type__app_label for that.
Warning: This means all permissions need a content type, whether it makes sense for that permission to be
applied to a particular model or not.
To create a new permission programmatically:
content_type = ContentType.objects.get_for_model(BlogPost)
permission = Permission.objects.create(codename='can_publish',
name='Can Publish Posts',
content_type=content_type)

108

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

7.22.1 Default permissions
https://docs.djangoproject.com/en/stable/topics/auth/default/#default-permissions
For every model in an installed app, Django automatically creates three permissions: applabel.add_modelname, applabel.change_modelname, and applabel.delete_modelname, where the modelname is lowercased.

7.22.2 Adding model permissions
https://docs.djangoproject.com/en/stable/ref/models/options/#permissions
You can ask Django to create more permissions for a model:
class Meta:
permissions = [
('codename', 'verbose name'),
]

When the table is created during syncdb, Django will create the additional Permission objects too.
In Django 1.11 (and probably earlier, but definitely not before 1.7), if you edit these permissions and
makemigrations, Django will create a migration for you that when run, will add any missing migrations. (I
don’t know whether it’ll update verbose names of existing permissions.)
You can programmatically force Django to create additional Permissions with code like:
from django.db.models import get_models, get_app
from django.contrib.auth.management import create_permissions
apps = set([get_app(model._meta.app_label) for model in get_models()])
for app in apps:
create_permissions(app, None, 2)

7.22.3 Best practices
• Plan not to give users specific permissions, except when you have to make an exception to your usual policies.
• Design groups with useful sets of permissions.
• Plan to add users to the appropriate groups depending on their roles.
• Provide a way to ensure the groups continue to have the permissions you want.
Fixtures aren’t a bad way to provide initial data, but setting them up for automatic loading is deprecated with Django
1.7 and will go away with Django 2.0. Instead, load them from a data migration. This is better in some ways anyway,
because the migration will use the same version of the models that the fixtures were written for at the time. (Though,
this doesn’t matter so much for Permissions and Groups, which we don’t really expect to change their schemas. . . )
Add utility methods like this, maybe in accounts/utils.py or equivalent:
def permission_names_to_objects(names):
"""
Given an iterable of permission names (e.g. 'app_label.add_model'),
return an iterable of Permission objects for them. The permission
must already exist, because a permission name is not enough information
to create a new permission.
"""
(continues on next page)

7.22. Permissions

109

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

result = []
for name in names:
app_label, codename = name.split(".", 1)
# Is that enough to be unique? Hope so
try:
result.append(Permission.objects.get(content_type__app_label=app_label,
codename=codename))
except Permission.DoesNotExist:
logger.exception("NO SUCH PERMISSION: %s, %s" % (app_label, codename))
raise
return result

def get_all_perm_names_for_group(group):
# Return the set of permission names that the group should contain

def create__or_update_groups():
for group_name, perm_names in GROUP_PERMISSIONS.iteritems():
group, created = Group.objects.get_or_create(name=group_name)
perms_to_add = permission_names_to_objects(get_all_perm_names_for_
˓→group(group))
group.permissions.add(*perms_to_add)
if not created:
# Group already existed - make sure it doesn't have any perms we didn't
˓→want
to_remove = set(group.permissions.all()) - set(perms_to_add)
if to_remove:
group.permissions.remove(*to_remove)

7.22.4 Checking permissions in templates
https://docs.djangoproject.com/en/stable/topics/auth/default/#authentication-data-in-templates
{% if user.is_authenticated %} {% if perms.applabel %} {# user has any permissions in app applabel #}
{% if ‘applabel’ in perms %} {# same as above %} {% if perms.applabel.change_thing %} {# user has
‘change_thing’ permission in app applabel #} {% if ‘applabel.change_thing’ in perms %} {# same as
above #}

7.23 Queries and Querysets
7.23.1 Field lookups
exact, iexact, contains, icontains, startswith, istartswith, endswith, iendswith, in, gt, gte, lt, lte, range, year, month,
day, week_day, hour, minute, second, isnull, search, regex

7.23.2 Optimizing Django queries on big data
Suppose you have a query that needs to run against a table or tables with many millions of rows. Maybe you need
to operate on a couple million of them. What are the do’s and don’t’s of a Django query that will not pessimize
performance (time and memory use)?

110

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

• Don’t bother with .iterator(), it downloads the whole result and then iterates over it. It does not do what many
of us think/thought it did (use a database cursor to pull down the results only as you work through them)
• Do limit the query ([start:end]) and run it repeatedly in reasonable sized batches, to avoid downloading too big
a chunk
• Do use .only() and its kin to minimize how much of each record is downloaded to what you need
• Do not order_by() unless you must - it forces the DB to collect the results of the whole query first so it can sort
them, even if you then limit the results you retrieve
• Same for .distinct().

7.23.3 The model that a queryset is over
queryset.model

7.23.4 Combining querysets
Given two querysets over the same model, you can do things like this:
queryset = queryset1 & queryset2
queryset = queryset1 | queryset2
queryset = queryset1 & ~queryset2

(similar to Q objects)

7.23.5 Custom QuerySets
Calling custom QuerySet methods from the manager
Creating a manager with QuerySet methods¶:
class Person(models.Model):
...
people = PersonQuerySet.as_manager()

class BaseManager(....):
....
class MyModel(models.Model):
objects = BaseManager.from_queryset(CustomQuerySet)()

7.23.6 Custom Lookups
Adding to the kwargs you can pass to filter and exclude etc.
Custom Lookups

7.23. Queries and Querysets

111

Dan’s Cheat Sheets Documentation, Release 1

7.24 Security
7.24.1 Protect internal services
Vse a VPN, or check out oauth2_proxy or similar services.

7.24.2 Django
(django-secure appears to be abandoned. Last change was in 2014, and it doesn’t load under Django 1.11/Python 3.6.)
-Best practice: install django-secure and run manage.py checksecure to make sure all the right settings
are enabled.See also OWASP.

7.24.3 Admin
Don’t leave it externally accessible, even with a password.

7.24.4 SSH
Two important settings in /etc/sshd_config:
• Disable root login:
PermitRootLogin no

• Disable password auth:
PasswordAuthentication no

Also consider changing to some port other than 22.

7.24.5 SSL
SEE ALSO NGINX and Django docs on SSL and https.
Basically, make sure nginx is setting X-Forwarded-Proto, then add to settings:
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')

Django security
djangocon 2011 Paul McMillan
http://subversivecode.com/talks/djangocon-us-2011
HSTS
django needs better password hash (SHA1 not broken but very fast)
OpenID much more secure against password cracking (because cracker won’t have passwords)
password reset strings can be eventually worked out with a timing attack (if you have a long time and a fast connection)
same for which userids exist on the site
112

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

you should do rate limiting:
mod_evasive (apache) HttpLimitReqModule (nginx)
do NOT use random.Random() for security functions, not cryptographically secure; use random.SystemRandom()
instead e.g.:
from random import SystemRandom as random
xxxx random.choice(yyyy)...

Be very careful with pickle, it’ll execute anything in the pickled data when you unpickle it
BOOK: The web application hacker’s handbook (new version coming out soon (as of 9/8/2011))
SITE: lost.org? (not sure I heard that right)(no I didn’t)

7.25 Sentry on a Django site
Requirements:
raven==6.6.0

# or whatever

Settings:
INSTALLED_APPS += ('raven.contrib.django.raven_compat',)
LOGGING[handlers]['sentry'] = {
'level': 'ERROR', # To capture more than ERROR, change to WARNING, INFO, etc.
'class': 'raven.contrib.django.raven_compat.handlers.SentryHandler',
# 'tags': {'custom-tag': 'x'},
}
LOGGING['root']['handlers'].append('sentry')
# OR
LOGGING['root'] = {
'level': 'WARNING',
'handlers': ['sentry'],
}
RAVEN_CONFIG = {
'dsn': '{{ RAVEN_DSN }}',
'release': '{{ commit }}',
'site': 'TypeCoach',
'environment': '{{ env }}',
'processors': [
'raven.processors.SanitizePasswordsProcessor',
]
}

Base template:
{% load raven %}
<!doctype html>
<head>
...
<script src="https://cdn.ravenjs.com/3.23.2/raven.min.js" crossorigin="anonymous">
˓→</script>
<script>Raven.config('{% sentry_public_dsn %}').install()</script>

7.25. Sentry on a Django site

113

Dan’s Cheat Sheets Documentation, Release 1

wsgi.py:
from raven.contrib.django.raven_compat.middleware.wsgi import Sentry
from django.core.wsgi import get_wsgi_application
application = Sentry(get_wsgi_application())

7.26 Settings
7.26.1 Using the right one
Baumgartner suggests symlinking the desired one (e.g. dev.py or deploy.py) to local.py and hard-coding that in manage.py.
Greenfelds suggest. . . (FILL THIS IN)
12-factor says there should only be one settings file, and any values that vary by deploy should be pulled from the
environment. See Env vars.

7.26.2 Secret key
Generate a secret key:
from django.utils.crypto import get_random_string
chars = 'abcdefghijklmnopqrstuvwxyz0123456789!@#$%^&*(-_=+)'
SECRET_KEY = get_random_string(50, chars)

(https://github.com/django/django/blob/master/django/core/management/commands/startproject.py#L26)

7.26.3 Env vars
Suppose you have env vars in a .env file:
SECRET_KEY=jdfsdfsdf
PASSWORD=jsdkfjsdlkfjdsf

You can load them into Django using dotenv. Pop open manage.py. Add:
import dotenv
dotenv.read_dotenv()

Or in a settings file:
SECRET_KEY = os.environ.get("SECRET_KEY")

And if they’re not all strings, use ast:
import ast, os
DEBUG = ast.literal_eval(os.environ.get("DEBUG", "True"))
TEMPLATE_DIRS = ast.literal_eval(os.environ.get("TEMPLATE_DIRS", "/path1,/path2"))

You can load them into a shell this way:

114

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

export $(cat .env | grep -v ^# | xargs)

7.27 Templates
7.27.1 Template tag to set variables
Example usage:
{% set foo="bar" a=1 %}
...
Hello everyone, foo is {{ foo }} and a is {{ a }}.

Here’s the code:
from django import template
register = template.Library()
@register.simple_tag(takes_context=True)
def set(context, **kwargs):
context.update(kwargs)
return ''

7.27.2 Working block tag with arguments
Here’s an example of a working block tag. Usage is {% detail_link arg1=1 arg2=2 %}...{%
end_detail_link %} and what ends up in the output is <a arg1="1" arg2="2" target="_blank">.
..</a>.
The code:
from
from
from
from

django import template
django.template.base import token_kwargs, TemplateSyntaxError
django.utils.html import format_html, format_html_join
django.utils.safestring import mark_safe

register = template.Library()

def do_detail_link(parser, token):
"""
Block tag to help render links to detail pages consistently
with an option to open in a new tab or window.
{% detail_link href="xxxx" arg1="yyy" ... %} what to display {% end_detail_link %}
is rendered as
<a href="xxxx" arg1="yyy" ... target="_blank" %} what to display </a>
This adds `target="_blank"` to open the link in a new tab or window.
That's the main purpose of this block tag (and so we can disable that in
one place, here, if we ever want to). But you can override it by specifying
(continues on next page)

7.27. Templates

115

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

another value for `target` if you want.
"""
# This is called each time a detail_link tag is encountered while parsing
# a template.
# Split the contents of the tag itself
args = token.split_contents() # e.g. ["detail_link", "arg1='foo'", "arg2=bar"]
tag_name = args.pop(0)

˓→

# Parse out the arg1=foo arg2=bar ... arguments from the arg list into a
dictionary.
# kwargs will have "arg1" etc as keys, while the values will be
# template thingies that can later be rendered using different contexts
# to get their value at different times.
kwargs = token_kwargs(args, parser)
# If there are any args left, we have a problem; this tag only
# accepts kwargs.
if args:
raise TemplateSyntaxError("%r only accepts named kwargs" % tag_name)
# Open in new tab unless otherwise told (by setting target to something else).
if 'target' not in kwargs:
kwargs['target'] = parser.compile_filter('"_blank"')
# Parse inside of block *until* we're looking at {% end_detail_link %},
# then we don't care about end_detail_link, so discard it.
# When we return, the parsing will then continue after our end tag.
nodelist = parser.parse(('end_detail_link',))
parser.delete_first_token()
# Now return a node for the parsed template
return DetailLinkNode(nodelist, tag_name, kwargs)

register.tag('detail_link', do_detail_link)

class DetailLinkNode(template.Node):
"""
Stores info about one occurrence of detail_link in a template.
See also `do_detail_link`.
"""
def __init__(self, nodelist, tag_name, kwargs):
self.nodelist = nodelist
self.tag_name = tag_name
self.kwargs = kwargs
def render(self, context):
"""Turn this node into text using the given context."""
# Start with the part inside the block
innerds = self.nodelist.render(context)
# Now work out the <a> wrapper.
args = format_html_join(
(continues on next page)

116

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

' ',
'{}="{}"',
((name, value.resolve(context)) for name, value in self.kwargs.items())
)
result = format_html(
mark_safe("<a {}>{}</a>"),
args,
mark_safe(innerds)
)
return result

7.27.3 Debugging template syntax errors during tests
The normal error message when a view fails rendering a template during testing gives no clue where the error is.
You can get a better idea by temporarily editing your local Django installation. Find the file django/template/
base.py. Around line 194 (in Django 1.8.x), in the __init__ method of the Template class, look for this
code:
self.nodelist = engine.compile_string(template_string, origin)

and change it to:
try:
self.nodelist = engine.compile_string(template_string, origin)
except TemplateSyntaxError:
print("ERROR COMPILING %r" % origin.name)
raise

TODO: would be nice to get a line number too (this just gives a filename, which is often enough in combination with
the error message).

7.28 Testing
self.assertEqual(a, b, msg=None)

rsp = self.client.get(url, [follow=True])
rsp = self.client.post(url, data, [follow=True])
rsp.content is a byte string
rsp['HeaderName']
rsp.context['template_var']
assert self.client.login(**login_parms)
login(email='foo@example.com', password='cleartextpassword')

# http://docs.python.org/library/unittest.html # https://docs.djangoproject.com/en/stable/topics/testing/
from django.test import TestCase
from django.contrib.auth.models import User
(continues on next page)

7.28. Testing

117

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

class XxxTest(TestCase):
def setUp(self):
self.user = User.objects.create_user('tester', 'test@example.com', 'testpass')
def test_something(self):
response = self.client.get(show_timemap)
self.assertEqual(response.status_code, 200)
self.assertEqual(response.context['lat'], '123.123')
self.assertEqual(response.context['lon'], '456.456')
self.assertContains(response, "some text")
self.assertNotContains(response, "other text")
self.assertIsNone(val)
self.assertIsNotNone(val)
self.assertIn(thing, iterable) # Python >= 2.7
self.assertNotIn(thing, iterable) # Python >= 2.7

# Test uploading a file
(from https://docs.djangoproject.com/en/stable/topics/testing/tools/#django.test.Client.post)
Submitting files is a special case. To POST a file, you need only provide the file field name as a key, and a file handle
to the file you wish to upload as a value. For example:
>>> c = Client()
>>> with open('wishlist.doc') as fp:
...
c.post('/customers/wishes/', {'name': 'fred',
...
'attachment': fp})

(The name attachment here is not relevant; use whatever name your file-processing code expects.)
Note that if you wish to use the same file handle for multiple post() calls then you will need to manually reset the file
pointer between posts. The easiest way to do this is to manually close the file after it has been provided to post(), as
demonstrated above.
You should also ensure that the file is opened in a way that allows the data to be read. If your file contains binary data
such as an image, this means you will need to open the file in rb (read binary) mode.

7.28.1 Writing a test for a separately-distributed Django app
# setup.py:
...
setup(
...
test_suite="runtests.runtests",
...
)

# runtests.py:
#!/usr/bin/env python
import os
import sys
from django.conf import settings
(continues on next page)

118

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

if not settings.configured:
settings.configure(
DATABASES={
'default': {
'ENGINE': 'django.db.backends.sqlite3',
'NAME': ':memory:',
}
},
INSTALLED_APPS=(
'selectable',
),
SITE_ID=1,
SECRET_KEY='super-secret',
ROOT_URLCONF='selectable.tests.urls',
)

from django.test.utils import get_runner

def runtests():
TestRunner = get_runner(settings)
test_runner = TestRunner(verbosity=1, interactive=True, failfast=False)
args = sys.argv[1:] or ['selectable', ]
failures = test_runner.run_tests(args)
sys.exit(failures)

if __name__ == '__main__':
runtests()

7.29 Translation
Switch context to a new language:
from django.utils import translation
translation.activate('en-us')

(link to Using translations outside views and templates)

7.30 URLs
7.30.1 reverse
from django.core.urlresolvers import reverse
reverse(viewname='myview',
urlconf=None,
args=(1, 2),

# remaining args optional

(continues on next page)

7.29. Translation

119

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

kwargs={'pk': foo.pk},
current_app=None)

7.30.2 redirect
from django.shortcuts import redirect

redirect(to[, permanent=False ], *args, **kwargs)
Returns an HttpResponseRedirect to the appropriate URL for the arguments passed.
The arguments could be:
• A model: the model’s get_absolute_url() function will be called.
• A view name, possibly with arguments: urlresolvers.reverse() will be used to reverse-resolve the name.
• A URL, which will be used as-is for the redirect location.
By default issues a temporary redirect; pass permanent=True to issue a permanent redirect
Examples
You can use the redirect() function in a number of ways.
1. By passing some object; that object’s get_absolute_url() method will be called to figure out the redirect
URL:
def my_view(request):
...
object = MyModel.objects.get(...)
return redirect(object)

2. By passing the name of a view and optionally some positional or keyword arguments; the URL will be reverse
resolved using the reverse() method:
def my_view(request):
...
return redirect('some-view-name', foo='bar')

3. By passing a hardcoded URL to redirect to:
def my_view(request):
...
return redirect('/some/url/')

This also works with full URLs:
def my_view(request):
...
return redirect('http://example.com/')

By default, redirect() returns a temporary redirect. All of the above forms accept a permanent argument; if set
to True a permanent redirect will be returned:

120

Chapter 7. Django

Dan’s Cheat Sheets Documentation, Release 1

def my_view(request):
...
object = MyModel.objects.get(...)
return redirect(object, permanent=True)

https://docs.djangoproject.com/en/stable/topics/http/urls/
from django.conf.urls.defaults import patterns, include, url
from django.contrib import admin admin.autodiscover()
urlpatterns = patterns('',
(r'^polls/', include('polls.urls')),
url(r'^admin/', include(admin.site.urls)),
)
urlpatterns = patterns('polls.views',
(r'^, 'index'),
(r'^(?P<poll_id>\d+)/, 'detail'),
(r'^(?P<poll_id>\d+)/results/, 'results'),
(r'^(?P<poll_id>\d+)/vote/, 'vote'),
url(r'^(?P<poll_id>\d+)/foo/, 'fooview', name='app-viewname'),
)

7.31 Django with Vue
Also Dokku. . .
If you want to serve your Django app, your Django app’s static files, and the files constituting your vue app, all from
your Django process, using whitenoise, this seems to work.
Note: this doesn’t work as well locally; see end.

7.31.1 Set up Django to gather static files from dist
In settings:
STATICFILES_DIRS = [
...
os.path.join(BASE_DIR, 'dist'),
...
]

7.31.2 Configure whitenoise
Do the basic Django configuration, but add a few things:
WHITENOISE_INDEX_FILE = True
WHITENOISE_ROOT = os.path.join(STATIC_ROOT, 'vue')

WHITENOISE_INDEX_FILE tells whitenoise to serve index.html for / when it seems appropriate.
WHITENOISE_ROOT tells whitenoise to serve files at the root URL if it finds them in WHITENOISE_ROOT. E.g. if
a request comes in for /app.js and there’s a file <WHITENOISE_ROOT>/app.js, then Whitenoise will handle
the request and return that file.

7.31. Django with Vue

121

Dan’s Cheat Sheets Documentation, Release 1

7.31.3 At deploy
Build your vue app for production and have the resulting files put under dist/vue:
mkdir -p dist/vue
yarn run build --dest=dist/vue

(that runs vue-cli-service build).
Run collectstatic. It’ll gather the files from dist along with other static files:
python manage.py collectstatic --noinput

Now ‘runserver’ or whatever.

7.31.4 Running locally
This prebuilds the Vue stuff, so if you’re doing development and would like things to rebuild when you edit files, this
won’t do that.
Misc to file:
Avoid circular imports:
from django.db.models import get_model
MyModel = get_model('applabel', 'mymodelname'.lower())

122

Chapter 7. Django

CHAPTER

8

Docker

8.1 Terminology
Container: A container is used to execute an image. See docker run, docker-compose up.
Image: A kind of snapshot of a computer system that can be run in a container. Images are built from Dockerfiles. See
docker build, docker-compose build.

8.2 Common commands
Build an image from Dockerfile in current directory:
docker build -t imagetag .

Start a container from an image, run a command, and when the command exits, stop the container without saving any
changes:
docker run --rm -it imagetag bash

8.3 Cleanup
8.3.1 delete volumes
see: https://github.com/chadoe/docker-cleanup-volumes
$ docker volume rm $(docker volume ls -qf dangling=true)
$ docker volume ls -qf dangling=true | xargs -r docker volume rm

123

Dan’s Cheat Sheets Documentation, Release 1

8.3.2 delete networks
$ docker network ls $ docker network ls | grep “bridge” $ docker network rm $(docker network ls | grep
“bridge” | awk ‘/ / { print $1 }’)

8.3.3 remove docker images
see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images
$ docker images
$ docker rmi $(docker images --filter "dangling=true" -q --no-trunc)
$ docker images | grep "none"
$ docker rmi $(docker images | grep "none" | awk '/ / { print $3 }')

8.3.4 remove docker containers
see: http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images
$ docker ps
$ docker ps -a
$ docker rm $(docker ps -qa --no-trunc --filter "status=exited")

8.3.5 Resize disk space for docker vm
$ docker-machine create --driver virtualbox --virtualbox-disk-size "40000" default

124

Chapter 8. Docker

CHAPTER

9

Elasticsearch

9.1 Documentation
• Elasticsearch Reference
• Elasticsearch Definitive Guide
Contents:

9.1.1 Indices
Create an index
Create Index API
Example args:
{
"settings" : {
"number_of_shards" : 3,
"number_of_replicas" : 2
}
}
{
"settings" : {
"number_of_shards" : 1
},
"mappings" : {
"type1" : {
"_source" : { "enabled" : false },
"properties" : {
"field1" : { "type" : "string", "index" : "not_analyzed" }
(continues on next page)

125

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

}
}
}
}

Index settings
TBD
dynamic Dynamic mapping Values true, false, "strict".

9.1.2 Mappings
Mappings API
Mappings reference
Intro to Mappings in the Guide
Types and Mappings in the Guide
Example mapping for a tweet doctype:
{
"tweet" : {
"properties" : {
"message" : {
"type" : "string",
"store" : true,
"index" : "analyzed",
"null_value" : "na"
},
"user" : {
"type" : "string",
"index" : "not_analyzed",
"norms" : {
"enabled" : false
}
},
"postDate" : {"type" : "date"},
"priority" : {"type" : "integer"},
"rank" : {"type" : "float"}
}
}
}

The string type
The string type is analyzed as full text by default.
String type reference includes all the possible attributes.

126

Chapter 9. Elasticsearch

Dan’s Cheat Sheets Documentation, Release 1

The number type
Number type reference
The date type
Date type reference
The boolean type
Boolean type reference and it’s boolean not Boolean.
Multi fields
Multi fields reference
You can store the same source field in several index fields, analyzed differently.
Object type
Object Type Ref
You can define a field to contain other fields.
Root object type
Root object type ref
Root object in guide - better
The top-level doc type in a mapping is also an object type, but has some special characteristics. For example, you can
set the default analyzers that fields without an explicit analyzer will use.
You can also turn off dynamic mapping for a doctype, though the Root object type ref doesn’t mention this. See
Dynamic mapping. You can even turn it back on for one field. Example:
{
"my_type": {
"dynamic":
"strict",
"properties": {
...
"stash": {
"type": "object",
"dynamic": True
}
}
}

9.1. Documentation

127

Dan’s Cheat Sheets Documentation, Release 1

9.1.3 Analysis
Analysis reference
Analysis and Analyzers in the Guide
An analyzer consists of:
• Zero or more CharFilters
• One Tokenizer
• Zero or more TokenFilters
Analysis can be configured when creating an index with the top-level analysis key in the API argument. Example:
analysis :
analyzer :
standard :
type : standard
stopwords : [stop1, stop2]
myAnalyzer1 :
type : standard
stopwords : [stop1, stop2, stop3]
max_token_length : 500
# configure a custom analyzer which is
# exactly like the default standard analyzer
myAnalyzer2 :
tokenizer : standard
filter : [standard, lowercase, stop]
tokenizer :
myTokenizer1 :
type : standard
max_token_length : 900
myTokenizer2 :
type : keyword
buffer_size : 512
filter :
myTokenFilter1 :
type : stop
stopwords : [stop1, stop2, stop3, stop4]
myTokenFilter2 :
type : length
min : 0
max : 2000

Built-in analyzers
Built-in analyzers in the Guide
Custom analyzers
You can define custom analyzers.
Custom Analyzers in the Guide
Example:

128

Chapter 9. Elasticsearch

Dan’s Cheat Sheets Documentation, Release 1

analysis :
analyzer :
myAnalyzer2 :
type : custom
tokenizer : myTokenizer1
filter : [myTokenFilter1, myTokenFilter2]
char_filter : [my_html]
position_offset_gap: 256
tokenizer :
myTokenizer1 :
type : standard
max_token_length : 900
filter :
myTokenFilter1 :
type : stop
stopwords : [stop1, stop2, stop3, stop4]
myTokenFilter2 :
type : length
min : 0
max : 2000
char_filter :
my_html :
type : html_strip
escaped_tags : [xxx, yyy]
read_ahead : 1024

9.1. Documentation

129

Dan’s Cheat Sheets Documentation, Release 1

130

Chapter 9. Elasticsearch

CHAPTER

10

Elixir

10.1 Basic types
Examples:
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>
iex>

1
# integer
0x1F
# integer (31)
0x1010
# integer (10)
0o777
# integer (511)
1.0
# float
1.0e-10
# float
true
# boolean
false
# boolean
:atom
# atom / symbol
"elixir"
# string
[1, 2, 3] # list
{1, 2, 3} # tuple
is_atom(false)
# true
is_atom(:false)
# true
is_boolean(true)
# true
is_boolean(:true)
# true
is_integer(1.0)
# false
is_float("foo")
is_number(1.0)
# true

10.2 Arithmetic
Infix: 40 + 2 is 42. / on integers returns a float, e.g. 10 / 2 is 5.0:
10 / 2
div(10, 2)

5.0
5
(continues on next page)

131

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

div 10, 2
rem 10, 3
round(3.58)
trunc(3.58)

5
1
4
3

10.3 Boolean expressions
true == false is false.
true != false is true.
You can also use or, and, and not. or and and are short-circuiting operators. All three of these require Boolean
arguments.
Elixir also has ||, &&, and !, which accept values of any type, and where any value except false and nil are truthy.
For comparison: ==, !=, ===, !==, <=, >=, <, and >. The only difference between == and === is that 1 == 1.0
is true but 1 === 1.0 is not true.
Elixir allows applying the comparison operators to values of any type or combination of types, for simplicity when
doing things like sorting. There is an ordering among types, e.g. <number> < <atom>.

10.4 Strings
Double quoted literals are strings (single quoted literals are char lists, not strings).
Use <> to concatenate, e.g. "hello" <> " world"
You can interpolate:
iex> "hellö #{:world}"
"hellö world"

The typical \x char codes work, e.g. "hello\nworld"
Internally strings are binary, sequences of bytes (UTF-8):
iex> String.length("hellö")
5
iex> is_binary("hellö")
true
iex> byte_size("hellö")
6

The String module has lots of useful methods like upcase.
You can print a string using IO.puts/1:
iex> IO.puts "hello\nworld"
hello
world
:ok

Note that the return value of IO.puts is :ok.

132

Chapter 10. Elixir

Dan’s Cheat Sheets Documentation, Release 1

10.5 Functions
Note: Functions in Elixir are identified by name and by number of arguments (i.e. arity). Therefore, is_boolean/1
identifies a function named is_boolean that takes 1 argument. is_boolean/2 identifies a different (nonexistent) function
with the same name but different arity.:
iex> is_boolean(true)
true
iex> is_boolean(1)
false

You can get help on a function with h and its name/arity:
iex> h is_boolean
iex> h is_boolean/1
iex> h ==/2

BUT you can’t call a function using its full name and arity, you have to leave off the arity:
iex> is_boolean/1(1)
** (SyntaxError) iex:2: syntax error before: '('

10.6 Anonymous functions
Define anonymous functions with fn, ->, and end:
iex> add = fn a, b -> a + b end
...
iex> is_function(add)
true
iex> is_function(add, 2)
true
iex> is_function(add, 1)
false

Anonymous functions require a dot . to invoke:
iex> add.(1, 2)
3

Anonymous functions are closures and can access variables that were in scope when they were defined.
Variables assigned inside a function do not affect the surrounding environment, though:
iex> x = 42
42
iex> (fn -> x = 0 end).()
0
iex> x
42

10.5. Functions

133

Dan’s Cheat Sheets Documentation, Release 1

10.7 Lists
Literal lists are written with square brackets. Values can be a mix of any types:
iex> length [1, 2, true, 3]
4

Lists are concatenated using ++/2 and can be “subtracted” using --/2:
iex> [1, 2, 3] ++ [4, 5, 6]
[1, 2, 3, 4, 5, 6]
iex> [1, true, 2, false, 3, true] -- [true, false]
[1, 2, 3, true]

The “head” of a list is like Lisp’s car but is accessed using the hd/1 function. Similarly, the “tail” is the cdr and
you get it with tl/1:
iex> list = [1,2,3]
iex> hd(list)
1
iex> tl(list)
[2, 3]

You can add a new head to a list with |:
iex> [1 | [2, 3]]
[1, 2, 3]

Getting the head or the tail of an empty list is an error:
iex> hd []
** (ArgumentError) argument error

A list of small integers is printed by Elixir as a single-quoted “string” - but it’s not a string, it’s a list of chars:
iex> [11, 12, 13]
'\v\f\r'
iex> [104, 101, 108, 108, 111]
'hello'

10.8 Introspection
Use i/1 to get information about a value:
iex(2)> i 'hello'
Term
'hello'
Data type
List
Description
This is a list of integers that is printed as a sequence of characters
delimited by single quotes because all the integers in it represent valid
ASCII characters. Conventionally, such lists of integers are referred to as
"char lists" (more precisely, a char list is a list of Unicode codepoints,
(continues on next page)

134

Chapter 10. Elixir

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

and ASCII is a subset of Unicode).
Raw representation
[104, 101, 108, 108, 111]
Reference modules
List
iex(3)> i "hello"
Term
"hello"
Data type
BitString
Byte size
5
Description
This is a string: a UTF-8 encoded binary. It's printed surrounded by
"double quotes" because all UTF-8 encoded codepoints in it are printable.
Raw representation
<<104, 101, 108, 108, 111>>
Reference modules
String, :binary

10.9 Tuples
Literal tuples are written with curly brackets {1, :ok, true}. Access any element with elem/2 using 0indexing, get the length with tuple_size/1, and return a new tuple with an element changed using put_elem/3:
iex> elem({:ok, "hello"})
"hello"
iex> tuple_size({:ok, "hello"})
2
iex> put_elem({:ok, "hello"}, 1, "world"})
{:ok, "world"}

10.9. Tuples

135

Dan’s Cheat Sheets Documentation, Release 1

136

Chapter 10. Elixir

CHAPTER

11

Git

11.1 Disaster recovery
git reflog will list all the recent commits, whether they’re reachable from any branch or tag or not. Find the one
you want, check it out by its commit, and then you can make that a branch with git branch <new-name> (I
think).>

11.2 Undoing things
If you’ve committed some changes, then for some reason decide you didn’t want to commit them yet - but still want
the changes present in your local working directory - there are several options.
To get rid of the actual commit but keep all those changes staged:
$ git reset --soft HEAD~

To get rid of the actual commit and keep the changes, but not staged:
$ git reset HEAD~

And if you didn’t want those changes at all - WARNING this will lose changes - gone:
$ git reset --hard HEAD~

11.3 Fetching
Update all local remote tracking branches from all remotes:
git fetch --all

137

Dan’s Cheat Sheets Documentation, Release 1

Update all local remote tracking branches from origin:
git fetch origin

Update/create local branch origin/master from remote origin’s branch master with default configuration:
git fetch origin master

Update/create local branch ‘tmp’ from remote origin’s branch master (but only updates if fast-forward is possible):
get fetch origin master:tmp

Peek at an artitrary remote’s branch by pulling it into a (temporary) local branch, then check its log. The temporary
local branch will eventually be garbage collected:
git fetch git://git.kernel.org/pub/scm/git/git.git maint
git log FETCH_HEAD

11.4 Branches and checkouts
Check out an existing branch:
git checkout <branch>

Create new branch:
git branch <branchname> [<start point>]

Create new branch and check it out in one command:
git checkout -b <newbranch> [<start point>]

11.5 Import one repo into another with history
http://stackoverflow.com/questions/1683531/how-to-import-existing-git-repository-into-another

11.6 Cleaning
Delete untracked files (be careful!):
git clean -fdx

Prune branches that have been merged and are no longer upstream:
http://devblog.springest.com/a-script-to-remove-old-git-branches

Prune branches that track remote branches that no longer exist (http://kparal.wordpress.com/2011/04/15/
git-tip-of-the-day-pruning-stale-remote-tracking-branches/):
$ git remote prune origin --dry-run
$ git remote prune origin

138

Chapter 11. Git

Dan’s Cheat Sheets Documentation, Release 1

11.7 Pulls
Easier access to pull requests on Github. Add to config:
# This will make pull requests visible in your local repo
# with branch names like 'origin/pr/NNN'
# WARNING: This also breaks adding a new remote called "origin" manually
# because git thinks there already is one. Comment this out temporarily
# in that case, unless you can think of a better solution.
[remote "pulls"]
fetch = +refs/pull/*/head:refs/remotes/origin/pr/*

11.8 Aliases
Handy aliases for config:
[alias]
lg = log --oneline --graph --date-order
lgd = log --oneline --graph --date-order --format=format:\"%ai %d %s\"
cb = checkout -b
cd = checkout develop
co = checkout
gd = !git fetch origin && git checkout develop && git pull origin develop
gm = !git fetch origin && git checkout master && git pull origin master
# push -u the current branch
pu = "!CURRENT=$(git symbolic-ref --short HEAD) && git push -u origin $CURRENT"
# push -f
pf = push -f
# Find the common ancestor of HEAD and develop and show a diff
# from that to HEAD
dd = "!git diff $(git merge-base develop HEAD)"
# Find the common ancestor of HEAD and master and show a diff
# from that to HEAD
dm = "!git diff $(git merge-base master HEAD)"
# These need 'hub' installed.
# Create pull request against develop. Must pass issue number.
#pr = pull-request -b develop -i
# Create pull request against develop, not passing issue number:
pr = pull-request -b develop
# Checkout pull request
# Assume origin/pr/NN is pull request NN
# Need a bash function because we need to concatenate something to $1
#cpr = "!f() {set -x;git checkout origin/pr/$1; };f"
cpr = "!gitcpr"
# Undo any uncommited changes
abort = checkout -- .

11.7. Pulls

139

Dan’s Cheat Sheets Documentation, Release 1

11.9 Submodules
This will typically fix things:
git submodule update --init --recursive

(and yes, you need –init every time)
Add a new submodule [http://git-scm.com/book/en/Git-Tools-Submodules]
$ git submodule add git@github.com:mozilla/basket-client basket-client

11.10 Combining feature branches
Suppose you have branch A and branch B, which branched off of master at various times, and you want to create a
branch C that contains the changes from both A & B.
According to Calvin: checkout the first branch, then git checkout -b BRANDNEWBRANCH. then rebase it on the
second.
(SEE DIAGRAMS BELOW)
Example:
# Start from master
git checkout master
git pull [--rebase]
# Create the new branch from tip
git checkout -b C
# rebase A on master
git checkout A
git rebase -i master
# merge A into C
git checkout C
git merge A
# rebase B
git checkout B
git rebase -i master
# merge B into C
git checkout C
git merge B
# I think???
# Review before using, and verify the result

Combining git branches diagrams
Start:
o - o - o - o <--- master
\
\
\
o - o - o <--- A
o - o - o <--- B

140

Chapter 11. Git

Dan’s Cheat Sheets Documentation, Release 1

Rebase A on master:
master
/
o - o - o - o - o - o - o <--- A
\
o - o - o <--- B

Create new branch N from master:
master
/
o - o - o - o - o - o - o <--- A
\
\
\
N
\
o - o - o <--- B

Switch to N and merge A:
master
/
o - o - o - o - o - o - o <--- A
\
\
\
o - o - o <--- N
\
o - o - o <--- B

(includes A)

Rebase B on master:
master
/
o - o - o - o - o - o - o - o <--- A
|\
| o - o - o <--- N (includes A)
\
o - o - o <--- B

On N, merge B:
master
/
o - o - o - o - o - o - o - o <--- A
|\
| o - o - o - o - o - o <--- N (includes A and B)
\
o - o - o <--- B

Delete A and B if desired.

11.10. Combining feature branches

141

Dan’s Cheat Sheets Documentation, Release 1

142

Chapter 11. Git

CHAPTER

12

Google APIs

Google APIs and Docs
Google Apps
Google Apps APIs
Google Drive API
Google Apps Script

12.1 Google libraries
These are all for Python.

12.2 Older libraries (Google Data)
12.3 Newer libraries
OAuth 2.0
Google APIs client library for Python (beta)

143

Dan’s Cheat Sheets Documentation, Release 1

144

Chapter 12. Google APIs

CHAPTER

13

Gulp Tasks

Because gulp tasks are actually from another package, orchestrator, the gulp people don’t feel the need to document
how gulp tasks work very much. So. . .

13.1 Asynchronous
Gulp tasks are asynchronous. Here are some patterns to use.

13.1.1 Just exit
THIS IS ALMOST ALWAYS WRONG
Gulp calls the task function, which returns when it’s done.
Even if everything your task is doing is synchronous, this is still wrong because Gulp is allowed to kick it off in the
background and then immediately assume it’s done and start running other tasks that depend on it, which might or
might not work. A real bear to debug. But here’s how it looks:
# DO NOT DO THIS:
gulp.task('sync_task', function() {
stuff that runs immediately;
})

13.1.2 Callback
Gulp passes a callback. The tasks calls it when done:
gulp.task('foo', function(cb) {
stuff...;
cb();
})

145

Dan’s Cheat Sheets Documentation, Release 1

13.1.3 Return a promise or an event stream
Gulp pipes, and lots of gulp plugins, return a promise or even stream. We can just return the thing they gave us, and
gulp will use that to tell when the work is done:
gulp.task('make_promise', function() {
return some_gulp_plugin.pipe(stuff).pipe(more_stuff);
})

13.2 Watching
Call a task whenever any of a group of files changes:
gulp.watch('filepattern', ['task1', 'task2'])

After calling this, anytime a file that existed when this was called and matched the filepattern changes, task1 and task2
will be called.
This will result in the gulp command not exiting, because it’s hanging around to watch for changes!
(But the watch() function itself does return, no worries there.)
TBD: What does gulp.watch return? Anything?

146

Chapter 13. Gulp Tasks

CHAPTER

14

HAProxy

Make sure to use the docs corresponding to the version you are using.
1.5: https://cbonte.github.io/haproxy-dconv/1.5/configuration.html

14.1 Pass SSL thru
Use proxy “mode tcp”. E.g:
listen sectionname
bind :443
mode tcp
server server1 10.0.0.1:443
default_backend sslserver
backend sslserver
mode tcp
server servername 1.2.3.4:443

14.2 Route based on SNI
This works even if haproxy is not terminating the SSL connection:
acl site_b req_ssl_sni -i site_b.com
use_backend site_b_backend if site_b
backend site_b_backend
mode tcp
server b1 10.0.0.1:443
server b2 10.0.0.2:443

Explanation: we set the condition “site_b” true if the SSL SNI in the request (req_ssl_sni) is case-insensitively equal
to (-i) the string “site_b.com”. We use the backend “site_b_backend” if the condition “site_b” is true. Backend

147

Dan’s Cheat Sheets Documentation, Release 1

“site_b_backend” means to forward the request without terminating the SSL connection (“mode tcp”) to either the
server at 10.0.0.1 port 443, or 10.0.0.2 port 443.

14.3 Route based on Host request header
Use an ACL to check the header and then pick a backend:
acl site_a hdr(host) -i site_a.com
use_backend site_a_backend if site_a
backend site_a_backend
mode http
server a1 10.0.0.1:80
server a2 10.0.0.2:80

148

Chapter 14. HAProxy

CHAPTER

15

Haskell

By analogy to Python. . .

15.1 Imports
Python
from module import *

Haskell
import module

from module import a,b

import module (a,b)

import module

import
qualified
module
import
qualified
module as M
import module hiding (c)

import module; M = module; del module
n/a

Notes
Import everything from the module directly into the namespace
Import selected items from the module directly into the
namespace
Make all module.NAME available in the name space
Give module a shorter alias
Import everything from the module directly into the namespec, except selected items

149

Dan’s Cheat Sheets Documentation, Release 1

15.2 Math
Python
a+b, a*b, a-b

a and b, a or b, not a
a == b, a != b
min(a,b), max(a,b)
min([a,b,c]),
sum([a,b,c])

Haskell
a+b, a*b, a-b
a/b

max([a,b,c]),

Notes
Integer division giving a
float

a && b, a || b, not a
a==b, a /= b
min a b, max a b
minimum [a,b,c], maximum [a,b,c], sum
[a,b,c]

15.3 Expressions
Python
b if a else c

150

Haskell
if a then b else c

Notes
Both are expressions, not statements

Chapter 15. Haskell

Dan’s Cheat Sheets Documentation, Release 1

15.4 Lists
Python
[1,2,3,4]
[1,
‘a’,
“foo”]
[1,2]
+
[3,4]
[1] + [2,3]

Haskell
[1,2,3,4]
n/a

Haskell lists must be homogeneous

[1,2] ++ [3,4]
1:[2,3]

[‘a’,’b’,’c’][1][‘a’, ‘b’, ‘c’]
!! 1
[‘a’,’b’,’c’][:3]take
3
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][3:]drop
3
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][1:2]
take 2 . drop 1
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][0]head
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][1:]tail
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][- last
1]
[‘a’,’b’,’c’]
[‘a’,’b’,’c’][:- init
1]
[‘a’,’b’,’c’]
len([‘a’,’b’,’c’])
length
[‘a’,’b’,’c’]
not
null
len([‘a’,’b’,’c’])
[‘a’,’b’,’c’]
rereverse
verse([‘a’,’b’,’c’])
[‘a’,’b’,’c’]
‘a’
in ‘a’
elem
[‘a’,’b’,’c’] [‘a’,’b’,’c’]
range(1,21) [1..20]
set(x)
- x\y
set(y)
set(x) + x union y
set(y)

15.4. Lists

Notes

Haskell has more syntax for list expressions
Extract a list element
First N elements
Drop N, take rest
Slices are uglier in Haskell
First elt
All but first elt

All but last elt

is list empty (but would probably just do bool(list) in Python)

Python counts to the last value before the 2nd parm, Haskell includes it
Set difference for lists x and y - except Haskell isn’t really, it just removes one value
‘z’ from x for each occurrence of ‘z’ in y. See Data.Set for real sets.
Haskell adds one occurrence of each element of y to x if x doesn’t already have one

151

Dan’s Cheat Sheets Documentation, Release 1

15.5 Functions
Python
def doubleMe(x): return x + x
def doubleUs(x, y): return x*2 +
y*2

152

Haskell
doubleMe x = x + x

Notes

doubleUs x y = x*2 + y+2

Chapter 15. Haskell

CHAPTER

16

i3

My i3 bindings
“Ŵ” is the “windows” key
Change what we see:
Ŵ-<NUMBER>: switch to workspace NUMBER on whatever monitor it's
attached to.
Ŵ-Control-1: Only use built-in laptop display
Ŵ-Control-2: Use built-in laptop display, and external display
positioned to its left
Ŵ-<n>:
Switch to workspace <n> (need not already exist)
(if workspace <n> is on another screen, it'll switch
that screen to workspace <n>, not your current screen)
Ŵ-<n> where <n> is the current workspace: Switch back to previous
workspace (So you can just do Ŵ-1 (look at screen) Ŵ-1
and be back where you started)

Focus:
Ŵ-j,
Ŵ-k,
Ŵ-l,
Ŵ-;,

Ŵ-<left>
Ŵ-<down>
Ŵ-<up>
Ŵ-<right>

left
down
up
right

Move things:
Ŵ-Control-<ARROW>: Move current workspace to another monitor.
Ŵ-Shift-Number: Move current window to another workspace
(need not already exist)
Shift-<FOCUS COMMAND>: Move current window within workspace

Layouts:

153

Dan’s Cheat Sheets Documentation, Release 1

Ŵ-e
Ŵ-s
Ŵ-w
Ŵ-f
Ŵ-S-<spc>
Ŵ-mouse1-drag
Ŵ-h

default (splith/splitv), repeat to toggle
splith/splitv
stacked
tabbed
fullscreen (toggle)
float (toggle)
move floating
Make the current window/container a horizontal
split container. New windows opened when this
container is focused will be created
by splitting this container horizontally
(side-by-side)
Like Ŵ-h, but vertical (one above another)

Ŵ-v
Ŵ-e

toggle between defaulting to horizontal and
defaulting to vertical

Start/end things:
Ŵ-return: open new terminal
Ŵ-D: open dmenu at top to enter a command (output invisible,
use to start new graphical programs)
Ŵ-S-q
kill window

Control I3:
Ŵ-S-c
Ŵ-S-r
Ŵ-S-e

reload I3 config
restart I3
kill I3 (logout)

Resizing:
Ŵ-mouse2-drag

stretch or shrink window

Screen capture:
<Printscreen> - capture whole screen
Shift-<Printscreen> - select a rectangle or window (?)
Control-<Printscreen> - capture currently focused window

154

Chapter 16. i3

CHAPTER

17

IPv6

17.1 Localhost
Localhost is ::1

17.2 Any addr
Any addr (equivalent of 0.0.0.0) is ::

17.3 With port
Adding “:<portnumber>” to an IPv6 address would be ambiguous. The solution is to put “[]” around the address part,
e.g. [::1]:8000.

17.4 URLs with IPv6 addresses
You need the [] here too, at least if you’re using a hexadecimal IPv6 address. (Even without a port number.):
http://[fe80::b746:6473:e65f:5dd4]/foo/bar
http://[fe80::b746:6473:e65f:5dd4]:8000/foo/bar

17.5 Ping
Use ping6:

155

Dan’s Cheat Sheets Documentation, Release 1

ping6 ::1

17.6 Django
To run a local dev server listening on any IPv6 address:
python manage.py runserver --ipv6 "[::]:8000"

It does NOT appear possible to have the dev server listen on both IPv4 and IPv6, at least not in Django 1.8. (But I’m
sure you could put nginx in front to do that for you.)

17.7 Private IPv6 network addresses
Try http://simpledns.com/private-ipv6.aspx to get a random private address range.
Example output:
Here is a unique private IPv6 address range generated just for you (refresh page to
˓→get another one):
Prefix/L:
fd
Global ID:
442da008f4
Subnet ID:
cf4f
Combined/CID:
fd44:2da0:08f4:cf4f::/64
IPv6 addresses:
fd44:2da0:08f4:cf4f:xxxx:xxxx:xxxx:xxxx
If you have multiple locations/sites/networks, you should assign each one a different
˓→"Subnet ID", but use the same "Global" ID for all of them.

To add an address to your loopback interface:
sudo ifconfig lo add fd44:2da0:08f4:cf4f::1/64

17.8 Find out your ipv6 address
In theory, run “ifconfig” and look for “inet6 addr”. E.g.:
enp0s25

Link encap:Ethernet HWaddr 54:ee:75:8b:03:99
inet addr:172.20.1.110 Bcast:172.20.3.255 Mask:255.255.252.0
inet6 addr: fe80::b746:6473:e65f:5dd4/64 Scope:Link
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1

Try to find an “inet6 addr” that isn’t “Scope:Link” or “Scope:Host”; you want “Scope:Global”.
Better way - if you think you have real IPv6 connectivity to the internet, go to google.com and search for “what’s my
IP”. If you’re connecting to Google over IPv6, Google will tell you your IPv6 address (which might be a NATting
router, I suppose - I don’t know if IPv6 still does that?) But that won’t help if you’re just running IPv6 locally for
testing.

156

Chapter 17. IPv6

CHAPTER

18

Javascript

Contents:

18.1 Javascript Builtins
18.1.1 Arrays
Traditional literals, append, extend:
>> a = [1, 2, 3]
>> console.log(a)
[1, 2, 3]
>> b = [4, 5]
>> Array.prototype.push.apply(a, b);
>> console.log(a)
[1, 2, 3, 4, 5]
>> a.push(6)
>> console.log(a)
[1, 2, 3, 4, 5, 6]

# literal

# 'extend'

# 'append'

ES2015 literals, append, extend (Spread operator ):
>> a = [1, 2, 3]
>> b = [0, ...a]
>> console.log(b)
[0, 1, 2, 3]
>> a.push(4)
>> console.log(a)
[1, 2, 3, 4]
>> console.log(b)
[0, 1, 2, 3]
>> a.push(...b)

# literal incorporating another array

# append

# extend
(continues on next page)

157

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

>> console.log(a)
[1, 2, 3, 4, 0, 1, 2, 3]

18.1.2 Iterate over an array
Run code for each element (ES5+) (forEach):
arr.forEach(function(value, index, arr){}[, thisArg])

See if none, some, or all elements pass a test (ES5+) (every, some):
all_passed = arr.every(function(value, index, arr){ return bool;}[, thisArg])
some_passed = arr.some(function(value, index, arr){ return bool;}[, thisArg])
none_passed = !arr.some(...)

Create a new array by applying a function to each element of an existing array (ES5+) (map):
arr2 = arr1.map(function(value, index, arr){}[, thisArg])

Create a new array only including elements that pass a test (ES5+ (MDN):
arr2 = arr1.filter(function(value, index, arr){}[, thisArg])

18.1.3 Iterate over a “dictionary” (JS object)
This will include enumerable properties of prototype classes (traditional) (for. . . in):
for (var key in object) {
value = object[key]
# ... do stuff ...
}

Note: For objects that you’re just using as dictionaries, for. . . in is perfectly good. Just be careful not to use it on
instances of anything more complicated.
For more complicated objects, here’s how you get just properties that are directly on the object (not inherited from a
prototype). Traditional:
for (var key in object) {
if (object.hasOwnProperty(key)) {
value = object[key]
# ... do stuff ...
}
}

Just properties directly on the object, with ES2015+ (keys):
var keys = object.keys();
for (var i = 0; i < keys.length; i++) {
value = object[keys[i]];
# ... do stuff ...
}

158

Chapter 18. Javascript

Dan’s Cheat Sheets Documentation, Release 1

18.1.4 Is a key in a dictionary?
dict.hasOwnProperty(key)

18.1.5 Does an object have a key (possibly inherited)?
key in object

18.1.6 Remove key from dictionary
delete dict[“key”] delete dict.key

18.1.7 String operations
String, endsWith, includes, indexOf, join, match, replace, search, split, startsWith, substr, substring
arr = str.split(sep=(str|regex)[, limit])
str = arr.join(sep)
index = str.indexOf(substr[, startIndex]) # returns -1 if not found
sub = str.substr(firstIndex[, length]) # firstIndex can be negative to count back
˓→from end
sub = str.substring(firstIndex[, lastIndex+1])
str2 = str.replace(regexp|substr, newSubStr|function)
bool = str.startsWith(str2)
bool = str.includes(str2)
bool = str.endsWith(str2)
[matchstr, groups...] = str.match(regexp) # returns null if doesn't match
[matchstr, groups...] = str.search(regexp) # returns null if doesn't match entire
˓→string

Contains: haystack.indexOf(needle) != -1

18.1.8 Timer
setTimeout:
window.setTimeout(func, delay, param1, param2, ...);

All but func is optional. delay defaults to 0.
timerId = window.setTimeout(func, [delay, param1, param2, . . . ]); window.clearTimeout(timerId);

18.2 Javascript Events
18.2.1 Event object
• currentTarget: the element that has the handler attached that is currently running
• target: the element that received the event initially

18.2. Javascript Events

159

Dan’s Cheat Sheets Documentation, Release 1

18.3 NVM and NPM
Use another node version:
$ nvm use 8
$ nvm use 10

etc.
Back-level your npm:
$ which npm

to make sure you’re running npm from an nvm version, then:
$ npm install -g npm@5.10.0
$ npm version
...

18.4 Promises
MDN docs
quoting from there:
A Promise is in one of these states:
• pending: initial state, not fulfilled or rejected.
• fulfilled: meaning that the operation completed successfully.
• rejected: meaning that the operation failed.
A promise that is not pending is “settled”.
You can create a Promise with new, passing it an executor function:
let p = new Promise((resolve, reject) => {
if (things go well) {
resolve(resulting_value)
} else {
reject(error)
}
})

At any time after the promise is created, you can call then on it and pass in a success handler, a failure handler, or
both:
p.then(on_success) p.then(undefined, on_failure) p.then(on_success, on_failure)
If the promise is still pending, the appropriate handler will be called once it is settled. If it’s settled already, the handler
will be calleed immediately (or ASAP, anyway).
The on_success handler is called with the resolved value from the promise, while the on_failure handler is
called with the error value from the promise.
then() returns a new promise, so you can chain calls:

160

Chapter 18. Javascript

Dan’s Cheat Sheets Documentation, Release 1

p.then(on_success).then(another_on_success).then(a_third_on_success)

If the on_success handler returns a new promise, that promise will be the return value from then() (or an equivalent
promise, anyway).
The handlers will be called in order. If one fails, then the promise returned by that then() call will be rejected. “Fail”
can mean raises an exception.
Many async functions nowadays return promises.

18.4.1 Pausing
Here’s a way of doing something after a delay:
let p = new Promise((resolve) => {
setTimeout(resolve, 100)
}).then(()=>{
do stuff
})

18.4.2 Some notes I made a while ago
Here are some examples:
// Return a new promise.
return new Promise(function(resolve, reject) {
// do stuff. if it works:
resolve(result);
// but if it fails:
reject(Error(error text));
});
// USE a promise
promise.then(function(result) {
// use result here
}, function(error) {
// do something with error here
});
// CHAINING
// Note that 'then' returns a new promise
promise.then(function(val1) {
return val1 + 2;
}).then(function(val2) {
val2 is here val1 + 2!!!
});
// MORE CHAINING
promise.then(function(result){
// do something, then return a new promise
return promise2;
}).then(function(result2) {
// this isn't invoked until promise2 resolves, and it gets promise2's result.
(continues on next page)

18.4. Promises

161

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

...
}

18.5 Javascript Syntax
18.5.1 Spread Operator
Spread operator
Given function and args:
function myFunction(x, y, z) { }
var args = [0, 1, 2];

Traditional:
myFunction.apply(null, args);

ES2015:
myFunction(...args);
myFunction(1, ...[2, 3]);

Caution: The ES2016 . . . operator is NOT the same as * in a Python function call. . . . basically splices the array
it’s applied to into the list at the place where it’s used. It can be used repeatedly, and in any combination with other
unnamed arguments. Python’s * can only be used to extend the list of unnamed arguments at the end.

18.6 DOM operations with JavaScript
18.6.1 Finding elements by selector
https://developer.mozilla.org/en-US/docs/Web/API/Element/querySelectorAll
items = document.querySelectorAll('a.class-name')

Returns a NodeList.

18.6.2 Iterating over elements
https://developer.mozilla.org/en-US/docs/Web/API/NodeList
Note: Although NodeList is not an Array, it is possible to iterate on it using forEach(). Several older browsers have
not implemented this method yet.

162

Chapter 18. Javascript

Dan’s Cheat Sheets Documentation, Release 1

// Newer browsers
items.forEach(function(item){ do something with item })
// Old (how old?) browsers
Array.prototype.forEach.call(items, function(item) { do something with item })

Here’s a polyfill for ES5+ browsers from that NodeList.forEach page linked above:
if (window.NodeList && !NodeList.prototype.forEach) {
NodeList.prototype.forEach = function (callback, thisArg) {
thisArg = thisArg || window;
for (var i = 0; i < this.length; i++) {
callback.call(thisArg, this[i], i, this);
}
};
}

18.6. DOM operations with JavaScript

163

Dan’s Cheat Sheets Documentation, Release 1

164

Chapter 18. Javascript

CHAPTER

19

Kobo ereader

19.1 Activating without connecting to kobo on the internet
• Start up the kobo. It’ll ask if you want to setup over wifi or not. Say not.
• Plug the kobo into your computer using a USB cable.
• On my laptop, it mounts automatically at /media/usb0; I don’t know if I set that up somehow in the past.
• Use sqlite3 to add a dummy user:
$ sqlite3 /media/usb0/.kobo/KoboReader.sqlite3
sqlite> INSERT INTO user (UserID, UserKey, UserDisplayName, UserEmail) values(
˓→"00000000-0000-0000-0000-000000000000","00000000-0000-0000-0000-000000000000",
˓→"MyDummyUser@dummy.com","MyDummyUser@dummy.com");
sqlite> .quit

Before rebooting, continue by manually updating the latest firmware, see next section.

19.2 Adding fonts
instructions
Briefly, mount kobo, create fonts dir at top level (should be next to .kobo), and copy font files there.

19.3 Manually updating firmware
• Download a zipfile with the latest firmware for your Kobo device from this wiki page
• The Kobo should be mounted over USB as above.
• Change to the kobo’s .kobo directory

165

Dan’s Cheat Sheets Documentation, Release 1

• Unpack the zipfile containing the firmware update
• Properly unmount the Kobo
• Unplug the USB cable
Within a minute or so, the Kobo should notice the update, install it, and reboot.

19.4 KFMon Files monitor
– probably better to use KSM for me – But KSM 09 seems to break WIFI? Maybe?
• github project
• more recent install instructions are here (combined with install KOReader instructions)
• For historical interest only: original discussion but the download link there no longer works, and you shouldn’t
use that old version anyway.

19.5 Installing KSM 09
• do NOT use the regular KSM 09 download, see the warning in the first post
• https://www.mobileread.com/forums/showthread.php?t=293804

19.6 Installing KSM (Kobo Start Menu) 08
• instructions
• download v8 zipfile
• follow the instructions, they’re not bad
• One thing easy to miss: once it’s starting okay, “From the home menu select “tools” > “activate” > “set runmenu
settings.msh.” There you will find the options “always,” “once,” etc. Choose “always” to make the Kobo Start
Menu appear after each time you power the device on.)”

19.7 Installing Koreader
• Download the latest koreader release from here
• Follow the instructions from above

19.8 KOReader tips and tricks
Many from here.
• Start Koreader with the last opened file: When in Koreader’s File Manager click on the top. A menu will open.
Check “Start with last opened file”.
• Make Defaults:

166

Chapter 19. Kobo ereader

Dan’s Cheat Sheets Documentation, Release 1

In some parts of the menu within a book in Koreader you can do a long tap on an entry. This will not submit the
corresponding event but will pop up a question like “Set [whatever you clicked] as a default for [whatever option
group this belongs to]”. You can e.g. set the default font, font size, font-weight and so on for new books (books that
are not in history right now). Right now this will not work with menus that use “decrease/increase” instead of the
actual values.
Other Screen gestures (some gestures are not recognized by all devices, and some settings are not available for all
neither):
• After following links in both EPUB and PDF documents, you can easily go back to the original page by executing a swipe from left to right.
• Two finger Swipe up/down: change the light settings
• Two finger Swipe left: open bookmarks
• Two finger swipe right: open TOC (table of content)
• Long tap on history entry: delete entry from history. If you reopen this book it will be starte from beginning
with default settings
• Long tap on file manager entry: file operations (e.g. copy/delete. . . )
• Long tap on mini bar: open “Go to” menu
Files:
defaults.lua: All default settings. You can do changes here, but if you install a new version of Koreader this file will
get overwritten. Because of that you can copy this file to a new file called defaults.persistent.lua and do changes there.
This file will not be overwritten, and all changes done there will be processed after the ones in defaults.lua. These files
are the right place to create tapzones.

19.9 KOreader fonts
19.10 KOreader dictionaries
• Vague-ish instructions
• go here and download GNU Collaborative International Dictionary of English. You’ll end up with a file named
gcide.zip
• mount Kobo to filesystem
• cd to <mountpoint>/.add/koreader/data/dicts
• unzip gcide.zip. It’ll create a new gcide directory containing several files
• cleanup unmount & eject
If you want another dictionary, try ‘this page <https://gitlab.com/artefact2/wiktionary-to-stardict/blob/master/
README.md>_ which has a tool that can download the English Wiktionary and convert to the proper format to
load onto the Kobo, same as above.

19.11 Sideloading books
Just mount on USB as above and copy epub files to the root directory of the kobo, or to any subdirectory (except
subdirs starting with “.”, which it won’t look in).

19.9. KOreader fonts

167

Dan’s Cheat Sheets Documentation, Release 1

168

Chapter 19. Kobo ereader

CHAPTER

20

Linux Notes, Misc.

20.1 Creating RPMS
• from ‘make install’: See [http://asic-linux.com.mx/~izto/checkinstall/index.php checkinstall]
• from CPAN packages: See [http://perl.arix.com/cpan2rpm/ cpan2rpm]

20.2 Increase open file limit
Edit /etc/security/limits.conf and add or edit:
hard nofile 2048
soft nofile 2048

to change the default limits set at login. Also double-check /etc/profile etc for ulimit commands that might set it lower
again.

20.3 Trace file operations
strace -F -e trace=file,process -o strace.out ‘’command’‘

20.4 Changing fonts for GAIM, Sanity, etc.
Run gnome-font-properties
You also need to start gnome-settings-daemon at login time if you’re not running the Gnome desktop.
Q: How do you use anti-aliased fonts in gnome2?

169

Dan’s Cheat Sheets Documentation, Release 1

A: You need to set the GDK_USE_XFT environment variable, if you are using bash type ‘export GDK_USE_XFT=1’.
You should not need to do this - your Linux distribution should do this automatically. Also AntiAliasingTroubleshooting may help you find the problem with your set-up.
• __How do you make the entire session use anti-aliased fonts?__
Create a file, ‘.gnomerc’, in your home directory and put in it
#!/bin/sh
export GDK_USE_XFT=1
exec gnome-session

Note
If you use a display manager such as gdm, you don’t need the “exec gnome-session” line and it may in fact be
counterproductive.
You may also have to edit the file /etc/X11/!XftConfig. Look for lines with:
#
# Don't antialias small fonts
#
match
any size < 14
any size > 8
edit antialias=false;

and comment them out.
Added 7-16-2002
NOTE /etc/X11/!XftConfig is deprecated. Use /etc/fonts/fonts.conf now. (11-26-2002)
• __Is the Bitstream Vera font anywhere available for download?__
Yes, you can get them from http://ftp.gnome.org/pub/GNOME/sources/ttf-bitstream-vera/
In debian just type:
apt-get install ttf-bitstream-vera

In gentoo just type:
emerge ttf-bitstream-vera

Updated 2003-07-14
• __Where do I put new (downloaded) truetype fonts?__
You can just put them into $HOME/.fonts directory
See http://gnome-hacks.jodrell.net/hacks.html?id=42 for how to make GNOME settings apply elsewhere.

170

Chapter 20. Linux Notes, Misc.

CHAPTER

21

LIRC: linux infrared remote control

LIRC

21.1 Intro
This is about how to use an arbitrary infrared remote control (like for your TV) to control your own program running
under Linux.
The end result will be that LIRC will receive signals from your remote and translate them to keypresses, and your
program can connect to LIRC and get these keypresses as they happen, then do whatever it wants with them.

21.2 Difficulties
One problem I ran into getting started with most of the howtos and tutorials I found on the web was that almost
anything not quite right in your configuration resulted in things not working with no indication of what the problem
was. That is, you could press buttons on the remote all day and there was no indication that the PC was seeing any of
it.

21.3 Why is this so hard
Here’s what I think is going on, based on how these things seem to need to be configured etc.
Sending data via infra-red is messy. An infra-red receiver attached to your computer just continuously measures and
reports the level of infra-red frequency light hitting it.
Then something we’ll call a decoder program - e.g. LIRC - has to monitor that continuous stream of light levels and
try to spot it when extra infra-red from a remote is hitting it, by the pattern of changes to the levels.

171

Dan’s Cheat Sheets Documentation, Release 1

There’s no standard on how IR remotes encode data into IR. So the only reasonable way to make this work is to tell
the decoder what remote or remotes we’re expecting to see commands from, so it can try to match up what it’s seeing
to commands from those specific remotes. Otherwise there are just too many possibilities to watch for them all.
The unfortunate consequence of this is that if we haven’t told it the right remote, it just won’t see any IR commands at
all.
Luckily, there are some very smart people who have built tools that can look at input from a remote for a while and
try to guess what remote it is, and we might have to resort to using them. But it’s much easier to use a configuration
someone else has already worked out for us, so we’ll try that first.

21.4 How to tell if it’s working
We need an easy way to tell if LIRC is seeing and correctly interpreting our remote commands. We’ll use the irw tool.
Run irw /var/run/lirc/lircd, then start pressing buttons on the remote. If things are working, it should print
out codes and key names. If not, you probably won’t see anything.
When done, hit Control-C to stop irw.

21.5 The easy start
So, I’ll start with the approach most often documented, that if it works, is simple. But if this doesn’t work, don’t waste
a lot of time fiddling with it. Move on to the next section.
This approach will only work if LIRC has a configuration file for your remote - and you know which one it is.
1. Install LIRC. On Ubuntu, sudo apt install lirc should do it.
2. During the install, Ubuntu will prompt you to pick your remote so that it can configure LIRC for you. Feel free
to try this.
3. If LIRC is already installed, or you want to try a different configuration, you can re-run the install-time configuration using sudo dpkg-reconfigure lirc.
4. Check if things are working as described above. If they are, you can skip down to the section on using LIRC
input from a program. If not, you can try configurations for other remotes that seem likely.

21.6 If the easy approach doesn’t work

172

Chapter 21. LIRC: linux infrared remote control

CHAPTER

22

LVM

LVM on Linux
Reference http://tldp.org/HOWTO/LVM-HOWTO/index.html

22.1 Terminology
PV Physical volume (e.g. a partition, RAID array, etc)
VG Volume Group - a collection of PV’s that we can use the space from
LV Logical volume - a partition created from space in a VG

22.2 Physical volumes
• List physical volumes : pvdisplay , or pvs for briefer output
• Info about one PV : pvdisplay <PV name>
• Partition type for LVM: 8e
• Make a PV from a partition : pvcreate <partition>

22.3 Volume groups
• Create a volume group : vgcreate <NewVGName> <PVname> [<PVname>...]
• Add PV to VG : vgextend <VGname> <PVname>
• Remove PV from VG : vgreduce <VG name> <PV name>
• List volume groups : vgdisplay, or vgs for briefer output

173

Dan’s Cheat Sheets Documentation, Release 1

22.4 Logical volumes
• List logical volumes : lvdisplay, or lvs for briefer output
• Create LV : lvcreate -L<SIZE> -n<NewLVName> <VGname> (SIZE=<num><units>, e.g. 1.47TiB)
or -l<EXTENTS>
• Device name of the logical volume = /dev/<VGname>/<LVname>
• Enlarge LV : lvextend -l+<extents> /dev/<VGname>/<LVname>
• Reduce LV: lvreduce -L<newSIZE> /dev/<VGNAME>/<LVname> Add -r to resize the filesystem
at the same time. Otherwise, be sure to shrink the filesystem first.

22.5 Resize file system after enlarging LV
Either of these will use all the available space.
sudo ext2fs -f /dev/<VGname>/<LVname> sudo resize2fs /dev/<VGname>/<LVname>

174

Chapter 22. LVM

CHAPTER

23

LXDE

Using LXDE desktop with i3 window manager.
There’s a brief note here but this gives a little more depth.
• Install lxde:
sudo apt install lxde lxsession-logout

• Logout of the desktop
• Login again, this time choosing the LXDE desktop
• Create an executable shell script somewhere on your path, naming it “i3wm”. It should run “i3”. (I don’t know
why it doesn’t work to just set the window manager to i3, but it doesn’t. Maybe someday I’ll take the time to
debug that.)
• Edit ~/.config/lxsession/LXDE/desktop.conf.
In the [Session]
dows_manager/command: windows_manager/command=i3wm

section,

change

win-

• In ~/.config/lxsession/LXDE/autostart, remove “@pcmanfm –desktop –profile LXDE”, it interferers with i3.
• Logout and login again.
• If you like, bind a key in i3 to “lxsession-logout” and use that to logout. Exiting i3 will not log you out with this
configuration. Or just use the menus in lxpanel to log out.

175

Dan’s Cheat Sheets Documentation, Release 1

176

Chapter 23. LXDE

CHAPTER

24

Logitech Harmony

Programming it using Linux
I have the Harmony One model (no longer produced).
Some of this information comes from http://ubuntuforums.org/showthread.php?t=781059, but I’m not using the GUI
tool (congruity), just command line.
Help Harmony Devices for finding devices.

24.1 Harmony Devices
<select class="devicetype_select" id="selectBoxVisible1" name="deviceType1"
˓→onmousedown="openMenu(this);event.cancelBubble = true;">
<option value="none">-select device to add-</option>
TELEVISION:
<option
<option
<option
<option
<option
<option
<option

value="1">TV</option>
value="7">Projector</option>
value="13">Monitor</option>
value="15">TvVcr</option>
value="37">TV DVD</option>
value="38">TV DVD VCR</option>
value="48">TV HDD</option>

AMPLIFIER:
<option
<option
<option
<option

value="19">Amplifier</option>
value="5">AV Receiver</option>
value="30">Audio/Video Switch</option>
value="36">Radio Tuner</option>

CABLE/SATELLITE BOX:
(continues on next page)

177

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option value="14">Cable Box</option>
<option value="16">Satellite</option>
<option value="12">Digital Set Top Box</option>
VIDEO RECORDER:
<option
<option
<option
<option
<option
<option
<option

value="2">VCR</option>
value="18">PVR</option>
value="25">DVD VCR</option>
value="38">TV DVD VCR</option>
value="15">TvVcr</option>
value="32">Mini System (DVD, VCR, Radio)</option>
value="47">DVDR VCR</option>

DVD:
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="4">DVD</option>
value="34">DVD Recorder</option>
value="25">DVD VCR</option>
value="37">TV DVD</option>
value="38">TV DVD VCR</option>
value="22">Mini System (DVD, CD, Radio)</option>
value="32">Mini System (DVD, VCR, Radio)</option>
value="33">Digital Music Server</option>
value="28">Laserdisc Player</option>
value="47">DVDR VCR</option>

MUSIC PLAYER:
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="3">CD Player</option>
value="11">CD Jukebox</option>
value="28">Laserdisc Player</option>
value="33">Digital Music Server</option>
value="36">Radio Tuner</option>
value="21">Mini System (CD, Radio, Cassette)</option>
value="6">Tape Deck</option>
value="29">Minidisc Player</option>
value="20">DAT</option>

GAME CONSOLE:
<option value="9">Game Console</option>
<option value="23">Game Console (With DVD)</option>
MINI SYSTEM:
<option value="22">Mini System (DVD, CD, Radio)</option>
<option value="21">Mini System (CD, Radio, Cassette)</option>
<option value="32">Mini System (DVD, VCR, Radio)</option>
COMPUTER:
<option value="8">Computer</option>
<option value="10">Laptop</option>
<option value="35">Media Center PC</option>
(continues on next page)

178

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

HOME AUTOMATION:
<option value="24">Light Controller</option>
<option value="45">Climate Control</option>
<option value="44">Home Appliance</option>
MORE DEVICE TYPES:
<option value="6">Tape Deck</option>
<option value="29">Minidisc Player</option>
<option value="20">DAT</option></select>

UNDER COMPUTER (8): MANUFACTURERS
<select class="manufacturer_select" id="manufacturerDropDown1" name="manufacturer1"
˓→onblur="if (is_ie) changeManufacturer(this);" onchange="if(manufacturerLastAction
˓→== 'mouse' || !is_ie) changeManufacturer(this);" onmousedown=
˓→"mousedownManufacturer(this);" onmouseup="manufacturerLastAction = 'mouse';"
˓→onkeypress="manufacturerLastAction = 'keyboard'; if(event.keyCode == 13)
˓→changeManufacturer(this) ;">
<option value="none">-select manufacturer-</option>
<option value="unavailable">-not listed-</option>
<option value="57283">@AlfaLine</option>
<option value="43116">@Xi Computer</option>
<option value="42270">10Moons</option>
<option value="15767">2PartsFusion</option>
<option value="18631">2Wire</option>
<option value="1096">3COM</option>
<option value="141159">3GO</option>
<option value="117481">3Q</option>
<option value="28619">3R System</option>
<option value="72513">4Geek</option>
<option value="147373">8level</option>
<option value="8394">Abit</option>
<option value="4594">ABS</option>
<option value="15631">Absolut Technology SA</option>
<option value="74609">AC Ryan</option>
<option value="3039">accessDTV</option>
<option value="35851">ACE</option>
<option value="227">Acer</option>
<option value="9418">Acesonic</option>
<option value="1296">Acoustic Research</option>
<option value="92895">Acrobak</option>
<option value="5666">Actiontec</option>
<option value="12962">Adaptec</option>
<option value="5745">Adesso</option>
<option value="42184">Adrenaline</option>
<option value="50556">ADS</option>
<option value="9184">Advance</option>
<option value="2199">Advanced Digital Broadcast</option>
<option value="10823">Advanced PC</option>
<option value="66439">Advantech</option>
<option value="894">Advent</option>
<option value="24911">AESO</option>
<option value="11838">AFK</option>
<option value="25068">AGE Computer</option>
(continues on next page)

24.1. Harmony Devices

179

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="50973">AGFAPHOTO</option>
value="4065">Ahanix</option>
value="23905">AIC</option>
value="34025">Aigo</option>
value="15652">Aim</option>
value="161051">aios</option>
value="27289">AirLink</option>
value="75793">AirLive</option>
value="123523">AKASA</option>
value="199534">AKASO</option>
value="8657">AL Tech</option>
value="4079">Albatron</option>
value="201058">Alfawise</option>
value="11502">Ali</option>
value="4711">Alienware</option>
value="18651">Allen Bradley</option>
value="18441">ALLNET</option>
value="38786">Alpha Digital</option>
value="1263">Altec Lansing</option>
value="24938">Altex</option>
value="43902">Aluratek</option>
value="109710">Amazon</option>
value="245">AMC</option>
value="10654">AMD</option>
value="24204">AMI</option>
value="15014">Amisos</option>
value="7269">Amitech</option>
value="91359">AM-Logic</option>
value="3580">Amoi</option>
value="54025">Ampaqs</option>
value="9141">AMS</option>
value="123">Amstrad</option>
value="301">AMX</option>
value="137244">Android</option>
value="4567">Antec</option>
value="24238">Anysee</option>
value="54131">Anyware</option>
value="2616">AOC</option>
value="7094">AOpen</option>
value="12799">Apacer</option>
value="52">Apex</option>
value="388">Apple</option>
value="20543">Aquado</option>
value="489">Archos</option>
value="116379">Arctic</option>
value="30792">Arcus</option>
value="85471">Ared</option>
value="21339">Argosy</option>
value="11235">Arisetec</option>
value="48963">Armada</option>
value="196687">ARNU BOX</option>
value="156741">AsiaBox</option>
value="131858">Asmax</option>
value="18605">ASRock</option>
value="48075">Astone</option>
value="270">Asus</option>
value="182185">asustor</option>
(continues on next page)

180

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="2579">ATC</option>
value="19681">Atelco</option>
value="267">ATI</option>
value="11986">Atlas Computers</option>
value="35973">ATMT</option>
value="9695">Aura</option>
value="12613">Auvisio</option>
value="191526">auxtek</option>
value="24339">AV Labs</option>
value="12149">Avalon Sound &amp; Vision (ASV)</option>
value="102748">AVedia</option>
value="2534">AVerMedia</option>
value="121771">AVF</option>
value="8937">AVM</option>
value="152611">AVOV</option>
value="13264">Avox</option>
value="136433">Avtrol</option>
value="42685">AZbox</option>
value="14780">Aztech</option>
value="29">Bang &amp; Olufsen</option>
value="8647">Bass Computers</option>
value="86839">Bauhn</option>
value="1319">BBK Electronics</option>
value="11901">BCOM</option>
value="188636">BeeLink</option>
value="26970">Beholder</option>
value="17406">Best Buy</option>
value="113346">Bevix</option>
value="111858">BeWan</option>
value="14568">Beyond</option>
value="43956">Beyonwiz</option>
value="3473">Biostar</option>
value="33799">Black Box</option>
value="13380">Black Gold</option>
value="11418">Blu Sens</option>
value="11947">Blue Maple Networks</option>
value="129611">Blue Times</option>
value="50443">Bluegear</option>
value="10688">BlueTinum</option>
value="51139">BMS</option>
value="20962">Bogobox</option>
value="26275">BOLData</option>
value="11771">Bow</option>
value="98564">Boxee</option>
value="199148">Bqeel</option>
value="23210">Brasse</option>
value="6111">Braun</option>
value="114081">Brite-View</option>
value="6992">BTC</option>
value="9810">Buffalo</option>
value="14968">Bullit</option>
value="47405">BuyCable</option>
value="1677">Calrad</option>
value="24450">CannonPC</option>
value="73">Canon</option>
value="3279">Canopus</option>
value="80907">Captiva</option>
(continues on next page)

24.1. Harmony Devices

181

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="38548">Catronics</option>
value="191948">CaveTec</option>
value="24399">CDC</option>
value="59336">Ceconet</option>
value="60630">Celem</option>
value="20874">Cellar Cinemas</option>
value="16045">Centarea</option>
value="12856">Central Computer Systems</option>
value="1575">CentraLite</option>
value="37104">Certified Data</option>
value="150693">Ceton</option>
value="8474">Chaintech</option>
value="40682">Chicony</option>
value="12196">chiliGREEN</option>
value="81640">Chinavasion</option>
value="9167">CiBox</option>
value="10157">Cicero</option>
value="181616">CIK</option>
value="14587">Cinet</option>
value="114546">Cirago</option>
value="40715">Cisco</option>
value="11308">Cisnet</option>
value="30881">City Desk</option>
value="16692">Claritas</option>
value="41535">Clever Tech MCE</option>
value="181738">CloudMedia</option>
value="184342">CloudNetGo</option>
value="24647">CNB</option>
value="2641">Coby</option>
value="98502">Cocoon</option>
value="50372">Columbus Micro</option>
value="2380">Commodore</option>
value="216">Compaq</option>
value="40876">Compositor</option>
value="2890">Compro</option>
value="115433">CompuLab</option>
value="23528">Computer Connections</option>
value="55096">Comsis</option>
value="18013">Conceptronic</option>
value="56247">Connectland</option>
value="14887">Conrad</option>
value="10076">Control4</option>
value="196060">COOD-E</option>
value="198727">COOLEAD</option>
value="17256">Cooler Master</option>
value="50861">Cosk'in</option>
value="13440">Cowon</option>
value="420">Creative</option>
value="9875">Crestron</option>
value="16515">CTL</option>
value="2536">Cyberlink</option>
value="50389">Cybernet</option>
value="4496">CyberPower</option>
value="26069">Cyber-System</option>
value="23355">Cybertron</option>
value="78273">Cyclone</option>
value="59804">Cytem</option>
(continues on next page)

182

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="26093">D1</option>
value="74740">Dane-Elec</option>
value="121445">Dark</option>
value="11590">DataFab</option>
value="16748">DataGo</option>
value="1715">Daytek</option>
value="4108">Dazzle Multimedia</option>
value="32402">DeBoxx</option>
value="151">Dell</option>
value="21933">Deltatronic</option>
value="22884">Demonite</option>
value="42">Denon</option>
value="239">Denver</option>
value="161197">DESIGNER HABITAT</option>
value="93381">Deutsche Telekom AG</option>
value="13078">DF Solutions</option>
value="25422">DFI</option>
value="863">DGTEC</option>
value="190475">DHG</option>
value="3155">Diamond</option>
value="32527">Dicota</option>
value="19149">Differo</option>
value="58827">Diframe</option>
value="30108">Digital Cowboy</option>
value="20958">Digital Cube</option>
value="68465">Digital Decor</option>
value="59576">Digital Perspective</option>
value="14290">Digital Rise</option>
value="35868">Digital Spectrum</option>
value="2279">Digital Stream</option>
value="16462">DigitalNow</option>
value="21704">Digitus</option>
value="189161">DigiXstream</option>
value="119269">Digma</option>
value="14744">Dign</option>
value="16777">Divx</option>
value="4190">D-Link</option>
value="34543">DNJ Technology</option>
value="21413">DNT</option>
value="48233">DNTV</option>
value="195796">docooler</option>
value="200608">dolamee</option>
value="81060">Dragon Tech</option>
value="24083">Dragonbox</option>
value="22280">Dreamsys</option>
value="185046">DroidBox</option>
value="189375">DROIDPLAYER</option>
value="2820">DScaler</option>
value="13516">DTS Infocom</option>
value="47325">Dueple</option>
value="44191">Dune</option>
value="124195">DUNE HD</option>
value="127586">Dutchtronics</option>
value="11698">DVB-Viewer</option>
value="3349">Dvico</option>
value="25400">D-Vision</option>
value="147566">DXtreme</option>
(continues on next page)

24.1. Harmony Devices

183

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="15647">Dynex</option>
value="111187">Dyon</option>
value="118485">Eaget</option>
value="6448">E-Boda</option>
value="51146">EchoLogic</option>
value="24179">ECS</option>
value="5787">eCube</option>
value="70094">eData</option>
value="78369">eGreat</option>
value="22769">Elecom</option>
value="89256">Elektron</option>
value="199683">ELEMENT</option>
value="35233">Element Electronics</option>
value="21924">Elettrodata</option>
value="2377">Elgato</option>
value="7958">Elitegroup Computer Systems</option>
value="8055">Ellion</option>
value="41664">Elmak</option>
value="6755">Elonex</option>
value="3872">E-Machines</option>
value="76315">Emgeton</option>
value="68368">Eminent</option>
value="194722">EMISH</option>
value="31448">Emtec</option>
value="15621">Energy Sistem</option>
value="23781">Enermax</option>
value="19846">Enspire</option>
value="6050">Entertainment PC</option>
value="131252">EnVivo</option>
value="187505">Enybox</option>
value="6148">EPC</option>
value="7196">EPoX</option>
value="86735">Epsilon</option>
value="11">Epson</option>
value="14444">Equator</option>
value="46237">Equinux</option>
value="24265">Equus</option>
value="51">Escient</option>
value="40799">Essedi</option>
value="49474">Essentiel B</option>
value="35392">Eureka</option>
value="18369">Euromatrix</option>
value="5591">Evation</option>
value="19790">Everex</option>
value="75981">EverTech</option>
value="9633">Evesham</option>
value="46001">EVGA</option>
value="40522">Evolve</option>
value="15036">Extended Systems</option>
value="31700">Extreme Solutions</option>
value="16524">Falcon Northwest</option>
value="59073">Fantec</option>
value="69333">FAVI</option>
value="1386">Ferguson</option>
value="55548">FIA</option>
value="24649">FIC</option>
value="190107">Filmspeler</option>
(continues on next page)

184

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="22857">Flipr</option>
value="162634">Flirc</option>
value="10385">fly video</option>
value="67272">Foxconn</option>
value="10850">Freecom</option>
value="8835">Freevo</option>
value="55741">Frontier</option>
value="55443">Frost ACM</option>
value="9433">Fry's</option>
value="143">Fujitsu</option>
value="6606">Fujitsu-Siemens</option>
value="3457">Fukushima</option>
value="103">Funai</option>
value="4949">Fusion</option>
value="50870">Fusion Research</option>
value="904">Galaxy</option>
value="501">Gateway</option>
value="93981">GBOX</option>
value="7440">GB-PVR</option>
value="199">Gemini</option>
value="35779">Geniatech</option>
value="7785">Genius</option>
value="127975">Giada</option>
value="8908">GIEC</option>
value="1790">GigaByte</option>
value="53692">Gladiator</option>
value="200346">GLOBMALL</option>
value="67067">GMC</option>
value="131255">Gmini</option>
value="165094">gmyle</option>
value="61367">Goldlantern</option>
value="195893">Goobang Doo</option>
value="2089">Goodmans</option>
value="36442">Goodview</option>
value="117498">Google</option>
value="145">GoVideo</option>
value="37722">GQ</option>
value="11753">Granville</option>
value="199751">GReATeVeR</option>
value="11433">Griffin</option>
value="11555">Gyration</option>
value="4183">H&amp;B</option>
value="72558">H.TV</option>
value="26636">Hallmark Computer</option>
value="8358">Hama</option>
value="70481">Hantech</option>
value="187721">Hardkernel</option>
value="14306">Hatch</option>
value="829">Hauppauge</option>
value="66754">hBox</option>
value="67736">hd box</option>
value="85526">HD Digitech</option>
value="100375">HDI</option>
value="144395">HDium</option>
value="187596">HDLand</option>
value="122653">HDMAX</option>
value="1216">Helios</option>
(continues on next page)

24.1. Harmony Devices

185

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="220">Hewlett Packard</option>
value="23980">HFX</option>
value="16492">Hifidelio</option>
value="5468">Hi-Grade</option>
value="77876">HiMedia</option>
value="13653">Hiper</option>
value="2945">Hisense</option>
value="185628">HiSilikon</option>
value="45">Hitachi</option>
value="74796">HMB</option>
value="272">HomeVision</option>
value="73717">Honor</option>
value="25431">Hoojum</option>
value="112080">HornetTek</option>
value="67267">HTC</option>
value="30264">Huawei</option>
value="864">Humax</option>
value="3559">Hush</option>
value="27848">Hyrican Tango</option>
value="2447">Hyundai</option>
value="253">IBM</option>
value="4997">iBuyPower</option>
value="2199">i-CAN</option>
value="16745">Ichbinleise</option>
value="88642">ICIDU</option>
value="67027">iconBIT</option>
value="7224">ICube</option>
value="37238">Ider</option>
value="50062">IDKorea</option>
value="31977">iDream</option>
value="195352">IDROIDNATION</option>
value="12412">i-Friend</option>
value="47240">Igor</option>
value="34118">IKBENSTIL</option>
value="32332">Imagin</option>
value="109693">Imation</option>
value="177725">iMito</option>
value="17594">iMuse Electronics</option>
value="166697">Incredisonic</option>
value="4509">iNeXT</option>
value="46867">Infni</option>
value="221">Infocus</option>
value="13305">Inmatrix</option>
value="24736">INOi</option>
value="138751">InOutTV</option>
value="109024">Inphic</option>
value="15167">Insight</option>
value="6394">Insignia</option>
value="167">Integra</option>
value="14196">Intel</option>
value="87608">Intertech</option>
value="10898">Inteset</option>
value="25174">Inves</option>
value="34131">Invion</option>
value="3217">IO Data</option>
value="102443">ioBox</option>
value="5913">IOGear</option>
(continues on next page)

186

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="13838">Iomega</option>
value="25434">iOne</option>
value="94599">Iospirit</option>
value="49809">IPEX</option>
value="9887">I-Point</option>
value="17484">IPS</option>
value="25545">IQ</option>
value="153330">IRF Media</option>
value="2688">iRiver</option>
value="65942">iSonic</option>
value="75037">iSTAR</option>
value="21941">ITV Media</option>
value="19519">iWILL</option>
value="1701">IX</option>
value="54355">Izzy</option>
value="3889">J. River</option>
value="97564">Jadoo</option>
value="108373">JadooTV</option>
value="12368">Jaycar</option>
value="14514">JB Media</option>
value="79583">JCMatthew</option>
value="191593">JetStreamBox</option>
value="25402">Jetta</option>
value="7308">Jetway</option>
value="197297">Jide</option>
value="197692">JOCOKA</option>
value="47315">Jusst</option>
value="173197">Jynxbox</option>
value="76774">Kaiboer</option>
value="50055">Kaiser Baas</option>
value="3260">Kaleidescape</option>
value="4424">Kanam</option>
value="93629">Kartina TV</option>
value="95744">Kaser</option>
value="38829">Kazimogo</option>
value="163351">KdLinks</option>
value="187649">Keedox</option>
value="31735">Keelai</option>
value="24216">KeeLai Tech</option>
value="200093">KEKILO</option>
value="200">Keyspan</option>
value="14493">Kingpin</option>
value="25896">Kingsun</option>
value="28052">KingWin</option>
value="4854">Kinyo</option>
value="16035">Kiss</option>
value="2387">Klegg</option>
value="8972">Kloss</option>
value="288">Kodak</option>
value="191591">kodi</option>
value="34014">Kogan</option>
value="25066">Komplett</option>
value="21590">Konig</option>
value="43724">KoolVu</option>
value="1049">Kramer</option>
value="24822">KSI</option>
value="200086">kudoTV</option>
(continues on next page)

24.1. Harmony Devices

187

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="1656">KWorld</option>
value="10210">LaCie</option>
value="61959">LASER</option>
value="7575">LC Power</option>
value="40947">LCD Memories</option>
value="51079">LCD Photo</option>
value="2508">Leadtek</option>
value="52649">Ledtech</option>
value="196987">Leelbox</option>
value="38557">Lenovo</option>
value="167246">LETV</option>
value="956">Leviton</option>
value="39">LG</option>
value="45795">Lian Li</option>
value="8576">LifeView</option>
value="7483">Lindemann</option>
value="1470">Linksys</option>
value="38403">Linx</option>
value="2250">LiteOn</option>
value="945">Logitech</option>
value="26261">Longshine</option>
value="126117">LPINTE</option>
value="79318">m1</option>
value="37140">Mach Speed</option>
value="47718">Macom</option>
value="43458">Macpower</option>
value="106994">Macron</option>
value="19913">Macrosystem</option>
value="18">Magnavox</option>
value="62672">Magnetox</option>
value="11835">Magnex</option>
value="132232">Manli</option>
value="11763">Manta</option>
value="15547">Maqma</option>
value="12365">Marshall Electronics</option>
value="159002">Masora AG</option>
value="81074">Masscool</option>
value="177022">Matricom</option>
value="38874">Matsunichi</option>
value="13274">Maxdata</option>
value="47739">Maxdome</option>
value="45387">Maxian</option>
value="31155">MaxInPower</option>
value="47729">MBOX</option>
value="85772">MBX</option>
value="164">McIntosh</option>
value="17231">mCubed</option>
value="7635">MDG</option>
value="55209">Me2</option>
value="108070">Measy</option>
value="11085">Mecer</option>
value="200054">MECOOL</option>
value="119054">MEDE8ER</option>
value="9261">Media Portal</option>
value="27916">MediaCom</option>
value="22530">Mediaman</option>
value="16523">Mediasonic</option>
(continues on next page)

188

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="707">Mediatech</option>
value="1085">Medion</option>
value="5589">Meedio</option>
value="66701">Mele</option>
value="182978">memoBOX</option>
value="26015">Memory Express</option>
value="27177">Memup</option>
value="32380">Merlin</option>
value="11213">MESH</option>
value="80895">Mesiro</option>
value="153246">Meteorit</option>
value="16276">Mevis</option>
value="133306">Micca</option>
value="11458">Micro Innovations</option>
value="6013">MicroByte</option>
value="310">Micron</option>
value="115">Microsoft</option>
value="12651">Microstar</option>
value="25594">Microtel</option>
value="53470">Midte</option>
value="8014">Miglia</option>
value="25487">Mind</option>
value="199805">Mini TV BOX</option>
value="18910">Minix</option>
value="17910">MiTAC</option>
value="176011">MK808</option>
value="32074">ML Arvutid</option>
value="19334">MM-Vision</option>
value="49767">Modecom</option>
value="13232">Monarch Computer Systems</option>
value="34646">Moneual</option>
value="141668">Monsoon Multimedia</option>
value="188511">MoonBox</option>
value="7725">Motion Computing</option>
value="49">Motorola</option>
value="74365">MPMAN</option>
value="24323">MPX</option>
value="3157">MSI</option>
value="42970">mStation</option>
value="13700">MS-Tech</option>
value="68417">MT Visions</option>
value="913">Music Mountain</option>
value="962">Mustek</option>
value="29398">Muvid</option>
value="15481">Mvix</option>
value="193428">MXQ</option>
value="123241">MXV</option>
value="80196">MyGica</option>
value="186226">MySku</option>
value="2438">MythTV</option>
value="213">Naim</option>
value="152173">Natec</option>
value="35236">NComputing</option>
value="57318">Nebula Media Solutions</option>
value="12">NEC</option>
value="140705">Neewer</option>
value="27900">NeoDigits</option>
(continues on next page)

24.1. Harmony Devices

189

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="51108">Neonumeric</option>
value="15187">Net Digital</option>
value="4018">Netgear</option>
value="36687">Netkia</option>
value="26435">Network</option>
value="17214">Neuros</option>
value="3563">Neuston</option>
value="46115">Neutron</option>
value="57261">Newron</option>
value="198510">NEXBOX</option>
value="201113">NEXSMART</option>
value="28577">NHJ</option>
value="14658">NiceTracker</option>
value="5599">Niveus Media</option>
value="137839">Nixeus</option>
value="17020">NMediaPC</option>
value="29954">Noontec</option>
value="112638">Normus</option>
value="55514">Northern Micro</option>
value="41583">Novac</option>
value="82581">Novatech</option>
value="20393">Novatron</option>
value="31606">Novita</option>
value="66565">NOX</option>
value="51663">NZXT</option>
value="86564">O2Media</option>
value="50747">O3B</option>
value="44588">Odsonic</option>
value="17959">ODYS</option>
value="37261">Okoro</option>
value="35961">Okoro Media Systems</option>
value="12432">Olidata</option>
value="201177">OMG FREETV</option>
value="9193">OnCinema</option>
value="40">Onkyo</option>
value="13847">Open Source Factory</option>
value="156846">openelec</option>
value="192538">OpenHour</option>
value="13058">Optima</option>
value="38">Optimus</option>
value="18215">Orange</option>
value="188862">Orbsmart</option>
value="35204">Ordi</option>
value="13986">Origen AE Technology</option>
value="423">Orion</option>
value="69839">ORtek</option>
value="194279">OSMC</option>
value="189948">OTT TV BOX</option>
value="18619">Overdrive PC</option>
value="197403">ovomedia</option>
value="41658">PAC</option>
value="4067">Packard Bell</option>
value="13152">Palmbutler</option>
value="13">Panasonic</option>
value="35848">PanDigital</option>
value="51446">Pantiac</option>
value="9082">Paradigit</option>
(continues on next page)

190

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="3595">Parex</option>
value="53562">Patriot</option>
value="14764">PC Mak</option>
value="11551">PC Plaza</option>
value="12465">PC Sleuth</option>
value="34201">Pcalchemy</option>
value="17547">PCCity</option>
value="13406">PCzapper</option>
value="12112">Peach Tron Systems</option>
value="43337">Pearl</option>
value="3785">Peekton</option>
value="87179">PeerTV</option>
value="14981">Penguin Computing</option>
value="191786">PeQ</option>
value="51900">Perfection</option>
value="27">Philips</option>
value="53661">PINE</option>
value="1205">Pinnacle</option>
value="4">Pioneer</option>
value="87995">Pipi</option>
value="67727">Pirelli</option>
value="160980">Pivos</option>
value="8916">Pixel Magic Systems</option>
value="8133">PixelView</option>
value="19217">Platinum</option>
value="38108">Playtime</option>
value="130339">Playtronics</option>
value="87601">Plex</option>
value="8577">Plextor</option>
value="506">Polaroid</option>
value="3367">Polycom</option>
value="11243">Polywell</option>
value="10699">POMi</option>
value="136750">PopBox</option>
value="98519">Popcorn Hour</option>
value="105572">Poppstar</option>
value="39701">Portable USA</option>
value="12275">Positivo</option>
value="94355">Power Zest</option>
value="12119">PowerColor</option>
value="8678">PowerSpec</option>
value="38912">PQI</option>
value="76415">PremiumBlue</option>
value="10700">Prestigio</option>
value="24373">PrimeDTV</option>
value="15623">Princeton</option>
value="117103">Probox</option>
value="191728">Probox2</option>
value="124073">Prodigi</option>
value="1134">ProSAT</option>
value="23032">Psyclone</option>
value="32606">Pyrogate</option>
value="200336">QcoQce</option>
value="24678">QCS</option>
value="192892">Qianxun</option>
value="61834">QMedia</option>
value="19527">Q-Motion</option>
(continues on next page)

24.1. Harmony Devices

191

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="94246">Qnap</option>
value="6089">QPVision</option>
value="14852">Quality PC</option>
value="15741">Quartek</option>
value="17178">Quibus</option>
value="198550">Quick Play</option>
value="4246">Quixun</option>
value="95603">Radiogears</option>
value="443">RadioShack</option>
value="58220">RaidSonic</option>
value="66209">Rapsody</option>
value="172343">Raspberry</option>
value="7">RCA</option>
value="80763">RCKING</option>
value="65951">Red Sky Global</option>
value="12347">Redbell</option>
value="12378">Reel Multimedia</option>
value="14706">Remotec</option>
value="28132">Replay Plus</option>
value="371">ReQuest</option>
value="192140">revez</option>
value="179">Revox</option>
value="14896">Reycom</option>
value="14412">RicaVision</option>
value="172678">Rikomagic</option>
value="8325">Rimax</option>
value="16278">Riscom</option>
value="77146">Ritmo</option>
value="37418">Rivertech</option>
value="28566">Rixid</option>
value="47796">Rock</option>
value="165884">Rockchip</option>
value="199853">Rominetak</option>
value="117528">Rosen Aviation</option>
value="57775">Rosewill</option>
value="90031">Roxcore</option>
value="15049">Royal</option>
value="14308">R-Style</option>
value="62551">RTI</option>
value="147">Russound</option>
value="12726">S1Digital</option>
value="12802">SACA Technologies</option>
value="8864">Sage</option>
value="12183">SageTV</option>
value="2086">Salora</option>
value="118935">Sama</option>
value="2">Samsung</option>
value="44128">San Hawk</option>
value="1959">SanDisk</option>
value="17052">Sansun</option>
value="11253">Sapphire</option>
value="11908">Sarotech</option>
value="12323">Savit Micro</option>
value="10717">Sceneo</option>
value="190242">SCISHION</option>
value="26485">Sdtec</option>
value="72767">Seagate</option>
(continues on next page)

192

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="10744">Seanix</option>
value="5910">Sencor</option>
value="19890">Sharkoon</option>
value="8">Sharp</option>
value="52509">Shenzhen Newland</option>
value="53887">Shenzhen Soma</option>
value="48241">SHG</option>
value="104362">Shintaro</option>
value="797">Shuttle</option>
value="13284">Sicuro</option>
value="3306">Siemens</option>
value="2844">Sigma Designs</option>
value="1502">Sigmatek</option>
value="25501">SigmaTel</option>
value="12578">Silentmaxx</option>
value="8960">SilverCrest</option>
value="12330">Silverleaf</option>
value="8123">Silverstone</option>
value="61342">SIMEREC</option>
value="13022">Sitecom</option>
value="27874">SkipJam</option>
value="12553">Sky</option>
value="61553">Skystar</option>
value="191494">Skystream</option>
value="3519">SkyWorth</option>
value="6496">SleekLine</option>
value="42268">Sling Media</option>
value="4613">SmartDisk</option>
value="28148">SmartParts</option>
value="190095">SmartThings</option>
value="1135">SMC</option>
value="1300">SnapStream</option>
value="10166">SnaZio</option>
value="43395">Snogard</option>
value="46183">Solid Year</option>
value="165345">SolidRun</option>
value="23706">Solidtek</option>
value="16103">Soltek</option>
value="10776">Sonavis</option>
value="42804">Sonbook</option>
value="30444">Sonic Impact</option>
value="1">Sony</option>
value="17599">SorensonVRS</option>
value="10294">SoundGraph</option>
value="12287">SOYO</option>
value="12255">Spectra</option>
value="81773">Speed</option>
value="17607">Speed-Link</option>
value="14620">ST Lab</option>
value="1650">Stands Unique</option>
value="12523">Stein</option>
value="37926">STiNO</option>
value="15776">Storex</option>
value="159725">Streacom</option>
value="200967">STREAM TEAM MEDIA</option>
value="196331">STREAMAXTV</option>
value="193260">StreamSmart</option>
(continues on next page)

24.1. Harmony Devices

193

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="1071">Streamzap</option>
value="47851">Sumicom</option>
value="7188">Sumvision</option>
value="25750">Sun Microsystems</option>
value="198096">Sunvell</option>
value="50097">SuperMicro</option>
value="50009">Superna</option>
value="53413">SuperPower</option>
value="116962">Sveon</option>
value="34182">Sweex</option>
value="10362">Syabas</option>
value="20578">Syba</option>
value="61311">Synology</option>
value="4171">Syntax-Brillian</option>
value="35636">Sysmaster</option>
value="9717">Systemax</option>
value="94196">syvio</option>
value="4923">Tagar Systems</option>
value="2056">Tandberg</option>
value="199761">Tanix</option>
value="6337">Targa</option>
value="23631">Target</option>
value="21874">Tarox</option>
value="13073">TCI</option>
value="50571">TCR</option>
value="36">Teac</option>
value="67282">TechGear</option>
value="4693">Technaxx</option>
value="7251">Technika</option>
value="1329">TechniSat</option>
value="7371">TechnoTrend</option>
value="18681">Techsolo</option>
value="132344">TechStudioTV</option>
value="75571">Tekkeon</option>
value="28819">Tekram</option>
value="31399">Telecom Italia</option>
value="15495">Telekom</option>
value="12075">Tempest Microsystems</option>
value="1118">Terratec</option>
value="5825">Teufel</option>
value="91367">TeVii</option>
value="5808">Texas Instruments</option>
value="36483">Texet</option>
value="7531">Textorm</option>
value="184224">The Little Black Box</option>
value="13599">TheBox</option>
value="85794">Thecus</option>
value="16114">Thermaltake</option>
value="126">Thomson</option>
value="196639">TICTID</option>
value="4842">Tilgin</option>
value="249">TiVo</option>
value="163223">TizzBird</option>
value="52301">Tomacro</option>
value="196411">Tonbux</option>
value="62865">Topke</option>
value="124655">Topseed</option>
(continues on next page)

194

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

value="199799">Topsion</option>
value="9883">Torspoal</option>
value="5">Toshiba</option>
value="9101">Touch Systems</option>
value="36195">Tranquil PC</option>
value="11883">Transcend</option>
value="8961">Traxdata</option>
value="48659">Trekstor</option>
value="38804">Tricod</option>
value="31646">Triline</option>
value="21864">Trinix</option>
value="192589">Tronfy</option>
value="199331">Trongle</option>
value="179524">Tronsmart</option>
value="9246">Trust</option>
value="22371">Tsunami Dream</option>
value="23580">Tundra</option>
value="55707">Turbo-X</option>
value="191819">TVB Anywhere</option>
value="37199">TVonics</option>
value="4293">TwinHan</option>
value="76981">Twisted Melon</option>
value="41737">TwonkyMedia</option>
value="10871">Tyan</option>
value="9554">Typhoon</option>
value="186933">U2C</option>
value="166823">UBOX</option>
value="139766">Uebo</option>
value="175913">UGOOS</option>
value="7534">UIRT</option>
value="13348">Umax</option>
value="57978">Umbra</option>
value="192076">Unblock Tech</option>
value="12940">Uneed</option>
value="6532">UniBrain</option>
value="14204">Unicorn</option>
value="12751">Unika</option>
value="12504">Uvem</option>
value="32264">Vadim</option>
value="291">Vantage</option>
value="31405">VEI</option>
value="19091">Velocity Micro</option>
value="162528">VENZ</option>
value="89397">Verbatim</option>
value="44280">Verkkokauppa</option>
value="14642">Via</option>
value="34618">Vibe</option>
value="41761">Vidabox</option>
value="193849">Videostrong</option>
value="179094">VidOn.me</option>
value="217">ViewSonic</option>
value="192387">VIGICA</option>
value="29890">Viglen</option>
value="11851">Viscom</option>
value="14590">VisionPlus</option>
value="1156">Vizio</option>
value="21634">VLSystem</option>
(continues on next page)

24.1. Harmony Devices

195

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option
<option

196

value="21512">Vobis</option>
value="184069">VONHAUS</option>
value="12218">Voodoo PC</option>
value="8463">VPR Matrix</option>
value="54604">Vudu, Inc.</option>
value="43858">We Digital</option>
value="16573">Webster</option>
value="19795">Welland</option>
value="7748">Wellton Way</option>
value="73793">Western Digital</option>
value="193008">WeTek</option>
value="12161">White Box Computers</option>
value="4020">WinBook</option>
value="51240">Wincomm</option>
value="8381">Woxter</option>
value="118559">Wyplayer</option>
value="56670">Wyse</option>
value="58">X10 Wireless</option>
value="15111">X4-Tech</option>
value="118279">Xenta</option>
value="195958">XGODY</option>
value="181054">Xiaomi</option>
value="28767">Ximeta</option>
value="4499">Xitel</option>
value="49736">X-ONE</option>
value="5100">Xoro</option>
value="58753">Xparity</option>
value="113618">Xtreamer</option>
value="3432">Xtreme</option>
value="5499">Yakumo</option>
value="25">Yamaha</option>
value="196901">Yixu</option>
value="200561">YokaTV</option>
value="25205">Yuan</option>
value="197047">Yuntab</option>
value="131996">YuppTV</option>
value="23925">Zaapa</option>
value="136988">ZAAPTV</option>
value="17847">Zalman</option>
value="179654">Zappiti</option>
value="32609">Zelfbouw</option>
value="22010">Zepto</option>
value="194333">Zidoo</option>
value="17658">Ziga</option>
value="1000">Zinwell</option>
value="31936">Zio</option>
value="23594">Zioncom</option>
value="43123">Ziova</option>
value="15555">Zitech</option>
value="186475">Zoomtak</option>
value="110163">Zotac</option>
value="6054">ZT Group</option>
value="28514">ZyXEL</option></select>

Chapter 24. Logitech Harmony

Dan’s Cheat Sheets Documentation, Release 1

24.2 Install Concordance
Install the concordance tool.
I’m using v1.0 on Ubuntu 15.10 64-bit.
Briefly:
sudo apt-get install libusb-dev libzzip-dev
wget http://downloads.sourceforge.net/project/concordance/concordance/1.0/concordance˓→1.0.tar.bz2
tar xjf concordance-1.0.tar.bz2
cd concordance-1.0/libconcord
./configure
make
sudo make install
sudo ldconfig
cd ../concordance
./configure
make
sudo make install

24.3 Arrange to run without needing sudo
• Run ‘lsusb’ to see what devices are already attached to your computer.
• Plug in your remote
• Run ‘lsusb’, looking for the device that wasn’t there before. E.g. my Harmony One produced this:
Bus 001 Device 021: ID 046d:c121 Logitech, Inc.

• Unplug the remote
• Now (using sudo as needed) create a new file, /etc/udev/rules.d/custom-concordance.rules, substituting in the
values for your own remote:
ATTRS{idVendor}=="046d", ATTRS{idProduct}=="c121", MODE="666"

• Test
– Plug the remote in
– Run “concordance -i”. It should print out information about the attached remote

24.4 Programming the remote
• Make a directory to hold firmware and config backups, e.g. ~/Documents/LogitechHarmonyOne.
• cd ~/Documents/LogitechHarmonyOne
• Backup firmware if you haven’t previously:
concordance --dump-firmware <filename> (default: firmware.EZUp)

• Backup config if you haven’t previously:

24.2. Install Concordance

197

Dan’s Cheat Sheets Documentation, Release 1

concordance --dump-config <filename>

(default: config.EZHex)

• Go to http://members.harmonyremote.com/EasyZapper/ and log in (ignore the message about upgrading your
software). If you don’t already have an account, create one.
• Update your remote’s configuration using the web site.
• When ready to update your remote:
– Click “Update your remote”. It’ll prompt to connect your remote.
– Connect the remote to the computer via USB.
– Click “Next” on the web page.
– Your browser will download a file named “Connectivity.EZHex”. Save it to your LogitechHarmonyOne
directory.
– Go to your shell.
– Run:
concordance Connectivity.EZHex

– Go back to your browser.
– Click “Next”.
– Wait. . . could be several minutes.
– Eventually your browser will download a file named “Update.EZHex”. Save it to your LogitechHarmonyOne directory.
– Go to your shell.
– Run this command. This will take quite a while (5 minutes?), but it will print progress status as it goes:
concordance Update.EZHex

– When that’s done, disconnect your remote and try it out.

198

Chapter 24. Logitech Harmony

CHAPTER

25

MPD

25.1 Fixing on Ubuntu
On Ubuntu, mpd is installed broken. You’ll have to go read this page and do some work to fix things so mpd will
actually work on Ubuntu. Sigh.
Important: To play anything, you must first get it into the current playlist. Even if you just want to play one thing.

25.2 Playlist commands
Commands that change the playlist:
clear Empty the playlist (stops playing if anything was playing)
crop Delete all playlist entries except the one currently playing
del <number> Delete one item from the playlist; 0 means the currently playing item, otherwise items are numbered
starting at 1. (To see playlist with numbers, try mpc playlist | cat -n. There’s probably a better way.)
add <file> Add an item from the database to the current playlist, at the end. <file> should be a path to the item, as
shown by “mpc ls”.
insert <file> Like add, only it puts the item immediately after the currently playing item, so it’ll play next. If random
mode is enabled, it’ll still be played next.
mv|move <from> <to> Move item at position <from> to be at position <to>.
save <name> Save current playlist as database playlist with name <name>.
load <name> Add contents of database playlist named <name> to the current playlist.
rm <name> Delete database playlist named <name> from database.

199

Dan’s Cheat Sheets Documentation, Release 1

25.3 Playing things
Status:
playlist [-f <format>] List songs in current playlist. See “man mpc” for format string syntax.
current Show what’s playing right now
Control:
play [<position>] Start playing the item at <position> in the playlist. Deafult is number 1.
pause Pause playing
stop Stop playing
next Stop playing the current entry from the current playlist and start playing the next one.
prev Reverse of next.

25.4 Playing a playlist from the music database with mpc
Suppose you have a playlist in the database already - e.g. a file “/var/lib/mpd/playlists/WCPE.m3u” that you’ve created
earlier.
Now you want to play that playlist.
$ mpc clear
$ mpc lsplaylists
WUNC
WCPE
Favorites
$ mpc load WCPE
loading: WCPE
$ mpc play
volume: 96%
repeat: on
random: off
single: off
loading: WCPE
http://audio-ogg.ibiblio.org:8000/wcpe.ogg
[playing] #1/1
0:00/0:00 (0%)
volume: 96%
repeat: on
random: off
single: off

200

consume: off

consume: off

Chapter 25. MPD

CHAPTER

26

MySQL with Django

Ubuntu: need to install (to use MySQL with Django):
sudo apt-get install mysql-client mysql-server libmysqlclient-dev

Django:
pip install mysqlclient
DATABASES['default'] = {
'ENGINE': 'django.db.backends.mysql',
'NAME': 'dbname',
'USER': 'username',
}

26.1 Using the client
Starting the client:
$ mysql --user=username [database]
# if user has no password
$ mysql --user=username --password [database]
# to be prompted for password

To do things that require mysql root:
$ mysql -u root
# If root has no password and older Debian
$ mysql -u root -p # if root has password and older Debian
$ sudo mysql -u root
# On more recent Debian, no need for root password but must be
˓→root user

201

Dan’s Cheat Sheets Documentation, Release 1

26.2 Users and permissions
In the client:
mysql> SELECT user, host from mysql.user;
# List existing
˓→users
mysql> CREATE USER 'username' IDENTIFIED BY 'plaintextpassword';
# Create user
˓→with password
mysql> CREATE USER 'username'@'localhost';
# no password, can only connect locally
mysql> SHOW DATABASES;
mysql> CREATE DATABASE databasename;
mysql> GRANT ALL ON databasename.* TO "username"@"hostname" IDENTIFIED BY "password";
mysql> FLUSH PRIVILEGES;
mysql> DROP DATABASE databasename;
mysql> DROP USER username;
mysql> EXIT
Bye

26.3 Change user password
Note: default host is ‘%’ which will not let you connect via unix socket, must set password for host ‘localhost’ to
allow that:
mysql> update mysql.user set password=password('foo'),host='localhost' where user=
˓→'poirier_wordpres';
# On older MySQL
mysql> set password for 'dpoirier'@'localhost' = 'plainpass'; # More recent MySQL
mysql> flush privileges;

26.4 Recover lost password
http://dev.mysql.com/doc/refman/5.5/en/resetting-permissions.html
C.5.4.1.3. Resetting the Root Password: Generic Instructions On any platform, you can set the new password using
the mysql client:
Stop mysqld
Restart it with the --skip-grant-tables option. This enables anyone to connect
˓→without a password and with all privileges. Because this is insecure, you might
˓→want to use --skip-grant-tables in conjunction with --skip-networking to prevent
˓→remote clients from connecting.
$ mysql
mysql> UPDATE mysql.user SET Password=PASSWORD('MyNewPass') WHERE User='root';
mysql> FLUSH PRIVILEGES;
mysql> EXIT
Stop the server
Restart it normally (without the --skip-grant-tables and --skip-networking options).

202

Chapter 26. MySQL with Django

Dan’s Cheat Sheets Documentation, Release 1

26.5 Dumps
Make a dump:
mysqldump --single-transaction _dbname_ > dumpfile.sql
mysqldump --result-file=dumpfile.sql --single-transaction _dbname_

(Use --single-transaction to avoid locking the DB during the dump.)
Restore a dump:
mysql dbname < dumpfile.sql

26.6 Create a new MySQL database
Step by step:
$ mysql -u root -p
<ENTER MYSQL ROOT PASSWORD>
mysql> create user 'ctsv2_TR'@'localhost';
mysql> create database ctsv2_TR;
mysql> grant all on ctsv2_TR.* to 'cstv2_TR'@'localhost';
mysql> flush privileges;
mysql> exit
Bye

26.5. Dumps

203

Dan’s Cheat Sheets Documentation, Release 1

204

Chapter 26. MySQL with Django

CHAPTER

27

Nginx

Nginx docs are here but good luck finding anything there if you don’t already where it is.

27.1 Redirect non-SSL to SSL
From https://serverfault.com/questions/250476/how-to-force-or-redirect-to-ssl-in-nginx:
server {
listen
listen
listen

80;
[::]:80;
443 default_server ssl;

server_name www.example.com;
ssl_certificate
ssl_certificate_key

/path/to/my/cert;
/path/to/my/key;

if ($scheme = http) {
return 301 https://$server_name$request_uri;
}
}

27.2 Most useful variables
$host in this order of precedence: host name from the request line, or host name from the “Host” request header field,
or the server name matching a request
$http_host Value of the “Host:” header in the request (same as all $http_<headername> variables)
$https “on” if connection operates in SSL mode, or an empty string otherwise
$request_method request method, usually “GET” or “POST”

205

Dan’s Cheat Sheets Documentation, Release 1

$request_uri full original request URI (with arguments)
$scheme request scheme, e.g. “http” or “https”
$server_name name of the server which accepted a request
$server_port port of the server which accepted a request

27.3 Variables in configuration files
See above for “variables” that get set automaticaly for each request (and that we cannot modify).
The ability to set variables at runtime and control logic flow based on them is part of the rewrite module and not a
general feature of nginx.
You can set a variable:
Syntax:
Default:
Context:

set $variable value;
-server, location, if

“The value can contain text, variables, and their combination.” – but I have not yet found the documentation on how
these can be “combined”.
Then use if etc.:
Syntax:
Default:
Context:

if (condition) { rewrite directives... }
-server, location

Conditions can include:
* a variable name; false if the value of a variable is an empty string or “0”;
* comparison of a variable with a string using the “=” and “!=” operators;
* matching of a variable against a regular expression using the “~” (for case˓→sensitive matching) and “~*” (for case-insensitive matching) operators. Regular
˓→expressions can contain captures that are made available for later reuse in the $1..
˓→$9 variables. Negative operators “!~” and “!~*” are also available. If a regular
˓→expression includes the “}” or “;” characters, the whole expressions should be
˓→enclosed in single or double quotes.
* checking of a file existence with the “-f” and “!-f” operators;
* checking of a directory existence with the “-d” and “!-d” operators;
* checking of a file, directory, or symbolic link existence with the “-e” and “!-e”
˓→operators;
* checking for an executable file with the “-x” and “!-x” operators.

Examples:
if ($http_user_agent ~ MSIE) {
rewrite ^(.*)$ /msie/$1 break;
}
if ($http_cookie ~* "id=([^;]+)(?:;|$)") {
set $id $1;
}
if ($request_method = POST) {
return 405;
(continues on next page)

206

Chapter 27. Nginx

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

}
if ($slow) {
limit_rate 10k;
}
if ($invalid_referer) {
return 403;
}

Warning: You CANNOT put any directive you want inside the if, only rewrite directives like set, rewrite,
return, etc.

Warning: The values of variables you set this way can ONLY be used in if conditions, and maybe rewrite
directives; don’t try to use them elsewhere.

27.3. Variables in configuration files

207

Dan’s Cheat Sheets Documentation, Release 1

208

Chapter 27. Nginx

CHAPTER

28

NPM

Make npm install less noisy:
npm config set loglevel warn

or add this to ~/.npmrc:
loglevel=warn

source.

209

Dan’s Cheat Sheets Documentation, Release 1

210

Chapter 28. NPM

CHAPTER

29

OpenSSL

Some of this from http://www.coresecuritypatterns.com/blogs/?p=763 and http://www.bogpeople.com/networking/
openssl.shtml.

29.1 End-user Functions
29.1.1 Create key
Create a 2048-bit key pair:
openssl genrsa 2048 > myRSA-key.pem
openssl genrsa -out blah.key.pem
openssl genrsa -out blah.key.pem 2048

Create a password-protected 2048-bit key pair:
openssl genrsa 2048 -aes256 -out myRSA-key.pem

OpenSSL will prompt for the password to use. Algorithms: AES (aes128, aes192 aes256), DES/3DES (des, des3).
Remove passphrase from a key:
openssl rsa -in server.key -out server-without-passphrase.key

Extract public key:
openssl rsa -in blah.key.pem -out public.key -pubout

29.1.2 Getting Certificates
Create Certificate Request and Unsigned Key:

211

Dan’s Cheat Sheets Documentation, Release 1

openssl req -nodes -new -keyout blah.key.pem -out blah.csr.pem

More thorough example:
openssl req -new rsa:1024 -node -out myCSR.pem \
-keyout myPrivCertkey.pem \
-subj "/C=US/ST=MA/L=Burlington/CN=myHost.domain.com/emailAddress=user@example.com
˓→"

Create a self-signed certificate:
openssl req -nodes -x509 -newkey rsa:1024 -days 365 \
-out mySelfSignedCert.pem -set_serial 01 \
-keyout myPrivServerKey.pem \
-subj "/C=US/ST=MA/L=Burlington/CN=myHost.domain.com/emailAddress=user@example.com
˓→"

-x509 identifies it as a self-signed certificate and -set_serial sets the serial number for the server certificate.
Create a single file that contains both private key and the self-signed certificate:
openssl req -x509 -nodes -days 365 -newkey rsa:1024 \
-keyout myServerCert.pem -out myServerCert.pem \
-subj "/C=US/ST=MA/L=Burlington/CN=myHost.domain.com/emailAddress=user@example.com
˓→"

Fingerprint for Unsigned Certificate:
openssl x509 -subject -dates -fingerprint -in blah.key.pem

Display Certificate Information:
openssl x509 -in blah.crt.pem -noout -text

Creating a PEM File for Servers:
cat blah.key.pem blah.crt.pem blah.dhp.pem > blah.pem

Download some server’s certificate:
openssl s_client -connect www.example.com:443

(then hit ^C out of the interactive shell)

29.1.3 Viewing Certificate Contents
X.509 certificates are usually stored in one of two formats. Most applications understand one or the other, some
understand both:
• DER which is raw binary data.
• PEM which is a text-encoded format based on the Privacy-Enhanced Mail standard (see RFC1421). PEM-format
certificates look something like this:
-----BEGIN CERTIFICATE----MIIBrjCCAWwCAQswCQYFKw4DAhsFADBTMQswCQYDVQQGEwJBVTETMBEGA1UECBMK
(continues on next page)

212

Chapter 29. OpenSSL

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

U29tZS1TdGF0ZTEhMB8GA1UEChMYSW50ZXJuZXQgV2lkZ2l0cyBQdHkgTHRkMQww
:
:
MQAwLgIVAJ4wtQsANPxHo7Q4IQZYsL12SKdbAhUAjJ9n38zxT+iai2164xS+LIfa
C1Q=
-----END CERTIFICATE----OpenSSL uses the PEM format by default, but you can tell it to process DER format
˓→certificates...you just need to know which you are dealing with.

The command to view an X.509 certificate is:
openssl x509 -in filename.cer -inform der -text

You can specifiy -inform pem if you want to look at a PEM-format certificate

29.1.4 Convert Between Formats
If you have a PEM-format certificate which you want to convert into DER-format, you can use the command:
openssl x509 -in filename.pem -inform pem -out filename.cer -outform der

29.1.5 PKCS12 files
PKCS12 files are a standard way of storing multiple keys and certificates in a single file. Think of it like a zip file for
keys & certificates, which includes options to password protect etc.
Don’t worry about this unless you need it because some application requires a PKCS12 file or you’re given one that
you need to get stuff out of.
Viewing PKCS12 Keystore Contents:
openssl pkcs12 -in filename.p12 -info

If you have two separate files containing your certificate and private key, both in PEM format, you can combine these
into a single PKCS12 file using the command:
openssl pkcs12 -in cert.pem -inkey key.pem -export -out filename.p12

29.1.6 Encrypting and signing things
Signing E-mails:
openssl smine -sign -in msg.txt -text -out msg.encrypted -signer blah.crt.pem -inkey
˓→blah.key.pem

Sign some text:
openssl dgst -sign private.key -out signature.asc

Verify signature:

29.1. End-user Functions

213

Dan’s Cheat Sheets Documentation, Release 1

if openssl dgst -verify public.key -signature signature.asc ; then echo GOOD; else
˓→echo BAD; fi

Encrypt and decrypt a single file:
openssl aes-128-cbc -salt -in file -out file.aes
openssl aes-128-cbc -d -salt -in file.aes -out file

Simple file encryption:
openssl enc -bf -A -in file_to_encrypt.txt

(password will be prompted)
Simple file decryption:
openssl enc -bf -d -A -in file_to_encrypt.txt

tar and encrypt a whole directory:
tar -cf - directory | openssl aes-128-cbc -salt -out directory.tar.aes
openssl aes-128-cbc -d -salt -in directory.tar.aes | tar -x

tar zip and encrypt a whole directory:
tar -zcf - directory | openssl aes-128-cbc -salt -out directory.tgz.aes
openssl aes-128-cbc -d -salt -in directory.tgz.aes | tar -xz

29.2 Certificate Authority Functions
When setting up a new CA on a system, make sure index.txt and serial exist (empty and set to 01, respectively), and
create directories private and newcert.
Edit openssl.cnf - change default_days, certificate and private_key, possibly key size (1024, 1280, 1536, 2048) to
whatever is desired.
Create CA Certificate:
openssl req -new -x509 -keyout private/something-CA.key.pem \
-out ./something-CA.crt.pem -days 3650

Export CA Certificate in DER Format:
openssl x509 -in something-CA.crt.pem -outform der \
-out something-CA.crt

Revoke Certificate:
openssl ca -revoke blah.crt.pem

Generate Certificate Revokation List:
openssl ca -gencrl -out crl/example.com-CA.crl

Sign Certificate Request:

214

Chapter 29. OpenSSL

Dan’s Cheat Sheets Documentation, Release 1

openssl ca -out blah.crt.pem -in blah.req.pem

Create Diffie-Hoffman Parameters for Current CA:
openssl dhparam -out example.com-CA.dhp.pem 1536

Creating Self-Signed Certificate from Generated Key:
openssl req -new -x509 -key blah.key.pem -out blah.crt.pem

Use only when you’ve no CA and will only be generating one key/certificate (useless for anything that requires signed
certificates on both ends)

29.2. Certificate Authority Functions

215

Dan’s Cheat Sheets Documentation, Release 1

216

Chapter 29. OpenSSL

CHAPTER

30

Org mode (Emacs)

http://orgmode.org/org.html See also http://orgmode.org/orgcard.pdf
Binding
Tasks
M-S-Ret
C-c C-t
C-c / t
Agenda
C-c C-a n
b
f
Scheduling
C-c C-s
C-u C-c C-s

Operation
Add a TODO item at same level
Change TODO state
Show only uncompleted todos
View schedule and unscheduled tasks
Move backward (previous day)
Move forward (next day)
Schedule a task (set a date and optional time to do it)
Unschedule a task (remove schedule date/time)

Keys outside org-mode:
Key
What
C-c g
my gtd file
C-c c t
Create task
C-c a X
Agenda view X
C-c l
C-c c
C-c b

org-store-link
org-capture
org-iswitchb (?)

Keys in org-mode file:
C-c C-x p
org-set-property
M-Return
org-meta-return - start new line with new heading at same level
M-S-right arrow move current heading one deeper
(continues on next page)

217

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

C-c C-s
schedule task
C-c C-d
set task deadline
C-c C-q
org-set-tags-command add task tag - USE FOR CONTEXT
C-c / d
org-check-deadlines - spared tree with deadlines that are past-due or
˓→soon to be
<TAB>
S-<TAB>

org-cycle
org-global-cycle

Keys in agenda views:
TBD

218

Chapter 30. Org mode (Emacs)

CHAPTER

31

Postfix

Retry sending all queued mail:
postfix flush

Delete all queued mail:
postsuper -d ALL deferred

219

Dan’s Cheat Sheets Documentation, Release 1

220

Chapter 31. Postfix

CHAPTER

32

Postgres

32.1 Snippets
• In psql:
#

\d *pattern*

Display definition of table, view, or other relations with name matching the pattern
See http://jacobian.org/writing/pg-encoding-ubuntu/ to fix postgres to default to UTF-8 on ancient Ubuntus. (Destroys
data.)
To set up your user on ubuntu to auth to local postgres automatically https://help.ubuntu.com/community/PostgreSQL
Check replication:
ON master, select * from pg_stat_replication;
(from http://www.dansketcher.com/2013/01/27/monitoring-postgresql-streaming˓→replication/)

32.2 Environment Variables
The following environment variables can be used to select default connection parameter values, which will be used
if no value is directly specified. These are useful to avoid hard-coding database connection information into simple
client applications, for example.
PGHOST behaves the same as host connection parameter.
PGHOSTADDR behaves the same as hostaddr connection parameter. This can be set instead of or in
addition to PGHOST to avoid DNS lookup overhead.
PGPORT behaves the same as port connection parameter.
PGDATABASE behaves the same as dbname connection parameter.

221

Dan’s Cheat Sheets Documentation, Release 1

PGUSER behaves the same as user connection parameter.
PGPASSWORD behaves the same as password connection parameter. Use of this environment variable
is not recommended for security reasons (some operating systems allow non-root users to see process
environment variables via ps); instead consider using the ~/.pgpass file (see Section 30.14).
PGPASSFILE specifies the name of the password file to use for lookups. If not set, it defaults to ~/.pgpass
(see Section 30.14).

32.3 Dump Postgres table to a .CSV file
Started with this: http://stackoverflow.com/questions/1120109/export-postgres-table-to-csv-file-with-headings
Using COPY requires superuser but the error message helpfully tells you that you can use copy instead :-)
Using caktus’ django template, something like:
$ fab -udpoirier production manage_run:dbshell
[huellavaliente.com:2222] out: venezuelasms_production=> \copy messagelog_message to
˓→'/tmp/messages.csv' csv header
[huellavaliente.com:2222] out: venezuelasms_production=> \q
$ sftp -o Port=2222 dpoirier@huellavaliente.com
Connected to huellavaliente.com.
sftp> cd /tmp
sftp> ls
messages.csv
sftp> get messages.csv
Fetching /tmp/messages.csv to messages.csv
/tmp/messages.csv
˓→
100% 1776KB 888.0KB/s
sftp> ^D

00:02

32.4 Postgres with non-privileged users
How do we do things on Postgres without giving superuser to the user that actually uses the database every day?
The following assumes a Postgres superuser named ‘master’. (Or the RDS ‘master’ user, who has most superuser
privileges.)
In the examples below, for readability I’m omitting most of the common arguments to specify where the postgres
server is, what the database name is, etc. You can set some environment variables to use as defaults for things:
export
export
export
export

PGDATABASE=dbname
PGHOST=xxxxxxxxx
PGUSER=master
PGPASSWORD=xxxxxxxxxx

32.5 Create user
This is pretty standard. To create user $username with plain text password $password:

222

Chapter 32. Postgres

Dan’s Cheat Sheets Documentation, Release 1

export PGUSER=master
export PGDATABASE=postgres
createuser -DERS $username
psql -c "ALTER USER $username WITH PASSWORD '$password';"

Yes, none of the options in -DERS are strictly required, but if you don’t mention them explicitly, createuser asks you
about them one at a time.
If not on RDS, for the user to actually do something useful like connect to postgres, you might also have to edit
pg_hba.conf and add a line like:
local

<dbname>

<rolename>

md5

to let it connect using host=” (unix domain socket) and provide a password to access <dbname>. You could also put
“all” there to let it access any password it otherwise has auth for. E.g. to allow local connections via both unix socket
and tcp connections to localhost:
local
host

all
all

all
all

127.0.0.1/32

md5
md5

32.6 Create database
If you need a database owned by $project_user, you can:
• Create it as $project_user if that user has CREATEDB:
export PGUSER=$project_user
createdb --template=template0 $dbname

• Create it as a superuser and specify that the owner should be $project_user:
export PGUSER=postgres
createdb --template=template0 --owner=$project_user $dbname

• Create it as any other user, so long as the other user is a member, direct or indirect, of the $project_user
role. That suggests that we could add master to that role. . . need to research that. I think we could do:
export PGUSER=master
psql -c "grant $project_user to master;" postgres
createdb --template=template0 --owner=$project_user $dbname

The question would be: Does master have enough privileges to grant itself membership in another role?
• Finally, you could create it as master when master is not a member of the project_user role. To do that, you’ll
need to create it as master and then modify the ownership and permissions:
export PGUSER=master
createdb --template=template0 $dbname
psql -c "revoke all on database $dbname from public;"
psql -c "grant all on database $dbname to master;"
psql -c "grant all on database $dbname to $project_user;"

If you need to enable extensions etc, do that now (see below). When done, then:
psql -c "alter database $dbname owner to $project_user;"

32.6. Create database

223

Dan’s Cheat Sheets Documentation, Release 1

A superuser could create the database already owned by a specific user, but RDS’s master user cannot.

32.7 PostGIS
To enable PostGIS, as the master user:
export PGUSER=master
psql -c "create extension postgis;"
psql -c "alter table spatial_ref_sys OWNER TO $project_user;"

where $project_user is the postgres user who will be using the database.
(Outside of RDS, only a superuser can use create extension; RDS has special handling for a whitelist of
extensions.)

32.8 Hstore
Hstore is simpler, but you still have to use the master user:
export PGUSER=master
psql -c "create extension hstore;"

32.9 Grant read-only access to a database
Only let readonly_user do reads:
$ psql -c "GRANT CONNECT ON DATABASE $dbname TO $readonly_user;"
$ psql -c "GRANT SELECT ON ALL TABLES IN SCHEMA PUBLIC TO $readonly_user;" $dbname

32.10 Restore a dump to a new database
Create the database as above, including changing ownership to the project user, and enabling any needed extensions.
Then as the project user:
export PGUSER=$project_user
pg_restore --no-owner --no-acl --dbname=$dbname file.dump

Note that you might get some errors during the restore if it tries to create extensions that already exist and that kind of
thing, but those are harmless. It does mean you can’t use --one-transaction or --exit-on-error for the
restore though, because they abort on the first error.

32.11 Dump the database
This is pretty standard and can be done by the project user:
export PGUSER=$project_user
pg_dump --file=output.dump --format=custom $dbname

224

Chapter 32. Postgres

Dan’s Cheat Sheets Documentation, Release 1

32.12 Drop database
When it comes time to drop a database, only master has the permission, but master can only drop databases it owns,
so it takes two steps. Also, you can’t drop the database you’re connected to, so you need to connect to a different
database for the dropdb. The postgres database is as good as any:
export PGUSER=master PGDATABASE=postgres
psql -c "alter database $dbname owner to master;"
psql -c "drop database if exists $dbname;"

(Outside of RDS, a superuser can drop any database. A superuser still has to be connected to some other database
when doing it, though.)

32.13 Drop user
This is standard too. Just beware that you cannot drop a user if anything they own still exists, including things like
permissions on databases.:
$ export PGUSER=master
$ dropuser $user

32.14 Postgres on RDS
• Add django-extensions to the requirements and django_extensions to the INSTALLED_APPS so we can
use the [sqldsn](http://django-extensions.readthedocs.org/en/latest/sqldsn.html) management command to get
the exact Postgres settings we need to access the database from outside of Django. Here’s how it works:
manage.py [--settings=xxxx] sqldsn

32.12. Drop database

225

Dan’s Cheat Sheets Documentation, Release 1

226

Chapter 32. Postgres

CHAPTER

33

Python

Contents:

33.1 Asyncio
33.1.1 What is it
asyncio is a library included in Python 3.5 that supports a programming model where sometimes, operations that
would normally block the thread until some other event happened (like getting a response from a network connection)
instead allow other code to run on that thread while waiting.
asyncio takes a very, very explicit approach to asynchronous programming: only code written in methods flagged as
async can call any code in an asynchronous way.
Which creates a chicken/egg problem: your async methods can only be called by other async methods, so how do you
call the first one?
The answer: you don’t. What you have to do instead is turn over control of the thread to an event loop, after arranging
for the loop to (sooner or later) invoke your async code.
Then once you start the loop running, it can invoke the async code.

33.1.2 What good is it
Note first that you can use threads to accomplish the same things as asyncio in most cases, with better performance.
So what good is asyncio?
For one thing, it leads to more straightforward code than managing multiple threads, protecting data structures from
concurrent access, etc. There’s only one thread and no preemptive multitasking.
If you want to play with async programming in Python, asyncio looks easier to work with and understand than Twisted,
but that’s not a very practical reason.

227

Dan’s Cheat Sheets Documentation, Release 1

More significantly, threads won’t scale as well if you need to wait for many, many things at the same time - asyncio
might be somewhat slower, but might be the only way that some tasks can be run at all. Each thread can take 50K of
memory, while a coroutine might take only 3K.

33.1.3 Event loops
Async code can only run inside an event loop. The event loop is the driver code that manages the cooperative multitasking.
(I think) a typical pattern would be to get or create an event loop, set up some things to be run by it, then start the event
loop running and have it run until the program is finished.
If it’s useful for some reason, you can create multiple threads and run different event loops in each of them. For
example, Django uses the main thread to wait for incoming requests, so we can’t run an asyncio event loop there, but
we can start a separate worker thread for our event loop.

33.1.4 Coroutines
coroutines
• Python distinguishes between a coroutine function and a coroutine object
• Write a coroutine function by putting async in front of the def.
• Only a coroutine function can use await, non-coroutine functions cannot.
• Calling a coroutine function does not execute it, but rather returns a coroutine object. (This is analogous to
generator functions - calling them doesn’t execute the function, it returns a generator object, which we then use
later.)
• To execute a coroutine object, either:
– use it in an expression with await in front of it, or
– schedule it with ensure_future() or create_task().
Example with await:
async def coro_function():
return 2 + 2
coro = coro_function()
# not executed yet; coro is a coroutine, not 4
print(await coro)
# prints "4"

Example of scheduling it:
async def coro_function(hostname):
conn = await .... connect async to hostname somehow...
coro = coro_function("example.com")
asyncio.ensure_future(coro)

Of course, usually you wouldn’t split it onto two lines with a temp variable:
asyncio.ensure_future(coro_function("example.com"))

228

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

or:
asyncio.get_event_loop().create_task(coro_function("example.com"))

33.1.5 Futures
A future is an object that represents something uncompleted. It makes it easy for code in one place to indicate when
the work is done, and optionally what the result was, and for code elsewhere that was interested in it to find out about
it.
In other words, you can use future objects to manage synchronization more explicitly.
Create one on the fly by calling loop.create_future():
future = loop.create_future()

Arrange for something to be called when the future becomes done:
future.add_done_callback(fn)

You can add lots of callbacks. They’ll all be called (one at a time).
The callback receives the future object as an argument. Use functools.partial as usual if you want to pass other
arguments.
When the future is done, mark it done and set its result:
future.set_result(value)

The callbacks can call future.result() to find out what the result was if they care.

33.1.6 Tasks
A Task is a way to arrange for a coroutine to be executed by an event loop, while also providing the caller a way to
find out what the result was.
A task is automatically scheduled for execution when it is created.
There are two ways to do this, which seem equivalent as far as I can tell:
future = loop.create_task(coroutine)
future = asyncio.ensure_future(coroutine[, loop=loop])

Now you can add callbacks if you want:
future.add_done_callback(fn1)

Also, if the loop isn’t already running and you just want to run the loop for this one thing, you can now:
loop.run_until_complete(future)

33.1.7 Awaitables
Coroutine objects and future objects are called awaitables - either can be used with await.
Note: You can only invoke an awaitable once; after that, it’s completed, done, it runs no more.
33.1. Asyncio

229

Dan’s Cheat Sheets Documentation, Release 1

33.1.8 Event loops
Creating/getting one
• To get the current thread’s default event loop object, call asyncio.get_event_loop()
• get_event_loop will not create an event loop object unless you’re on the main thread, and otherwise will raise
an exception if the current thread doesn’t have a default loop set.
• To create a new event loop: new_event_loop()
• To make a loop the default loop for the current thread: set_event_loop(loop)
So, to use an event loop in the main thread, you can just do:
loop = asyncio.get_event_loop()
# use loop....

But to run an event loop in another thread, you would do something like:
loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
# use loop...

You don’t have to set your loop as the thread’s default, though, if you’re willing to pass your loop object to all the
APIs that otherwise use the default loop. But that’s a pain.
Running a loop
If you want a long-running loop that keeps responding to events until it’s told to stop, use loop.run_forever().
If you want to compute some finite work using coroutines and then stop, use loop.run_until_complete(<future or
coroutine>).
Stopping a loop
Use loop.stop().
Getting a loop to call a synchronous callable
By a synchronous callable, I mean a callable that is not an awaitable as described above.
This is more like Javascript’s callback-style async programming than in the spirit of Python’s coroutines, but sometimes you need it.
To call the callable as soon as possible, use loop.call_soon(callback). If you want to pass args to the callable, use
functools.partial:
loop.call_soon(functools.partial(callable, arg1, arg2))

To delay for N seconds before calling it, use loop.call_later(delay, callable).
To schedule a callback from a different thread, the AbstractEventLoop.call_soon_threadsafe() method should be used.
Example:
loop.call_soon_threadsafe(callback, *args)

230

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

Getting a loop to call an awaitable
Use asyncio.ensure_future(awaitable, *, loop=None).
Or loop.run_until_complete, but as noted above, that just runs the loop as long as it takes to complete the awaitable.
If you’re doing this from another
cio.run_coroutine_threadsafe(coro, loop):

thread,

then

you

need

to

use

a

different

method,

asyn-

future = asyncio.run_coroutine_threadsafe(coroutine, loop)

Running blocking code in another thread
If you need to call some blocking code from a coroutine, and don’t want to block the whole thread, you can make it
run in another thread using coroutine AbstractEventLoop.run_in_executor(executor, func, *args):
fn = functools.partial(method, *args)
result = await loop.run_in_executor(None, fn)

Sleep
Calling asyncio.sleep(seconds) does not sleep; it returns a coroutine object. When you execute it by invoking it with
await etc, it will complete after <seconds> seconds. So, mostly you’d do:
await asyncio.sleep(10)

# pause 10 seconds

33.2 How to Fix your Python Code’s Style
(A formatted version of this draft is at https://cheat.readthedocs.io/en/latest/python/fixing_style.html.)
Sometimes we inherit code that doesn’t follow the style guidelines we prefer when we’re writing new code. We could
just run flake8 on the whole codebase and fix everything before we continue, but that’s not necessarily the best use of
our time.
Another approach is to update the styling of files when we need to make other changes to them. To do that, it’s helpful
to be able to run a code style checker on just the files we’re changing. I’ve written tools to do that for various source
control systems and languages over the years. Here’s the one I’m currently using for Python and flake8.
I call this script flake. I have a key in my IDE bound to run it and show the output so I can click on each line to go to
the code that has the problem, which makes it pretty easy to fix things.
It can run in two modes. By default, it checks any files that have uncommitted changes. Or I can pass it the name of a
git branch, and it checks all files that have changes compared to that branch. That works well when I’m working on a
feature branch that is several commits downstream from develop and I want to be sure all the files I’ve changed while
working on the feature are now styled properly.
The script is in Python, of course.

33.2.1 Work from the repository root
Since we’re going to work with file paths output from git commands, it’s simplest if we first make sure we’re in the
root directory of the repository.

33.2. How to Fix your Python Code’s Style

231

Dan’s Cheat Sheets Documentation, Release 1

#!/usr/bin/env python3
import os
import os.path
import subprocess
if not os.path.isdir('.git'):
print("Working dir: %s" % os.getcwd())
result = subprocess.run(['git', 'rev-parse', '--show-toplevel'],
˓→stdout=subprocess.PIPE)
dir = result.stdout.rstrip(b'\n')
os.chdir(dir)
print("Changed to %s" % dir)

We use git rev-parse –show-toplevel to find out what the top directory in the repository working tree is, then change
to it. But first we check for a .git directory, which tells us we don’t need to change directories.

33.2.2 Find files changed from a branch
If a branch name is passed on the command line, we want to identify the Python files that have changed compared to
that branch.
import sys
...
if len(sys.argv) > 1:
# Run against files that are different from *branch_name*
branch_name = sys.argv[1]
cmd = ["git", "diff", "--name-status", branch_name, "--"]
out = subprocess.check_output(cmd).decode('utf-8')
changed = [
# "M\tfilename"
line[2:]
for line in out.splitlines()
if line.endswith(".py") and "migrations" not in line and line[0] != 'D'
]

We use git diff –name-status <branch-name> – to list the changes compared to the branch. We skip file deletions —
that means we no longer have a file to check — and migrations, which never seem to quite be PEP-8 compliant and
which I’ve decided aren’t worth trying to fix. (You may decide differently, of course.)

33.2.3 Find files with uncommitted changes
Alternatively, we just look at the files that have uncommitted changes.
else:
# See what files have uncommitted changes
cmd = ["git", "status", "--porcelain", "--untracked=no"]
out = subprocess.check_output(cmd).decode('utf-8')
changed = []
for line in out.splitlines():
if "migrations" in line:
# Auto-generated migrations are rarely PEP-8 compliant. It's a losing
# battle to always fix them.
continue
if line.endswith('.py'):
(continues on next page)

232

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

if '->' in line:
# A file was renamed. Consider the new name changed.
parts = line.split(' -> ')
changed.append(parts[1])
elif line[0] == 'M' or line[1] != ' ':
changed.append(line[3:])

Here we take advantage of git –porcelain to ensure the output won’t change from one git version to the next, and it’s
fairly easy to parse in a script. (Maybe I should investigate using –porcelain with the other git commands in the script,
but what I have now works well enough.)

33.2.4 Run flake8 on the changed files
Either way, changed now has a list of the files we want to run flake8 on.
cmd = ['flake8'] + changed
rc = subprocess.call(cmd)
if rc:
print("Flake8 checking failed")
sys.exit(rc)

Running flake8 with subprocess.call this way sends the output to stdout so we can see it. flake8 will exit with a
non-zero status if there are problems; we print a message and also exit with a non-zero status.

33.2.5 Wrapping up
I might have once written a script like this in Shell or Perl, but Python turns out to work quite well once you get a
handle on the subprocess module.
The resulting script is useful for me. I hope you’ll find parts of it useful too, or at least see something you can steal for
your own scripts.

33.3 Mock
• http://www.voidspace.org.uk/python/mock/mock.html
• https://docs.python.org/3/library/unittest.mock.html

33.3.1 Mock a function being called in another module
Function being called from another module (medley/photos/tasks/galleryimport.py):
from urllib2 import urlopen

our test.py:
with mock.patch('medley.photos.tasks.galleryimport.urlopen') as urlopen:
urlopen.side_effect = ValueError("Deliberate exception for testing")

33.3. Mock

233

Dan’s Cheat Sheets Documentation, Release 1

33.3.2 Mock a method on a class
Use mock.patch('python.packagepath.ClassName.method_name:
# medley/photos/models.py
class MedleyPhotoManager(...):
def build_from_url(...):

Test code:
with mock.patch('medley.photos.models.MedleyPhotoManager.build_from_url') as build_
˓→from_url:
build_from_url.return_value = None

33.3.3 Replace something with an existing object or literal
Use mock.patch and pass new=:
with mock.patch("medley.photos.tasks.galleryimport.cache", new=get_cache('locmem://
˓→')):
...
with mock.patch(target='medley.photos.tasks.galleryimport.MAX_IMPORTS', new=2):
...

33.3.4 Mock an attribute on an object we have a reference to
Use mock.patch.object(obj, 'attrname'):
with mock.patch.object(obj, ‘attrname’) as foo: . . .

33.3.5 Data on the mock
Attributes on mock objects:
obj.call_count # number of times it was called
obj.called == obj.call_count > 0
obj.call_args_list # a list of (args,kwargs), one for each call
obj.call_args # obj.call_args_list[-1] (args,kwargs from last call)
obj.return_value # set to what it should return
obj.side_effect # set to an exception class or instance that should be raised when
˓→its called
obj.assert_called() # doesn't work with autospec=True? just assert obj.called
obj.assert_called_with(*args, **kwargs) # last call was with (*args, **kwargs)

33.4 Python Packaging
The authoritative docs.
Example setup.py:

234

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

# Always prefer setuptools over distutils
from setuptools import setup, find_packages
# To use a consistent encoding
from codecs import open
from os import path
here = path.abspath(path.dirname(__file__))
setup(
name='ursonos',
version='0.0.1',
packages=find_packages(),
url='',
license='',
author='poirier',
author_email='dan@poirier.us',
description='Urwid application to control Sonos',
install_requires=[
'soco',
'urwid'
]
)

To include non-Python files in the packaging, create a MANIFEST.in file. Example:
include path/to/*.conf

adds the files matching path/to/*.conf. Another:
recursive-include subdir/path *.txt *.rst

adds all files matching *.txt or *.rst that are anywhere under subdir/path. Finally:
prune examples/sample?/build

should be obvious.

33.4.1 Source package
To build a source package:
python setup.py sdist

33.4.2 Wheels
To build a Universal Wheel:
python setup.py bdist_wheel --universal

You can also permanently set the --universal flag in “setup.cfg” (e.g., see sampleproject/setup.cfg)
[bdist_wheel]
universal=1

Only use the --universal setting, if:
33.4. Python Packaging

235

Dan’s Cheat Sheets Documentation, Release 1

1. Your project runs on Python 2 and 3 with no changes (i.e. it does not require 2to3).
2. Your project does not have any C extensions.

33.4.3 Upload
The docs recommend twine
twine upload dist/*

33.5 Pip
Based on A Better Pip Workflow, from a hackernews comment by blaze33:
To keep your file structure with commands and nicely separate your dependencies from your dependencies’ dependencies:
pip freeze -r requirements-to-freeze.txt > requirements.txt

instead of just:
pip freeze > requirements.txt

Danger: beware of git urls being replaced by egg names in the process.

33.6 Pipenv
Pipenv docs

33.6.1 Converting from a requirements file
Just run “pipenv install [-r requirementsfile]” and it’ll see that there’s no Pipfile but a requirements file, and will
generate a new Pipfile and .lock file for you. Then edit the Pipfile to clean it up.

33.6.2 Creating a requirements file
Do this:
pipenv lock --requirements >non-dev-requirements.txt
pipenv lock --requirements --dev >only-dev-requirements.txt

33.6.3 Keeping dev-only packages out of production
1. Add dev-only packages using pipenv install --dev <packages>
2. For development, install using pipenv install --dev
3. In production, leave off the --dev
236

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

33.7 Better Python dependency management with pip-tools
I recently looked into whether I could use pip-tools to improve my workflow around projects’ Python dependencies.My
conclusion was that pip-tools would help on some projects, but it wouldn’t do everything I wanted, and I couldn’t use
it everywhere.(I tried pip-tools version 2.0.2 in August 2018. If there are newer versions, they might fix some of the
things I ran into when trying pip-tools.)

33.7.1 My problems
What were the problems I wanted to find solutions for, that just pip wasn’t handling? Software engineer Kenneth Reitz
explains them pretty well in his post, but I’ll summarize here.
Let me start by briefly describing the environments I’m concerned with. First is my development environment, where
I want to manage the dependencies. Second is the test environment, where I want to know exactly what packages
and versions we test with, because then we come to the deployed environment, where I want to use exactly the same
Python packages and versions as I’ve used in development and testing, to be sure no problems are introduced by an
unexpected package upgrade.
The way we often handle that is to have a requirements file with every package and its version specified. We might start
by installing the packages we know that we need, then saving the output of pip freeze to record all the dependencies
that also got installed and their versions. Installing into an empty virtual environment using that requirements file gets
us the same packages and versions.
But there are several problems with that approach.
First, we no longer know which packages in that file we originally wanted, and which were pulled in as dependencies.
For example, maybe we needed Celery, but installing it pulled in a half-dozen other packages. Later we might decide
we don’t need Celery anymore and remove it from the requirements file, but we don’t know which other packages we
can also safely also remove.
Second, it gets very complicated if we want to upgrade some of the packages, for the same reasons.
Third, having to do a complete install of all the packages into an empty virtual environment can be slow, which is
especially aggravating when we know little or nothing has changed, but that’s the only way to be sure we have exactly
what we want.

33.7.2 Requirements
To list my requirements more concisely:
• Distinguish direct dependencies and versions from incidental
• Freeze a set of exact packages and versions that we know work
• Have one command to efficiently update a virtual environment to have exactly the frozen packages at the frozen
versions and no other packages
• Make it reasonably easy to update packages
• Work with both installing from PyPI, and installing from Git repositories
• Take advantage of pip’s hash checking to give a little more confidence that packages haven’t been modified
• Support multiple sets of dependencies (e.g. dev vs. prod, where prod is not necessarily a subset of dev)
• Perform reasonably well
• Be stable

33.7. Better Python dependency management with pip-tools

237

Dan’s Cheat Sheets Documentation, Release 1

That’s a lot of requirements. It turned out that I could meet more of them with pip-tools than just pip, but not all of
them, and not for all projects.
Here’s what I tried, using pip, virtualenv, and pip-tools.

33.7.3 How to set it up
1. I put the top-level requirements in requirements.in/*.txt.
To manage multiple sets of dependencies, we can include “-r file.txt”, where “file.txt” is another file in requirements.in, as many times as we want. So we might have a base.txt, a dev.txt that starts with -r
base.txt and then adds django-debug-toolbar etc, and a deploy.txt that starts with -r base.txt and
then adds gunicorn.
There’s one annoyance that seems minor at this point, but turns out to be a bigger problem: pip-tools only
supports URLs in these requirements files if they’re marked editable with -e.
# base.txt
Django<2.0
-e git+https://github.com/caktus/django-scribbler@v0.8.0#egg=django-scribbler
# dev.txt
-r base.txt
django-debug-toolbar
# deploy.txt
-r base.txt
gunicorn

2. Install pip-tools in the relevant virtual environment:
$ <venv>/bin/pip install pip-tools

3. Compile the requirements as follows:
$ <venv>/bin/pip-compile --output-file requirements/def.txt requirements.in/dev.txt

This looks only at the requirements file(s) we tell it to look at, and not at what’s currently installed in the virtual
environment. So one unexpected benefit is that pip-compile is faster and simpler than installing everything and then
running pip freeze.
The output is a new requirements file at requirements/dev.txt.
pip-compile nicely puts a comment at the top of the output file to tell developers exactly how the file was generated
and how to make a newer version of it.
#
# This file is autogenerated by pip-compile
# To update, run:
#
#
pip-compile --output-file requirements/dev.txt requirements.in/dev.txt
#
-e git+https://github.com/caktus/django-scribbler@v0.8.0#egg=django-scribbler
django-debug-toolbar==1.9.1
django==1.11.15
pytz==2018.5
sqlparse==0.2.4
# via django-debug-toolbar
```

238

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

4. Be sure requirements, requirements.in, and their contents are in version control.

33.7.4 How to make the current virtual environment have the same packages and
versions
To update your virtual environment to match your requirements file, ensure pip-tools is installed in the desired virtual
environment, then:
$ <venv>/bin/pip-sync requirements/dev.txt

And that’s all. There’s no need to create a new empty virtual environment to make sure only the listed requirements
end up installed. If everything is already as we want it, no packages need to be installed at all. Otherwise only the
necessary changes are made. And if there’s anything installed that’s no longer mentioned in our requirements, it gets
removed.
Except . . .
pip-sync doesn’t seem to know how to uninstall the packages that we installed using -e <URL>. I get errors like this:
Can't uninstall 'pkgname1'. No files were found to uninstall.
Can't uninstall 'pkgname2'. No files were found to uninstall.

I don’t really know, then, whether pip-sync is keeping those packages up to date. Maybe before running pip-sync, I
could just
rm -rf $VIRTUAL_ENV/src

to delete any packages that were installed with -e? But that’s ugly and would be easy to forget, so I don’t want to do
that.

33.7.5 How to update versions
1. Edit requirements.in/dev.txt if needed.
2. Run pip-compile again, exactly as before:
$ <venv>/bin/pip-compile--output-file requirements/dev.txt requirements.in/dev.txt

3. Update the requirements files in version control.

33.7.6 Hash checking
I’d like to use hash checking, but I can’t yet. pip-compile can generate hashes for packages we will install from PyPI,
but not for ones we install with -e <URL>. Also, pip-sync doesn’t check hashes. pip install will check hashes, but if
there are any hashes, then it will fail unless all packages have hashes. So if we have any -e <URL> packages, we have
to turn off hash generation or we won’t be able to pip install with the compiled requirements file. We could still use
pip-sync with the requirements file, but since pip-sync doesn’t check hashes, there’s not much point in having them,
even if we don’t have any -e packages.

33.7.7 What about pipenv?
pipenv promises to solve many of these same problems. Unfortunately, it imposes other constraints on my workflow
that I don’t want. It’s also changing too fast at the moment to rely on in production.

33.7. Better Python dependency management with pip-tools

239

Dan’s Cheat Sheets Documentation, Release 1

Pipenv solves several of the requirements I listed above, but fails on these: It only supports two sets of requirements:
base, and base plus dev, not arbitrary sets as I’d like. It can be very slow. It’s not (yet?) stable: the interface and
behavior is changing constantly, sometimes multiple times in the same day.
It also introduces some new constraints on my workflow. Primarily, it wants to control where the virtual environment
is in the filesystem. That both prevents me from putting my virtual environment where I’d like it to be, and prevents
me from using different virtual environments with the same working tree.

33.7.8 Shortcomings
pip-tools still has some shortcomings, in addition to the problems with checking hashes I’ve already mentioned.
Most concerning are the errors from pip-sync when packages have previously been installed using -e <URL>. I feel
this is an unresolved issue that needs to be fixed.
Also, I’d prefer not to have to use -e at all when installing from a URL.
This workflow is more complicated than the one we’re used to, though no more complicated than we’d have with
pipenv, I don’t think.
The number and age of open issues in the pip-tools git repository worry me. True, it’s orders of magnitude fewer than
some projects, but it still suggests to me that pip-tools isn’t as well maintained as I might like if I’m going to rely on
it in production.

33.7.9 Conclusions
I don’t feel that I can trust pip-tools when I need to install packages from Git URLs.
But many projects don’t need to install packages from Git URLs, and for those, I think adding pip-tools to my workflow
might be a win. I’m going to try it with some real projects and see how that goes for a while.

33.8 Six
Writing Python code that works the same in Python 2 & 3, using six as necessary.

240

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

Python 2
from urlparse import urlparse

Python 3
from urllib.parse import urlparse

dict.iteritems()
dict.iterkeys()
dict.keys()
Exception.message
isinstance(x, str)
filter(condition, iterable)

dict.items()
dict.keys()
list(dict.keys())
Exception.args[0]
isinstance(x, bytes)

Both
from six.moves.urllib.parse import
urlparse
six.iteritems(dict)
six.iterkeys(dict)
list(dict.keys())
Exception.args[0]
isinstance(x, six.binary_type)

[x for x in iterable if condition(x)]

[x for x in iterable if condition(x)]

[function(x) for x in iterable]

[function(x) for x in iterable]

self.assertItemsEqual(
random_order(items),
random_order(more_items))

self.assertCountEqual(
random_order(items),
random_order(more_items))

six.assertCountEqual( self,
random_order(items),
random_order(other_items)

string.lowercase

string.ascii_lowercase

class Foo(BaseClass):
__metaclass__ = MetaClass

class Foo(BaseClass,
metaclass=MetaClass):

string.ascii_lowercase
@six.add_metaclass(MetaClass)
class Foo(BaseClass)

str
unicode
[int, long]
iterator.next()
zip(a, b).__iter__()
zip(a, b)

bytes
str
[int]
next(iterator)
zip(a, b)
list(zip(a, b))

map(function, iterable)

six.binary_type
six.text_type
six.integer_types
six.next(iterator)
list(zip(a, b))

six.BytesIO This is a fake file object for binary data. In Python 2, it’s an alias for StringIO.StringIO, but in Python 3,
it’s an alias for io.BytesIO.
six.StringIO This is an fake file object for textual data. It’s an alias for StringIO.StringIO in Python 2 and io.StringIO
in Python 3.
six.moves.reduce reduce reduce() functools.reduce()
six.moves.range
range xrange() range
six.reraise(exc_type, exc_value, exc_traceback=None) Reraise an exception, possibly with a
different traceback. In the simple case, reraise(*sys.exc_info()) with an active exception (in an except block) reraises the current exception with the last traceback. A different traceback can be specified with the
exc_traceback parameter. Note that since the exception reraising is done within the reraise() function, Python
will attach the call frame of reraise() to whatever traceback is raised.
2to3 does raise E, V, T to raise E(V).with_traceback(T)

33.8. Six

241

Dan’s Cheat Sheets Documentation, Release 1

33.9 Timezones in Python
33.9.1 Key points
• Install the pytz package to provide actual time zones. Python doesn’t come with them.
• There are two kinds of datetime objects in Python, and you need to always know which you’re working with:
– naive - has no timezone info. (datetime.tzinfo is None)
– aware - has timezone info (datetime.tzinfo is not None)
• There will always be some things you want to do with datetimes that are just inherently ambiguous. Get used to
it.

33.9.2 Some use cases
Start by importing useful modules:
import datetime, time, pytz

Given a formatted time string with timezone, end up with a datetime object
Suppose we have RFC 2822 format:
s = "Tue, 3 July 2012 14:11:03 -0400"

It would be nice if strptime could just parse this and give you an aware datetime object, but no such luck:
>>> fmt = "%a, %d %B %Y %H:%M:%S %Z"
>>> datetime.datetime.strptime(s, fmt)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/_
˓→strptime.py", line 325, in _strptime
(data_string, format))
ValueError: time data 'Tue, 3 July 2012 14:11:03 -0400' does not match format '%a, %d
˓→%B %Y %H:%M:%S %Z'
>>> fmt = "%a, %d %B %Y %H:%M:%S %z"
>>> datetime.datetime.strptime(s, fmt)
Traceback (most recent call last):
File "<console>", line 1, in <module>
File "/System/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/_
˓→strptime.py", line 317, in _strptime
(bad_directive, format))
ValueError: 'z' is a bad directive in format '%a, %d %B %Y %H:%M:%S %z'

So, we have to parse it without the time zone:
>>> fmt = "%a, %d %B %Y %H:%M:%S"
>>> dt = datetime.datetime.strptime(s[:-6], fmt)
>>> dt
datetime.datetime(2012, 7, 3, 14, 11, 3)

That is assuming we know exactly how long the timezone string was, but we might not. Try again:

242

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

>>> last_space = s.rindex(' ')
>>> last_space
25
>>> datetime.datetime.strptime(s[:last_space], fmt)

Now, we need to figure out what that timezone string means. Pick it out:
>>> tzs = s[last_space+1:]
>>> tzs
'-0400'

We could have a timezone name or offset, but let’s assume the offset for now. RFC 2282 says this is in the format
[+-]HHMM:
>>> sign = 1
>>> if tzs.startswith("-"):
...
sign = -1
...
tzs = tzs[1:]
... elif tzs.startswith("+"):
...
tzs = tzs[1:]
...
>>> tzs
'0400'
>>> sign
-1

Now compute the offset:
>>> minutes = int(tzs[0:2])*60 + int(tzs[2:4])
>>> minutes *= sign
>>> minutes
-240

Unfortunately, we can’t just plug that offset into our datetime. To create an aware object, Python wants a tzinfo object
that has more information about the timezone than just the offset from UTC at this particular moment.
So here’s one of the problems - we don’t KNOW what timezone this date/time is from, we only know the current offset
from UTC.
So, the best we can do is to figure out the corresponding time in UTC, then create an aware object in UTC. We know
this time is 240 minutes less than the corresponding UTC time, so:
>>> import time
>>> time_seconds = time.mktime(dt.timetuple())
>>> time_seconds -= 60*minutes
>>> utc_time = datetime.datetime.fromtimestamp(time_seconds, pytz.utc)
>>> utc_time
datetime.datetime(2012, 7, 3, 22, 11, 3, tzinfo=<UTC>)

And there we have it, an aware datetime object for that moment in time.

33.10 Tox
33.10.1 Command line
Some useful options:
33.10. Tox

243

Dan’s Cheat Sheets Documentation, Release 1

• tox -l - list environments
• tox -e envname[,envname...] - run tests for just those environments

33.10.2 Configuration
Links:
• Configuration

33.10.3 Substitutions
E.g. {toxinidir}} expands to the directory where tox.ini is, and {{env:ENV_NAME}} expands to the value
of ENV_NAME from the environment:
• Substitutions

33.10.4 Environment variables
Set env vars for the test:
[testenv]
setenv =
VAR1 = value1
VAR2 = value2

Warning: By default tox strips most values from the environment.
You can override with passenv. I generally just put:
passenv = *

in every tox.ini file.
• passing in environment variables
• setting environment variables

33.11 Virtualenv
Using Python virtual environments
Assumes virtualenv and virtualenvwrapper is installed
pip install into site.USER_BASE (kind of a special virtualenv):
PIP_REQUIRE_VIRTUALENV= pip install --user ...

http://www.doughellmann.com/docs/virtualenvwrapper:
sudo /usr/bin/easy_install pip
sudo /usr/local/bin/pip install virtualenvwrapper

244

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

Then add to .bashrc:
export WORKON_HOME=$HOME/.virtualenvs
source /usr/local/bin/virtualenvwrapper.sh

creates and activates a new env, //envname//:
mkvirtualenv //envname//

switch to //envname2//:
workon //envname2//

no longer working with a virtual env:
deactivate

List all of the environments:
lsvirtualenv

Show the details for a single virtualenv:
showvirtualenv

delete a virtual env (must deactivate first):
rmvirtualenv

33.12 XML in Python
33.12.1 Formatting an etree Element
Like this:
def format_element(element):
"""
Given an etree Element object, return a string with the contents
formatted as an XML file.
"""
tree = ElementTree(element)
bytes = StringIO()
tree.write(bytes, encoding='UTF-8')
return bytes.getvalue().decode('utf-8')

33.13 Most minimal logging
Python doesn’t provide any logging handlers by default, resulting in not seeing anything but an error from the logging
package itself. . . Add a handler to the root logger so we can see the actual errors.:
import logging
logging.getLogger('').addHandler(logging.StreamHandler())

33.12. XML in Python

245

Dan’s Cheat Sheets Documentation, Release 1

33.14 Binary data to file-like object (readable)
f = io.BytesIO(binary_data) # Python 2.7 and 3

33.15 Join list items that are not None
Special case use of filter:
join(', ', filter(None, the_list))

33.16 Declare file encoding
Top of .py file:
# -*- coding: UTF-8 -*# vim:fileencoding=UTF-8

33.17 Quick ‘n’ easy static web server
• Change to the top level directory of the static files
• Run python -m http.server

33.18 Python snippet copy logging to stdout
add to top:
import logging
handler = logging.StreamHandler()
root_logger = logging.getLogger('')
root_logger.setLevel(logging.DEBUG)
root_logger.addHandler(handler)

33.19 Warnings
Hiding python warnings. e.g. Deprecations:
python -Wignore::DeprecationWarning ...

33.20 Pylint
Running it:

246

Chapter 33. Python

Dan’s Cheat Sheets Documentation, Release 1

python /usr/bin/pylint --rcfile=.pylintrc -f colorized aremind.apps.patients | less -r

Disabling a warning in code:
# pylint: disable-msg=E1101

33.20. Pylint

247

Dan’s Cheat Sheets Documentation, Release 1

248

Chapter 33. Python

CHAPTER

34

Raspberry Pi

34.1 USB drive with Raspberry PI
Here are detailed steps to get a Raspberry PI running entirely off a USB drive (after booting from its SD card).
Some sources:
• Move root to USB drive: http://magnatecha.com/using-a-usb-drive-as-os-root-on-a-raspberry-pi/
http://elinux.org/Transfer_system_disk_from_SD_card_to_hard_disk
• UUIDs: http://liquidat.wordpress.com/2013/03/13/uuids-and-linux-everything-you-ever-need-to-know/
Detailed log:
• Start with 4 GB SD card
• Copy 2013-07-26-wheezy-raspbian.img onto it:
sudo dd if=path/2013-07-26-wheezy-raspbian.img of=/dev/mmcblk0 bs=1M
• Partition USB drive:
– Partition 1: system root: 16 GB
– Partition 2: Swap: 1 GB
– Partition 3: /usr/local: rest of drive
• Format the partitions too (ext4)
– sudo mkfs.ext3 -q -m 0 -L ROOT /dev/sdb1
– sudo mkswap -q -L SWAP120 /dev/sdb2
– sudo mkfs.ext3 -q -m 0 -L LOCAL /dev/sdb3
• Boot off 4 GB SD card
• ssh to its IP address (get from router or whatever):

249

Dan’s Cheat Sheets Documentation, Release 1

ssh pi@[IP ADDRESS]
password: raspberry

• Copy current root partition to USB drive (see blog post mentioned above to make sure you’re using the right
partitions):
sudo dd if=/dev/mmcblk0p2 of=/dev/sda1 bs=4M

• Resize:
sudo e2fsck -f /dev/sda1
sudo resize2fs /dev/sda1

• See what UUID it got:
$ sudo blkid /dev/sda1
/dev/sda1: UUID="9c7e2035-df9b-490b-977b-d60f2170889d" TYPE="ext4"

• Mount:
sudo mount /dev/sda1 /mnt

• Edit config files and change current root partition to the new root UUID in fstab, and /dev/sda1 in cmdline.txt
(cmdline.txt doesn’t support UUID, darn)
– vi /mnt/etc/fstab:
UUID=9c7e2035-df9b-490b-977b-d60f2170889d
˓→async
0
1

/

ext4

defaults,noatime,

– vi /boot/cmdline.txt (http://elinux.org/RPi_cmdline.txt)
• Umount /mnt:
sudo umount /mnt

• Reboot and check things out
Swap:
• Format swap partition:
$ sudo mkswap -L swappart /dev/sda2
Setting up swapspace version 1, size = 1048572 KiB
LABEL=swappart, UUID=a471af01-938b-4ad0-8653-dafe211cdfba

• Make sure it’ll work:
sudo swapon -U a471af01-938b-4ad0-8653-dafe211cdfba
free -h

• Edit /etc/fstab, add at end:
UUID=a471af01-938b-4ad0-8653-dafe211cdfba swap swap defaults 0 0

• Remove the default 100M swap file:
sudo apt-get purge dphys-swapfile

250

Chapter 34. Raspberry Pi

Dan’s Cheat Sheets Documentation, Release 1

• reboot and check swap space again, should be 1 G (not 1.1 G)
Now move /usr/local to the USB drive:
• Format partition:
sudo mkfs.ext4 -L usr.local /dev/sda3

• Find out its UUID:
$ blkid /dev/sda3
/dev/sda3: LABEL="usr.local" UUID="3c6e0024-d0e4-412e-a4ab-35d7c9027070" TYPE=
˓→"ext4"

• Mount it temporarily on /mnt:
sudo mount UUID="3c6e0024-d0e4-412e-a4ab-35d7c9027070" /mnt

• Copy the current /usr/local over there:
(cd /usr/local;sudo tar cf - .) | ( cd /mnt;sudo tar xf -)

• Umount:
sudo umount /mnt

• Remove files from /usr/local:
sudo rm -rf /usr/local/*

• Edit /etc/fstab to mount /dev/sda3 on /usr/local at boot:
UUID=3c6e0024-d0e4-412e-a4ab-35d7c9027070
˓→noatime
0
1

/usr/local

ext4

defaults,

• See if that works:
sudo mount -a
df -h

• reboot and make sure it works again

34.1. USB drive with Raspberry PI

251

Dan’s Cheat Sheets Documentation, Release 1

252

Chapter 34. Raspberry Pi

CHAPTER

35

Release - how to

How to release
This is a checklist for releasing a new version of something if we’re using the Git Flow <http://nvie.com/posts/
a-successful-git-branching-model/> process for development.

35.1 Git branches
Since we use Git Flow, the two branches of concern at release time are:
• master - always has the most recently released code. Each release is tagged X.X.X.
• develop - contains the code under development for the next release
So technically, what makes a new release is merging develop to master and tagging it. Of course, we don’t want to do
that until we’re ready.
We also use the git flow <https://github.com/nvie/gitflow> tool to help with the Git Flow branching model, especially
for releases.

35.2 Release steps
Take these steps to release the new version:
• Make a fresh clone of the repo (to make sure we’re working off the same code that’s on github):
git clone git@github.com:org/project.git cd project
• Set up git flow in this new repo:
git checkout master
git flow init -d

• Start release branch using git flow:

253

Dan’s Cheat Sheets Documentation, Release 1

git flow release start <VERSION>
e.g.
git flow release start ‘0.0.5’
Do not include v on the front of the version number - there’s nothing wrong with it, we’re just not using it for our
version numbers here and want to be consistent.
• Run the tests locally. The tests must pass before proceeding. Fix any problems and commit the changes.
• Set VERSION in project/__init__.py to the same version, e.g. VERSION = ‘0.0.5’.
• Start a new section in RELEASE_NOTES.rst for the new release. Always put the new release section above the
previous ones.
• Review git log and add major new features and incompatibilities to the release notes.
• Commit changes. Be sure to include the new version number in the commit message first line, e.g. “Bump
version for 0.0.5”.
• Push the release branch.
• Open a pull request from the release branch to the master branch.
• When pull request has been reviewed, use git flow commands to make the release:
git flow release finish ‘0.0.5’
You’ll be prompted for a commit message for the merge to master. The default is fine (Merge branch ‘release/0.0.5’).
You’ll be prompted for a tag message. Make it “Tag for v0.0.5” or whatever the version is.
You’ll be prompted for a commit message for the merge back to develop. The default is fine.
• Push the merged master and develop branch and tag to github:
git push origin master –tags git push origin develop –tags
• Verify that CI tests have passed for the pushed master
• Email the release announcement

254

Chapter 35. Release - how to

CHAPTER

36

reStructuredText

REST reStructuredText notes (see also Sphinx notes)
SEE CHEATSHEET AT END
• rst tutorial
• rst primer
• rst markup
• autodoc
Example:
file1.rst
--------Contents:
.. toctree::
:maxdepth: 2
keys
api

Go read :ref:`morestuff` for more. Read about python package :py:mod:`package.name`
and python function :py:func:`package.name.function`. The python class
:py:class:`package.name.ClassName` might also be useful, and its method
:py:meth:`package.name.ClassName.method`. Not to mention the attribute
:py:attr:`package.name.ClassName.attrname`. The code might throw the exception
:py:exc:`package.name.MyException`.
file2.rst
--------(continues on next page)

255

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

.. _morestuff:
More stuff
==========
To show code::
Indent this 4 spaces.
You can indent more or less.
And keep going.
Even include blank lines
It ends after a blank line and returning to the original indentation.
You can also markup ``short inline code`` like this.

Automatically include the doc for a class like this:
.. _api:
.. autoclass:: healthvaultlib.healthvault.HealthVaultConn
:members:

And document them:
class MyClassName(object):
"""
Description. Can refer to :py:meth:`.method1` here or anywhere in the file.
:param string parm1: His name
:param long parm2: His number
"""
def __init__(self, parm1, parm2):
pass
def method1(self, arg1, arg2):
"""
Description
:param unicode arg1: something
:param object arg2: something else
"""

http://techblog.ironfroggy.com/2012/06/how-to-use-sphinx-autodoc-on.html
Various code blocks:
.. code-block:: bash|python|text
:linenos:
:emphasize-lines: 1,3-5
#
#
#
#

Hi
there
all
you
(continues on next page)

256

Chapter 36. reStructuredText

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

# coders
# rejoice
1
2
3
4
5
6

#
#
#
#
#
#

Hi
there
all
you
coders
rejoice

You can include an `HTML link`_ like this and the definition can go nearby or at the bottom of the page:
.. _HTML link: http://foo.bar.com/

Or you can just write `HTML link <http://foo.bar.com>`_ all in one place.
http://sphinx-doc.org/markup/inline.html#ref-role
Link to a filename in this set of docs using :doc:`Any text you want </path/to/page>` or just
:doc:`path`.
Don’t include the “.rst” on the end of the filename. Relative filenames work too. But it’s better to use :ref:, see next.
You can define an anchor point, which Sphinx calls a label. Put this above a section header:
.. _my-label:
My Section
----------

Now from somewhere else, you can write :ref:`my-label` and it’ll be rendered as “My Section” and will link
to the section. If you want some other text in the link, you can write :ref:`any text <my-label>` instead.

36.1 Cheatsheets
Copied from http://docs.sphinxdocs.com/en/latest/cheatsheet.html - thanks to Read The Docs.
BUGS:
• codeblock should be code-block

36.1. Cheatsheets

257

Dan’s Cheat Sheets Documentation, Release 1

258

Chapter 36. reStructuredText

Dan’s Cheat Sheets Documentation, Release 1

36.1. Cheatsheets

259

Dan’s Cheat Sheets Documentation, Release 1

260

Chapter 36. reStructuredText

CHAPTER

37

Salt Stack

https://docs.saltstack.com/en/latest/topics/tutorials/pillar.html

37.1 Fetching pillar data in templates
In the Jinja2 context, pillar is just a dictionary, so you can use the usual Python dictionary methods, e.g.:
{% for user, uid in pillar.get('users', {}).items() %}
{{user}}:
user.present:
- uid: {{uid}}
{% endfor %}

If you have nested data, it can be easier to use salt['pillar.get'], which accepts a single key parameter like
key1:key2. E.g. if the pillar data looks like:
apache:
user: fred

you could access the username as:
{{ salt['pillar.get']['apache:user'] }}

instead of:
{{ pillar['apache']['user'] }}

though that would work too.

261

Dan’s Cheat Sheets Documentation, Release 1

262

Chapter 37. Salt Stack

CHAPTER

38

Socat

http://stackoverflow.com/questions/2149564/redirecting-tcp-traffic-to-a-unix-domain-socket-under-linux
Turns out socat can be used to achieve this:
socat TCP-LISTEN:1234,reuseaddr,fork UNIX-CLIENT:/tmp/foo

And with a bit of added security:
socat TCP-LISTEN:1234,bind=127.0.0.1,reuseaddr,fork,su=nobody,range=127.0.0.0/8 UNIX˓→CLIENT:/tmp/foo

263

Dan’s Cheat Sheets Documentation, Release 1

264

Chapter 38. Socat

CHAPTER

39

Tmux

My tmux char: C-g (control-g)
session: a whole set of processes. Your tmux client is attached to one session. window:
Bindings:
Open prompt:

:

Client:
detach current:
detach any:
suspend:
Sessions:
rename
select
last

d
D
C-z

$
s
L

Windows:
Info:
i
Create:
c
Kill:
&
Switch to: '
Choose:
w
Rename:
,
Switch to 0-9: 0-9
Previously selected:
Next:
Previous:
Next window with bell
Pane:
Kill:
x
Previous:
;
swap with previous

l
n
p
M-n

{
(continues on next page)

265

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

swap with next

}

Panes:
Split current pane into two:
Top and bottom: Left and right: |

266

Chapter 39. Tmux

CHAPTER

40

Travis CI

Magic syntax to run tox tests with multiple Python versions (as of Nov 1, 2017 anyway):
# Use travis container-based build system for speed
sudo: false
# Ubuntu trusty (14.04) - latest that Travis offers
dist: trusty
# Make sure all the python versions we need are pre-installed
# (apt-get is not available in the container-based build system)
addons:
apt:
sources:
- deadsnakes
packages:
- python2.7
- python3.4
- python3.5
- python3.6
language: python
# The version of Python that'll be used to invoke tox. Has no effect
# on what version of Python tox uses to run each set of tests.
python:
- "3.5"
# Test a sampling of combinations
env:
- TOXENV=py27-1.7
- TOXENV=py27-1.8
- TOXENV=py27-1.10
- TOXENV=py27-1.11
- TOXENV=py34-1.7
(continues on next page)

267

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

-

TOXENV=py34-1.8
TOXENV=py34-1.11
TOXENV=py35-1.9
TOXENV=py35-1.10
TOXENV=py35-1.11
TOXENV=py36-1.8
TOXENV=py36-1.10
TOXENV=py36-1.11

install:
- pip install tox
script:
- tox
#
#matrix:
# allow_failures:
#
- env: TOXENV=py27-trunk,py33-trunk

268

Chapter 40. Travis CI

CHAPTER

41

Video

Video tools to use on Linux

41.1 avidemux
GUI tool that’s good for chopping up longer videos into shorter pieces without re-encoding when you need to watch
the video and scan back and forth to find the places you want to split.

41.2 makemkv
CLI good for ripping DVDs and Blu-Rays to mkv.
(Has GUI too.)

41.3 mkvmerge
CLI only.
Join mkv streams end-to-end without re-encoding. (Inverse of avidemux.)
Split mkv streams at timestamps or chapters without re-encoding.

269

Dan’s Cheat Sheets Documentation, Release 1

270

Chapter 41. Video

CHAPTER

42

X11 Window System

42.1 Startup
Looking around on Ubuntu
/etc/X11 is a good place to start
Xsession is invoked by the display manager.
See ‘man 5 Xsession’
Xsession redirects stdout & stderr to $HOME/.xsession-errors almost first thing
Xsession.d/* has a bunch of scripts that are sourced in order by Xsession:
20x11-common_process-args: sets STARTUP if arg passed to Xsession 40x11-common_xsessionrc: will
source $HOME/.xsessionrc if it is readable 50x11-common_determine-startup: will set STARTUP to
~/.xsession or ~/.Xsession but ONLY if the display manager has not already set a startup command by
passing it to Xsession - or so the comments say. . .
Also look at /etc/kde4/kdm:
kdmrc: LOTS of useful config stuff - read the comments
Which directories kdm looks in for different desktop sessions - It might just use the first of these where it finds
anything??????
/usr/share/xsessions /var/lib/menu-xdg/xsessions (no such dir) /etc/kde4/kdm/sessions (empty)
/usr/share/kde4/apps/kdm/sessions (a zillion files, I suspect it doesn’t look here since others come
first)

271

Dan’s Cheat Sheets Documentation, Release 1

272

Chapter 42. X11 Window System

CHAPTER

43

Virtualbox

List running VMs:
VBoxManage list runningvms

Stop a running VM:
VBoxManage controlvm <UUID|VMNAME> pause|resume|reset|poweroff etc.

Delete a VM:
VboxManage unregistervm <UUID|VMNAME> [--delete]

273

Dan’s Cheat Sheets Documentation, Release 1

274

Chapter 43. Virtualbox

CHAPTER

44

Vue

44.1 WORK IN PROGRESS: a Vue pattern for a component to edit the
properties of some object
Usage:
<my-component value="instance" @save="onSave" @cancel="onCancel">

Minimal implementation:
<template>
<input v-model="workingValue.prop1">
<input v-model="workingValue.prop2">
<button type="button" @click="cancelClicked">Cancel</button>
<button type="button" @click="saveClicked">Save</button>
</template>
<script>
import _ from 'lodash'
export default {
name: 'MyComponent',
data () {
return {
workingValue: _.cloneDeep(this.value)
}
},
props: {
value: {
type: Object,
required: true
}
},
(continues on next page)

275

Dan’s Cheat Sheets Documentation, Release 1

(continued from previous page)

methods: {
cancelClicked () {
this.$emit('cancel')
},
saveClicked () {
if (isValid(this.workingValue)) {
this.$emit('save', this.workingValue)
}
}
}
}
</script>

It is careful not to ever modify the value passed to it. The parent expects that it can manage changes itself by using a
computed property or watcher if it wants.
The component emits events to tell the parent when the user has chosen to save their changes, or cancel, but leaves it
to the parent to do what it wants at that point.
Example using the component:
<template>
<my-component
v-if="userIsEditingObject"
@save="onSave"
@cancel="onCancel"
/>
</template>
<script>
export default {
methods: {
onCancel () {
this.userIsEditingObject = false
},
onSave (value) {
this.$store.dispatch('save', value).then( () => {
this.userIsEditingObject = false
})
}
}
</script>

44.2 Reactivity
The following applies to the store’s state, anything in a component’s data, and other things that get pulled into the
reactivity system.
When an object is added to Vue’s reactivity system, Vue replaces all its properties with getters and setters under
the covers, so that if you fetch the value of a property, or assign a new value to it, Vue is aware and can react.
(https://vuejs.org/v2/guide/reactivity.html)
However, for technical reasons, Vue cannot detect when a property is added to or removed from an object. (https:
//vuejs.org/v2/guide/reactivity.html#Change-Detection-Caveats)
The implications are:

276

Chapter 44. Vue

Dan’s Cheat Sheets Documentation, Release 1

• When updating the store, it’s fine to assign a new value to a property of the state.
• When updating component data, it’s fine to assign a new value to a property of the component data.
• Don’t try to use Object.assign or equivalent to update properties of objects in-place in the store???? It doesn’t
seem to work.

44.3 Component properties
Vue doesn’t necessarily rebuild a component from scratch when one of its properties changes. If you’re using a
property to initialize something, for example, you will need to watch that property and re-initialize when it changes
that way.
However, I’m not sure even watching a property works. I’ve seen components updated when a watch on a property
never triggered.

44.4 Vuex (the store)
44.4.1 Getters
Getters doc
Getters provide computed values based on the state. Their results are cached until the state they depend on changes.
Getters are accessed as properties not methods.
They are passed as a second arg an object with all the store’s getters, in case they want to use them.
const store = new Vuex.Store({
...
getters: {
totalCost: (state, othergetters) => {
return some_computation_on_state
}
// component...
computed: {
the_total_cost () {
return store.getters.totalCost
}
}

// No parens, not called like a method

44.4.2 Mutations
Mutations doc
Mutations must be synchronous.
They cannot be called. They must be invoked using commit.
They receive a state and optional arguments, and can change the state.
When the state changes, other Vue components observing the state will update automatically.
Any value returned by a mutation is not passed back to the caller of commit.
44.3. Component properties

277

Dan’s Cheat Sheets Documentation, Release 1

44.4.3 Actions
Actions doc
Actions can contain asynchronous code. They receive a context object that has methods like commit and properties
like state and getters.
Actions cannot be called. They must be invoked using dispatch.
Any value returned by an action is passed back to the caller of dispatch, by way of resolving the promise that
dispatch returns to that value.
Dispatching actions always returns Promises.
Example:
const store = new Vuex.Store({
state: {
count: 0
},
mutations: {
increment (state) {
state.count++
}
},
actions: {
increment (context) {
context.commit('increment')
},
checkout ({ commit, state }, products) {
// save the items currently in the cart
const savedCartItems = [...state.cart.added]
// send out checkout request, and optimistically
// clear the cart
commit(types.CHECKOUT_REQUEST)
// the shop API accepts a success callback and a failure callback
shop.buyProducts(
products,
// handle success
() => commit(types.CHECKOUT_SUCCESS),
// handle failure
() => commit(types.CHECKOUT_FAILURE, savedCartItems)
)
},
async actionA ({ commit }) {
commit('gotData', await getData())
},
async actionB ({ dispatch, commit }) {
await dispatch('actionA') // wait for `actionA` to finish
commit('gotOtherData', await getOtherData())
}
}
})

44.5 Custom components implementing v-model
Vue handles the heavy lifting when a component is included somewhere with a v-model attribute. All your component
needs to do is accept a “value” property, and emit an “input” event when the value changes, with the new value.
278

Chapter 44. Vue

CHAPTER

45

Possibly surprising things in Vue

The Vue documentation tells you how almost everything in Vue works, but you really need to know more than that
to use Vue. I like the analogy that knowing how to drive nails and saw boards doesn’t enable you to build a house,
especially not a house that won’t fall down.
Here are some things I’ve discovered through experience, or that were mentioned in the documentation but I’ve found
to be more important than I would have guessed.

45.1 .vue files
• You can start your .vue file with a big multiline <!-- ... --> comment to document it.

45.2 Templates
• A component must end up rendering either zero or one HTML element. It may, of course, have lots of stuff
nested inside. The real surprise to me was that it can render to no element at all.
• You can use both :class and class on the same element. The resulting classes will be merged.
• When using ‘v-if’, ‘v-else’, ‘v-else-if’ in templates, give each element using them a unique key, just as if they
were using ‘v-for’.
• “control-flow” features like ‘v-if’ and ‘v-for’ can only be used as attributes on HTML elements. But if you
really don’t want an HTML element there, you can put them on the pseudo-element <template>.
• v-model should never refer directly to things in the store, because it’ll try to change values without going
through mutations. Using a computed property with a setter handles this nicely.
Note: Wouldn’t it be nice if Vue did “the right thing” in this case? But I guess it can’t know that, say, a Javscript
object string is a property of something else that is reactive.

279

Dan’s Cheat Sheets Documentation, Release 1

• v-model can refer to properties inside a computed property (e.g. v-model="prop1.subprop") where
prop is a computed property.
Warning: But I haven’t tested that the setter gets invoked when prop.subprop is changed, or does v-model just
update the object in place. I’d guess the latter.
• If you need to access something from a template that isn’t already part of the component’s data or methods, just
import it and stick it into .data. E.g.:
import { utilMethod } from '@/utils'
export default {
data () {
return {
a: 1,
utilMethod
}
}
}

Or maybe methods would be better stuck into methods?
• When using v-for, if there’s anything in the list you’re going to iterate over that you don’t want to include,
then use a computed property, or a method, to filter the list down to just the items you do want to include, then
iterate over that using v-for. (Do not try to use v-for and v-if on the same element.)

45.3 Component code
• You can use ref to get access in component code to the DOM. Or this.$el.
• Give every component a name. It’ll make output in the browser console more useful, and is required when
nesting components recursively.
• The vue docs make a point of saying that properties are a one-way flow of information into components.
• To get information back out of a component, you can use:
– events
– the store
– v-model

45.4 Reactivity
I get myself confused with two different things that I’m lumping together as “reactivity”:
1. Vue “knowing” when a piece of data changes so it can take action.
2. The actions Vue takes when it detects such changes.
It helps me to have a mental model of how Vue is implementing something like this. Here’s my mental model for
reactivity. (I do not know for sure that this is accurate - I might need to set up some tests to validate these points.)
• The way Vue can “watch” something is to set up its properties with proxy getters and setters. This is how it
watches vm.data and the store’s state, for example.
• For each property, it starts an “on change” list of things it needs to do if the property’s value changes.
280

Chapter 45. Possibly surprising things in Vue

Dan’s Cheat Sheets Documentation, Release 1

• Each time a watched property’s setter is invoked, Vue looks over its “on change” list and executes each item.
• Vue also arranges to know when watched properties are accessed, but it doesn’t pay attention to that all the time,
only during certain activities:
– while computing a computed property
– while rendering a component (?)
During those times, for each watched property that is accessed, Vue adds an action to that watched property’s
“on change” list to re-compute the thing it was computing when it accessed it previously.
• Any watch property handlers are added to the corresponding “on change” list for the watched data.
You can add properties here. E.g. if patient is part of the data, adding a watcher on patient.email will
trigger when patient.email changes.
Which data does Vue “watch”?
1. The data on a component. When a component is created, Vue sets up proxy getters and setters for each property
of its data, so that if anything is assigned, Vue gets invoked and knows things have changed. It also knows when
things are accessed.
Per the page linked just above, Vue will re-render the view when any property in the components data is changed.
2. Computed properties - at least, computed properties are included when Vue is paying attention to which watched
data is being accessed. (If a computed property has a set(), that doesn’t actually do anything special, though of
course it might make changes to other things that Vue is watching.)
3. The state in the store. “Since a Vuex store’s state is made reactive by Vue, when we mutate the state, Vue
components observing the state will update automatically.”
watching props - this does not seem to work? I put a ‘watch’ on a prop that was being changed, and could see the
component was updating, but the watch did not trigger.

45.5 Computed properties
• Computed properties can have getters and setters which makes them a lot more useful. A common pattern is for
get() to get a value from the store and set() to update the store.
• v-model and a computed property work very well together.

45.6 The store
• Dispatching an action always returns a promise, whether you wrote code in the action method to do that or not.
Of course, if you do return a promise, it’ll be returned to the caller. But this does mean that every time you
dispatch an action, you can (and must) assume it’s going to run asynchronously and code appropriately.
• It’s often a good idea to resist putting things into the store unless you have to. It is, essentially, a big global
variable. Some reasons I think you might reasonably put things into the store:
– you’d otherwise need to pass data as properties down into multiply nested components
– you need to share data among components that are only distantly related
Note that you can still model access to data in your backend by using store actions, but even then, you don’t
necessarily have to save a copy of the data in the store.
What’s the advantage of using the store?

45.5. Computed properties

281

Dan’s Cheat Sheets Documentation, Release 1

• When you commit a change, Vue knows that part of the state has changed and can propagate that change to all
the parts of the app that are depending on it. (more “reactivity”)
• Because the dispatch interface to actions is asynchronous, if the rest of the app accesses the store via actions,
then you can change to having the data in a backend and using an API to access it without having to change
the rest of the app. Just update the actions to use the API instead of looking in the store. The rest of the app is
already written to access things asynchronously.

45.7 More on reactivity
45.7.1 “watching” things
I didn’t notice right away that the “watch” feature of Vue components is cleverly defined so that you can only watch
properties of your component – it is not a general-purpose “watch anything for changes” function. So you can watch
data, or computed properties. And that’s about it, right? ANSWER THIS QUESTION.

282

Chapter 45. Possibly surprising things in Vue

CHAPTER

46

YAML

46.1 YAML syntax
A value:
value

A value named “foo”:
foo: value

A list:
- 1
- 2
- 'a string'

A list named “bar”:
bar:
- 1
- 2
- 'a string'

Alternate list syntax (“Flow style”):
bar: [1, 2, 'a string']

A dictionary:
key1: val1
key2: val2
key3: val3

A dictionary named “joe”:
283

Dan’s Cheat Sheets Documentation, Release 1

joe:
key1: val1
key2: val2
key3: val3

Dictionary in flow style:
joe: {key1: val1, key2: val2, key3: val3}

A list of dictionaries:
children:
name: Jimmy Smith
age: 15
name: Jenny Smith
age 12

284

Chapter 46. YAML

CHAPTER

47

Indices and tables

• genindex
• modindex
• search

285

Dan’s Cheat Sheets Documentation, Release 1

286

Chapter 47. Indices and tables

Index

D
Django, 59
django
circular imports, 122
Dokku, 70

K
Kobo, 163

R
redirect() (built-in function), 120

287

